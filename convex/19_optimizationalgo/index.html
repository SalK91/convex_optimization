<!DOCTYPE html><html lang="en" class="no-js"><head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Structured lecture notes on optimization, convex analysis, and algorithms.">
      
      
        <meta name="author" content="Salman Khan">
      
      
        <link rel="canonical" href="https://salk91.github.io/convex_optimization/convex/19_optimizationalgo/">
      
      
        <link rel="prev" href="../18b_regularization/">
      
      
        <link rel="next" href="../19a_optimization_constraints/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>12. Algorithms for Convex Optimization - Machine Learning Lecture Notes -  Optimization &amp; Algorithms</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.e53b48f4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Merriweather:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&amp;display=fallback">
        <style>:root{--md-text-font:"Merriweather";--md-code-font:"Fira Code"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/print-site.css">
    
      <link rel="stylesheet" href="../../css/print-site-material.css">
    
      <link rel="stylesheet" href="../../styles/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"><script src="../../assets/javascripts/glightbox.min.js"></script><style id="glightbox-style">
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="cyan">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#chapter-12-algorithms-for-convex-optimization" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Machine Learning Lecture Notes -  Optimization &amp; Algorithms" class="md-header__button md-logo" aria-label="Machine Learning Lecture Notes -  Optimization &amp; Algorithms" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Machine Learning Lecture Notes -  Optimization &amp; Algorithms
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              12. Algorithms for Convex Optimization
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="cyan" aria-label="Switch to dark mode" type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="cyan" aria-label="Switch to light mode" type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m3.55 19.09 1.41 1.41 1.8-1.79-1.42-1.42M12 6c-3.31 0-6 2.69-6 6s2.69 6 6 6 6-2.69 6-6c0-3.32-2.69-6-6-6m8 7h3v-2h-3m-2.76 7.71 1.8 1.79 1.41-1.41-1.79-1.8M20.45 5l-1.41-1.4-1.8 1.79 1.42 1.42M13 1h-2v3h2M6.76 5.39 4.96 3.6 3.55 5l1.79 1.81zM1 13h3v-2H1m12 9h-2v3h2"></path></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/SalK91/convex_optimization" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../tutorials/1_lp_transport/" class="md-tabs__link">
          
  
  
    
  
  Case-studies

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../11_intro/" class="md-tabs__link">
          
  
  
    
  
  Convex Optimization

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../print_page/" class="md-tabs__link">
        
  
  
    
  
  Print/PDF

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Machine Learning Lecture Notes -  Optimization &amp; Algorithms" class="md-nav__button md-logo" aria-label="Machine Learning Lecture Notes -  Optimization &amp; Algorithms" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    Machine Learning Lecture Notes -  Optimization &amp; Algorithms
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/SalK91/convex_optimization" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2">
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Case-studies
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Case-studies
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/1_lp_transport/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    I - Transportation Optimization: A Linear Programming Case Study.
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/2_portfolio/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    II - Mean–Variance Portfolio Optimization: A Pareto-Optimal Case Study.
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/3_meta/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    III - Vehicle Routing: A Metaheuristic Case Study.
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Convex Optimization
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Convex Optimization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11_intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. Introduction and Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../12_vector/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. Linear Algebra Foundations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../13_calculus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. Multivariable Calculus for Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../14_convexsets/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Convex Sets and Geometric Fundamentals
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15_convexfunctions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. Convex Functions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../16_subgradients/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. Nonsmooth Convex Optimization – Subgradients
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../16a_optimality_conditions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. First-Order Optimality Conditions in Convex Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../17_kkt/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8. Optimization Principles – From Gradient Descent to KKT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18_duality/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9. Lagrange Duality Theory
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18a_pareto/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10. Pareto Optimality and Multi-Objective Convex Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18b_regularization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11. Regularized Approximation – Balancing Fit and Complexity
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    12. Algorithms for Convex Optimization
    
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../19a_optimization_constraints/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    13. Optimization Algorithms for Equality-Constrained Problems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../19b_optimization_constraints/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    14. Optimization Algorithms for Inequality-Constrained Problems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../20_advanced/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    15. Advanced Large-Scale and Structured Methods
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../21_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    16. Modelling Patterns and Algorithm Selection in Practice
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../30_canonical_problems/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    17. Canonical Problems in Convex Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../35_modern/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    18. Modern Optimizers in Machine Learning Frameworks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../40_nonconvex/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    19. Beyond Convexity – Nonconvex and Global Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../42_derivativefree/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    20. Derivative-Free and Black-Box Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../44_metaheuristic/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    21. Metaheuristic and Evolutionary Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../48_advanced_combinatorial/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    22. Advanced Topics in Combinatorial Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../50_future/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    23. The Future of Optimization — Learning, Adaptation, and Intelligence
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../print_page/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Print/PDF
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/SalK91/convex_optimization/edit/main/docs/convex/19_optimizationalgo.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/SalK91/convex_optimization/raw/main/docs/convex/19_optimizationalgo.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg>
    </a>
  


<h1 id="chapter-12-algorithms-for-convex-optimization">Chapter 12: Algorithms for Convex Optimization<a class="headerlink" href="#chapter-12-algorithms-for-convex-optimization" title="Permanent link">¶</a></h1>
<p>In the previous chapters, we built the mathematical foundations of convex optimization: convex sets, convex functions, gradients, subgradients, KKT conditions, and duality. Now we answer the practical question: How do we actually solve convex optimization problems in practice?</p>
<p>This chapter now serves as the algorithmic backbone of the book. It bridges theoretical convex analysis (Chapters 3–11) with the practical numerical methods that solve those problems. Each algorithm here can be seen as a computational lens on a convex geometry concept — gradients as supporting planes, Hessians as curvature maps, and proximal maps as projection operators. Later chapters (13–15) extend these ideas to constrained, stochastic, and large-scale environments.</p>
<h2 id="problem-classes-vs-method-classes">Problem classes vs method classes<a class="headerlink" href="#problem-classes-vs-method-classes" title="Permanent link">¶</a></h2>
<p>Different convex problems call for different algorithmic structures. Here is the broad landscape:</p>
<table>
<thead>
<tr>
<th>Problem Type</th>
<th>Typical Formulation</th>
<th>Representative Methods</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr>
<td>Smooth, unconstrained</td>
<td><span class="arithmatex">\(\min_x f(x)\)</span>, convex and differentiable</td>
<td>Gradient descent, Accelerated gradient, Newton</td>
<td>Logistic regression, least squares</td>
</tr>
<tr>
<td>Smooth with simple constraints</td>
<td><span class="arithmatex">\(\min_x f(x)\)</span> s.t. <span class="arithmatex">\(x \in \mathcal{X}\)</span> (box, ball, simplex)</td>
<td>Projected gradient</td>
<td>Constrained regression, probability simplex</td>
</tr>
<tr>
<td>Composite convex (smooth + nonsmooth)</td>
<td><span class="arithmatex">\(\min_x f(x) + R(x)\)</span></td>
<td>Proximal gradient, coordinate descent</td>
<td>Lasso, Elastic Net, TV minimization</td>
</tr>
<tr>
<td>General constrained convex</td>
<td><span class="arithmatex">\(\min f(x)\)</span> s.t. <span class="arithmatex">\(g_i(x) \le 0, h_j(x)=0\)</span></td>
<td>Interior-point, primal–dual methods</td>
<td>LP, QP, SDP, SOCP</td>
</tr>
</tbody>
</table>
<h2 id="first-order-methods-gradient-descent">First-order methods: Gradient descent<a class="headerlink" href="#first-order-methods-gradient-descent" title="Permanent link">¶</a></h2>
<p>We solve
<script type="math/tex; mode=display">
\min_x f(x),
</script>
where <span class="arithmatex">\(f\)</span> is convex, differentiable, and (ideally) <span class="arithmatex">\(L\)</span>-smooth: its gradient is Lipschitz with constant <span class="arithmatex">\(L\)</span>, meaning
<script type="math/tex; mode=display">
\|\nabla f(x) - \nabla f(y)\|_2 \le L \|x-y\|_2 \quad \text{for all } x,y.
</script>
</p>
<blockquote>
<p>Smoothness lets us control step sizes.</p>
</blockquote>
<p>Gradient descent iterates
<script type="math/tex; mode=display">
x_{k+1} = x_k - \alpha_k \nabla f(x_k),
</script>
where <span class="arithmatex">\(\alpha_k&gt;0\)</span> is the step size (also called learning rate in machine learning). Typical choices:</p>
<ul>
<li>constant <span class="arithmatex">\(\alpha_k = 1/L\)</span> when <span class="arithmatex">\(L\)</span> is known,</li>
<li>backtracking line search when <span class="arithmatex">\(L\)</span> is unknown,</li>
<li>diminishing step sizes in some settings.</li>
</ul>
<blockquote>
<p>Derivation: </p>
<p>Around <span class="arithmatex">\(x_t\)</span>, we can approximate <span class="arithmatex">\(f\)</span> using its Taylor expansion:</p>
<div class="arithmatex">\[
f(x) \approx f(x_t) + \langle \nabla f(x_t), x - x_t \rangle.
\]</div>
<p>We assume <span class="arithmatex">\(f\)</span> behaves approximately like its tangent plane near <span class="arithmatex">\(x_t\)</span>.  But tf we were to minimize just this linear model, we would move infinitely far in the direction of steepest descent <span class="arithmatex">\(-\nabla f(x_t)\)</span>, which is not realistic or stable. This motivates adding a locality restriction: we trust the linear approximation near <span class="arithmatex">\(x_t\)</span>, not globally. To prevent taking arbitrarily large steps, we add a quadratic penalty for moving away from <span class="arithmatex">\(x_t\)</span>:</p>
<div class="arithmatex">\[
f(x) \approx f(x_t) + \langle \nabla f(x_t), x - x_t \rangle + \frac{1}{2\eta} \|x - x_t\|^2,
\]</div>
<p>where <span class="arithmatex">\(\eta &gt; 0\)</span> is the learning rate or step size.</p>
<ul>
<li>The linear term pulls <span class="arithmatex">\(x\)</span> in the steepest descent direction.</li>
<li>The quadratic term acts like a trust region, discouraging large deviations from <span class="arithmatex">\(x_t\)</span>.</li>
<li><span class="arithmatex">\(\eta\)</span> trades off aggressive progress vs stability:<ul>
<li>Small <span class="arithmatex">\(\eta\)</span> → cautious updates.</li>
<li>Large <span class="arithmatex">\(\eta\)</span> → bold updates (risk of divergence).</li>
</ul>
</li>
</ul>
<p>We define the next iterate as the minimizer of the surrogate objective:</p>
<div class="arithmatex">\[
x_{t+1} = \arg\min_{x \in \mathcal{X}} \Big[ f(x_t) + \langle \nabla f(x_t), x - x_t \rangle + \frac{1}{2\eta} \|x - x_t\|^2 \Big].
\]</div>
<p>Ignoring the constant term <span class="arithmatex">\(f(x_t)\)</span> and differentiating w.r.t. <span class="arithmatex">\(x\)</span>:</p>
<div class="arithmatex">\[
\nabla f(x_t) + \frac{1}{\eta}(x - x_t) = 0
\]</div>
<p>Solving:</p>
<div class="arithmatex">\[
x_{t+1} = x_t - \eta \nabla f(x_t)
\]</div>
</blockquote>
<p>Convergence: For convex, <span class="arithmatex">\(L\)</span>-smooth <span class="arithmatex">\(f\)</span>, gradient descent with a suitable fixed step size satisfies
<script type="math/tex; mode=display">
f(x_k) - f^\star = O\!\left(\frac{1}{k}\right),
</script>
where <span class="arithmatex">\(f^\star\)</span> is the global minimum. This <span class="arithmatex">\(O(1/k)\)</span> sublinear rate is slow compared to second-order methods, but each step is extremely cheap: you only need <span class="arithmatex">\(\nabla f(x_k)\)</span>.</p>
<p>When to use gradient descent:</p>
<ul>
<li>High-dimensional smooth convex problems (e.g. large-scale logistic regression).</li>
<li>You can compute gradients cheaply.</li>
<li>You only need moderate accuracy.</li>
<li>Memory constraints rule out storing or factoring Hessians.</li>
</ul>
<h2 id="accelerated-first-order-methods">Accelerated first-order methods<a class="headerlink" href="#accelerated-first-order-methods" title="Permanent link">¶</a></h2>
<p>Plain gradient descent has an <span class="arithmatex">\(O(1/k)\)</span> rate for smooth convex problems. Remarkably, we can do better — and in fact, provably optimal — by adding <em>momentum</em>.</p>
<h3 id="nesterov-acceleration">Nesterov acceleration<a class="headerlink" href="#nesterov-acceleration" title="Permanent link">¶</a></h3>
<p>Nesterov’s accelerated gradient method modifies the update using a momentum-like extrapolation. One common form of Nesterov acceleration uses two sequences <span class="arithmatex">\(x_k\)</span> and <span class="arithmatex">\(y_k\)</span>:</p>
<ol>
<li>Maintain two sequences <span class="arithmatex">\(x_k\)</span> and <span class="arithmatex">\(y_k\)</span>.</li>
<li>Take a gradient step from <span class="arithmatex">\(y_k\)</span>:
   <script type="math/tex; mode=display">
   x_{k+1} = y_k - \alpha \nabla f(y_k).
   </script>
</li>
<li>Extrapolate:
   <script type="math/tex; mode=display">
   y_{k+1} = x_{k+1} + \beta_k (x_{k+1} - x_k).
   </script>
</li>
</ol>
<p>The extra momentum term <span class="arithmatex">\(\beta_k (x_{k+1}-x_k)\)</span> uses past iterates to “look ahead” and can significantly accelerate convergence.</p>
<p>Convergece: For smooth convex <span class="arithmatex">\(f\)</span>, accelerated gradient achieves
<script type="math/tex; mode=display">
f(x_k) - f^\star = O\!\left(\frac{1}{k^2}\right),
</script>
which is <em>optimal</em> for any algorithm that uses only gradient information and not higher derivatives.</p>
<ul>
<li>Acceleration is effective for well-behaved smooth convex problems.</li>
<li>It can be more sensitive to step size and noise than plain gradient descent.</li>
<li>Variants such as FISTA apply acceleration in the composite setting <span class="arithmatex">\(f + R\)</span>.</li>
</ul>
<blockquote>
<p>The convergence of gradient descent depends strongly on the geometry of the level sets of the objective function. When these level sets are poorly conditioned—that is, highly anisotropic or elongated (not spherical) the gradient directions tend to oscillate across narrow valleys, leading to zig-zag behavior and slow convergence. In contrast, when the level sets are well-conditioned (approximately spherical), gradient descent progresses efficiently toward the minimum. Thus, the efficiency of gradient-based methods is governed by how aspherical (anisotropic) the level sets are, which is directly related to the condition number of the Hessian.</p>
</blockquote>
<h2 id="subgradient-methods">Subgradient Methods<a class="headerlink" href="#subgradient-methods" title="Permanent link">¶</a></h2>
<p>Even when <span class="arithmatex">\(f\)</span> is not differentiable, we can minimise it using subgradient descent:</p>
<div class="arithmatex">\[
x_{k+1} = x_k - \alpha_k g_k,
\qquad g_k \in \partial f(x_k).
\]</div>
<p>Key features:</p>
<ul>
<li>Requires only a subgradient (no differentiability needed).</li>
<li>Works for any convex function.</li>
<li>Stepsizes must typically decrease (e.g. <script type="math/tex"> \alpha_k = c/\sqrt{k} </script>, <script type="math/tex"> \alpha_k = c/k </script>).</li>
<li>Guaranteed convergence for convex <span class="arithmatex">\(f\)</span>, but generally slow.</li>
</ul>
<h3 id="convergence-rates-worst-case">Convergence rates (worst case)<a class="headerlink" href="#convergence-rates-worst-case" title="Permanent link">¶</a></h3>
<ul>
<li>Smooth convex gradient descent: <span class="arithmatex">\(O(1/k)\)</span> or <span class="arithmatex">\(O(1/k^2)\)</span>.  </li>
<li>Nonsmooth subgradient descent:<br>
<script type="math/tex; mode=display">
  f(x_k) - f(x^\star) = O(1/\sqrt{k}).
  </script>
</li>
</ul>
<p>This slower rate reflects the lack of curvature information at kinks.</p>
<h2 id="proximal-and-smoothed-alternatives">Proximal and Smoothed Alternatives<a class="headerlink" href="#proximal-and-smoothed-alternatives" title="Permanent link">¶</a></h2>
<p>Subgradient descent can be slow. Two important families of methods overcome this:</p>
<h3 id="1-proximal-methods">(1) Proximal methods<a class="headerlink" href="#1-proximal-methods" title="Permanent link">¶</a></h3>
<p>For a convex function <span class="arithmatex">\(f\)</span>, the proximal operator is
<script type="math/tex; mode=display">
\mathrm{prox}_{\alpha f}(y)
=
\arg\min_x \left\{
f(x) + \frac{1}{2\alpha}\|x-y\|^2
\right\}.
</script>
</p>
<p>Proximal algorithms (e.g., ISTA, FISTA, ADMM) can handle nonsmooth terms like:</p>
<ul>
<li>
<script type="math/tex"> \ell_1 </script> regularisation,</li>
<li>indicator functions of convex sets,</li>
<li>total variation penalties.</li>
</ul>
<p>They achieve faster and more stable convergence than basic subgradient descent.</p>
<h3 id="2-smoothing-techniques">(2) Smoothing techniques<a class="headerlink" href="#2-smoothing-techniques" title="Permanent link">¶</a></h3>
<p>Many nonsmooth convex functions have smooth approximations:</p>
<ul>
<li>Replace <script type="math/tex"> |t| </script> with the Huber loss.</li>
<li>Replace <script type="math/tex"> \max\{0,z\} </script> with softplus.</li>
<li>Replace <script type="math/tex"> \max_i(a_i^\top x) </script> with log-sum-exp, a smooth convex approximation.</li>
</ul>
<p>Smoothing preserves convexity while allowing the use of fast gradient methods.</p>
<h2 id="steepest-descent-method">Steepest Descent Method<a class="headerlink" href="#steepest-descent-method" title="Permanent link">¶</a></h2>
<p>The steepest descent method generalizes gradient descent by depending on the choice of norm used to measure step size or direction. It finds the direction of <em>maximum decrease</em> of the objective function under a unit norm constraint.</p>
<blockquote>
<p>The norm defines the “geometry” of optimization. Gradient descent is steepest descent under the Euclidean norm. Changing the norm changes what “steepest” means, and can greatly affect convergence, especially for ill-conditioned or anisotropic problems. The norm in steepest descent determines the geometry of the descent and choosing an appropriate norm effectively makes the level sets of the function more rounded (more isotropic), which greatly improves convergence.</p>
</blockquote>
<p>At a point <span class="arithmatex">\(x\)</span>, and for a chosen norm <span class="arithmatex">\(|\cdot|\)</span>:</p>
<div class="arithmatex">\[
\Delta x_{\text{nsd}} = \arg\min_{|v| = 1} \nabla f(x)^T v
\]</div>
<p>This defines the normalized steepest descent direction — the unit-norm direction that yields the most negative directional derivative (i.e., the steepest local decrease of <span class="arithmatex">\(f\)</span>).</p>
<ul>
<li><span class="arithmatex">\(\Delta x_{\text{nsd}}\)</span>: normalized steepest descent direction</li>
<li><span class="arithmatex">\(\Delta x_{\text{sd}}\)</span>: unnormalized direction (scaled by the gradient norm)</li>
</ul>
<p>For small steps <span class="arithmatex">\(v\)</span>,
<script type="math/tex; mode=display">
f(x + v) \approx f(x) + \nabla f(x)^T v.
</script>
The term <span class="arithmatex">\(\nabla f(x)^T v\)</span> describes how fast <span class="arithmatex">\(f\)</span> increases in direction <span class="arithmatex">\(v\)</span>.
To decrease <span class="arithmatex">\(f\)</span> most rapidly, we pick <span class="arithmatex">\(v\)</span> that minimizes this inner product — subject to <span class="arithmatex">\(|v| = 1\)</span>.</p>
<ul>
<li>The result depends on which norm we use to measure the “size” of <span class="arithmatex">\(v\)</span>.</li>
<li>The corresponding dual norm <span class="arithmatex">\(|\cdot|_*\)</span> determines how we measure the gradient’s magnitude.</li>
</ul>
<p>Thus, the steepest descent direction always aligns with the negative gradient, but it is scaled and shaped according to the geometry induced by the chosen norm.</p>
<p>The choice of norm determines:</p>
<ol>
<li>The shape of the unit ball <span class="arithmatex">\({v : |v| \le 1}\)</span>,</li>
<li>The direction of steepest descent, since the minimization is constrained by that shape,</li>
<li>The dual norm <span class="arithmatex">\(|\nabla f(x)|_*\)</span> that measures the gradient’s size.</li>
</ol>
<p>Different norms yield different “geometries” of descent:</p>
<table>
<thead>
<tr>
<th>Norm</th>
<th>Unit Ball Shape</th>
<th>Dual Norm</th>
<th>Effect on Direction</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(\ell_2\)</span></td>
<td>Circle / sphere</td>
<td><span class="arithmatex">\(\ell_2\)</span></td>
<td>Direction is opposite to gradient</td>
</tr>
<tr>
<td><span class="arithmatex">\(\ell_1\)</span></td>
<td>Diamond</td>
<td><span class="arithmatex">\(\ell_\infty\)</span></td>
<td>Moves along coordinate of largest gradient</td>
</tr>
<tr>
<td><span class="arithmatex">\(\ell_\infty\)</span></td>
<td>Square</td>
<td><span class="arithmatex">\(\ell_1\)</span></td>
<td>Moves opposite to sum of all gradient signs</td>
</tr>
<tr>
<td>Quadratic <span class="arithmatex">\((x^T P x)^{1/2}\)</span></td>
<td>Ellipsoid</td>
<td>Weighted <span class="arithmatex">\(\ell_2\)</span></td>
<td>Scales direction by preconditioner <span class="arithmatex">\(P^{-1}\)</span></td>
</tr>
</tbody>
</table>
<p>Thus, the norm defines how “distance” and “steepness” are perceived, shaping how the algorithm moves through the landscape of <span class="arithmatex">\(f(x)\)</span>.</p>
<h2 id="conjugate-gradient-method-fast-optimization-for-quadratic-objectives">Conjugate Gradient Method — Fast Optimization for Quadratic Objectives<a class="headerlink" href="#conjugate-gradient-method-fast-optimization-for-quadratic-objectives" title="Permanent link">¶</a></h2>
<p>Gradient descent can be painfully slow when the level sets of the objective are long and skinny an indication that the Hessian has very different curvature in different directions (poor conditioning). The Conjugate Gradient (CG) method fixes this without forming or inverting the Hessian. It exploits the exact structure of quadratic functions to build advanced search directions that incorporate curvature information at almost no extra cost.</p>
<p>CG is a <em>first-order</em> method that behaves like a <em>second-order</em> method for quadratics.</p>
<p>For a quadratic objective function:</p>
<div class="arithmatex">\[
f(x) = \tfrac12 x^\top A x - b^\top x 
\]</div>
<p>with <span class="arithmatex">\(A \succ 0\)</span>, the level sets are ellipses shaped by the eigenvalues of <span class="arithmatex">\(A\)</span>. If <span class="arithmatex">\(A\)</span> is ill-conditioned, these ellipses are highly elongated. Gradient descent follows the steepest Euclidean descent direction, which points perpendicular to level sets. On elongated ellipses, this produces a zig-zag path that wastes many iterations.</p>
<p>CG replaces the steepest-descent directions with conjugate directions. Two nonzero vectors <span class="arithmatex">\(p_i, p_j\)</span> are said to be A-conjugate if</p>
<div class="arithmatex">\[
p_i^\top A p_j = 0.
\]</div>
<p>This is orthogonality measured in the geometry induced by the Hessian <span class="arithmatex">\(A\)</span>. Why is this useful?</p>
<ul>
<li>Moving along an A-conjugate direction eliminates error components associated with a different eigen-direction of <span class="arithmatex">\(A\)</span>.</li>
<li>Once you minimize along a conjugate direction, you never need to correct that direction again.</li>
<li>After <span class="arithmatex">\(n\)</span> mutually A-conjugate directions, all curvature directions are resolved → exact solution.</li>
</ul>
<p>In contrast, gradient descent repeatedly re-corrects previous progress.</p>
<p>Algorithm (Linear CG): We solve the quadratic minimization problem or, equivalently, the linear system <span class="arithmatex">\(Ax = b\)</span>. Let</p>
<div class="arithmatex">\[
r_0 = b - A x_0, \qquad p_0 = r_0.
\]</div>
<p>For <span class="arithmatex">\(k = 0,1,2,\dots\)</span>:</p>
<ol>
<li>
<p>Step size
   <script type="math/tex; mode=display">
   \alpha_k = \frac{r_k^\top r_k}{p_k^\top A p_k}.
   </script>
</p>
</li>
<li>
<p>Update iterate
   <script type="math/tex; mode=display">
   x_{k+1} = x_k + \alpha_k p_k.
   </script>
</p>
</li>
<li>
<p>Update residual (negative gradient)
   <script type="math/tex; mode=display">
   r_{k+1} = r_k - \alpha_k A p_k.
   </script>
</p>
</li>
<li>
<p>Direction scaling
   <script type="math/tex; mode=display">
   \beta_k = \frac{r_{k+1}^\top r_{k+1}}{r_k^\top r_k}.
   </script>
</p>
</li>
<li>
<p>New conjugate direction
   <script type="math/tex; mode=display">
   p_{k+1} = r_{k+1} + \beta_k p_k.
   </script>
</p>
</li>
</ol>
<p>Stop when <span class="arithmatex">\(\|r_k\|\)</span> is below tolerance.</p>
<p>Every new direction <span class="arithmatex">\(p_{k+1}\)</span> is constructed to be A-conjugate to all previous ones, and this is preserved automatically by the recurrence.</p>
<p>Why CG Is Fast: For an <span class="arithmatex">\(n\)</span>-dimensional quadratic, CG solves the problem in at most <span class="arithmatex">\(n\)</span> iterations in exact arithmetic. In practice, due to floating-point errors and finite precision, it converges much earlier, typically in <span class="arithmatex">\(O(\sqrt{\kappa})\)</span> iterations, where <span class="arithmatex">\(\kappa = \lambda_{\max}/\lambda_{\min}\)</span> is the condition number. The convergence bound in the A-norm is:</p>
<div class="arithmatex">\[
\|x_k - x^\star\|_A \le 
2\left(\frac{\sqrt{\kappa}-1}{\sqrt{\kappa}+1}\right)^k 
\|x_0 - x^\star\|_A.
\]</div>
<p>This is dramatically better than the <span class="arithmatex">\(O(1/k)\)</span> rate of gradient descent.</p>
<p>CG is ideal when:</p>
<ul>
<li>The problem is a quadratic or a linear system with symmetric positive definite (SPD) matrix <span class="arithmatex">\(A\)</span>.</li>
<li><span class="arithmatex">\(A\)</span> is large and sparse or available as a matrix–vector product.</li>
<li>You cannot form or store <span class="arithmatex">\(A^{-1}\)</span> or even the full matrix <span class="arithmatex">\(A\)</span>.</li>
<li>You want a Hessian-aware method but cannot afford Newton’s method.</li>
</ul>
<p>Typical scenarios:</p>
<table>
<thead>
<tr>
<th>Application</th>
<th>Why CG fits</th>
</tr>
</thead>
<tbody>
<tr>
<td>Large linear systems <span class="arithmatex">\(A x = b\)</span></td>
<td>Only requires <span class="arithmatex">\(A p\)</span>, not factorization.</td>
</tr>
<tr>
<td>Ridge regression</td>
<td>Normal equations form an SPD matrix.</td>
</tr>
<tr>
<td>Kernel ridge regression</td>
<td>Solves <span class="arithmatex">\((K+\lambda I)\alpha = y\)</span> efficiently.</td>
</tr>
<tr>
<td>Newton steps in ML</td>
<td>Inner solver for Hessian systems without forming Hessian.</td>
</tr>
<tr>
<td>PDEs and scientific computing</td>
<td>Sparse SPD matrices, ideal for CG.</td>
</tr>
</tbody>
</table>
<p>Assumptions Required for CG: To guarantee correctness of <em>linear CG</em>, we require:</p>
<ul>
<li><span class="arithmatex">\(A\)</span> is symmetric</li>
<li><span class="arithmatex">\(A\)</span> is positive definite</li>
<li>Objective is strictly convex quadratic</li>
<li>Arithmetic is exact (for the finite-step guarantee)</li>
</ul>
<p>If the function is <em>not</em> quadratic or Hessian is not SPD, use Nonlinear CG, which generalizes the idea but loses finite-step guarantees.</p>
<p>Practical Notes:</p>
<ul>
<li>You only need matrix–vector products <span class="arithmatex">\(Ap\)</span>.  </li>
<li>Storage cost is <span class="arithmatex">\(O(n)\)</span>.  </li>
<li>Preconditioning (replacing the system with <span class="arithmatex">\(M^{-1} A\)</span>) improves conditioning and accelerates convergence dramatically.  </li>
<li>Periodic re-orthogonalization can help in long runs with floating-point drift.</li>
</ul>
<blockquote>
<p>CG is the optimal descent method for quadratic objectives:  it constructs Hessian-aware conjugate directions that efficiently resolve curvature, giving Newton-like speed while requiring only gradient-level operations.</p>
</blockquote>
<h2 id="newtons-method-and-second-order-methods">Newton’s method and second-order methods<a class="headerlink" href="#newtons-method-and-second-order-methods" title="Permanent link">¶</a></h2>
<p>First-order methods (like gradient descent) only use gradient information. Newton’s method, in contrast, incorporates curvature information from the Hessian to take steps that better adapt to the local geometry of the function. This often leads to much faster convergence near the optimum.</p>
<p>From Chapter 3, the second-order Taylor approximation of <span class="arithmatex">\(f(x)\)</span> around a point <span class="arithmatex">\(x_k\)</span> is:</p>
<div class="arithmatex">\[
f(x_k + d)
\approx
f(x_k)
+ \nabla f(x_k)^\top d
+ \tfrac{1}{2} d^\top \nabla^2 f(x_k) d.
\]</div>
<p>If we temporarily trust this quadratic model, we can choose <span class="arithmatex">\(d\)</span> to minimize the right-hand side. Differentiating with respect to <span class="arithmatex">\(d\)</span> and setting to zero gives:</p>
<div class="arithmatex">\[
\nabla^2 f(x_k) \, d_{\text{newton}} = - \nabla f(x_k).
\]</div>
<p>Hence, the Newton step is:</p>
<div class="arithmatex">\[
d_{\text{newton}} = - [\nabla^2 f(x_k)]^{-1} \nabla f(x_k),
\quad
x_{k+1} = x_k + d_{\text{newton}}.
\]</div>
<p>This step aims directly at the stationary point of the local quadratic model. When the iterates are sufficiently close to the true minimizer of a strictly convex <span class="arithmatex">\(f\)</span>, Newton’s method achieves quadratic convergence—dramatically faster than the <span class="arithmatex">\(O(1/k)\)</span> or <span class="arithmatex">\(O(1/k^2)\)</span> rates typical of first-order algorithms.</p>
<p>However, far from the minimizer the quadratic model may be inaccurate, the Hessian may be indefinite, or the step may be unreasonably large. For stability, Newton’s method is almost always paired with a line search or trust-region strategy that adjusts step length based on how well the model predicts actual decrease.</p>
<h3 id="solving-the-newton-system">Solving the Newton System<a class="headerlink" href="#solving-the-newton-system" title="Permanent link">¶</a></h3>
<p>Each iteration requires solving</p>
<div class="arithmatex">\[
H \,\Delta x = -g,
\qquad
H = \nabla^2 f(x), \;\; g = \nabla f(x).
\]</div>
<p>If <span class="arithmatex">\(H\)</span> is symmetric positive definite, a Cholesky factorization</p>
<div class="arithmatex">\[
H = L L^\top
\]</div>
<p>allows efficient and numerically stable solution via two triangular solves:</p>
<ol>
<li><span class="arithmatex">\(L y = -g\)</span></li>
<li><span class="arithmatex">\(L^\top \Delta x_{\text{nt}} = y\)</span></li>
</ol>
<p>This avoids forming <span class="arithmatex">\(H^{-1}\)</span> explicitly.</p>
<p>The Newton decrement:</p>
<div class="arithmatex">\[
\lambda(x) = \|L^{-1} g\|_2
\]</div>
<p>gauges proximity to the optimum and provides a natural stopping criterion: <span class="arithmatex">\(\lambda(x)^2/2 &lt; \varepsilon\)</span>.</p>
<p>Computationally, the dominant cost is solving the Newton system. For dense, unstructured problems this costs <span class="arithmatex">\(\approx (1/3)n^3\)</span> operations, though sparsity or structure can reduce this dramatically. Because of this cost, Newton’s method is most appealing for problems of moderate dimension or for situations where Hessian systems can be solved efficiently using sparse linear algebra or matrix–free iterative methods.</p>
<h3 id="gaussnewton-method">Gauss–Newton Method<a class="headerlink" href="#gaussnewton-method" title="Permanent link">¶</a></h3>
<p>The Gauss–Newton method is a specialization of Newton’s method for nonlinear least squares problems</p>
<div class="arithmatex">\[
f(x) = \tfrac12 \| r(x) \|^2,
\]</div>
<p>where <span class="arithmatex">\(r(x)\)</span> is a vector of residual functions and a nonlinear function of <span class="arithmatex">\(x\)</span> and <span class="arithmatex">\(J\)</span> is its Jacobian. Newton’s Hessian decomposes as</p>
<div class="arithmatex">\[
\nabla^2 f(x) = J^\top J \;+\; \sum_i r_i(x)\, \nabla^2 r_i(x).
\]</div>
<p>The second term involves the curvature of the residuals. When <span class="arithmatex">\(r(x)\)</span> is approximately linear near the optimum, this term is small. Gauss–Newton drops it, giving the approximation</p>
<div class="arithmatex">\[
\nabla^2 f(x) \approx J^\top J,
\]</div>
<p>leading to the Gauss–Newton step:</p>
<div class="arithmatex">\[
(J^\top J)\, \Delta = -J^\top r.
\]</div>
<p>Thus each iteration reduces to solving a (potentially large but structured) least-squares system, avoiding full Hessians entirely. The Levenberg–Marquardt method adds a damping term,</p>
<div class="arithmatex">\[
(J^\top J + \lambda I)\, \Delta = -J^\top r,
\]</div>
<p>which interpolates smoothly between  </p>
<ul>
<li>gradient descent (large <span class="arithmatex">\(\lambda\)</span>), and  </li>
<li>Gauss–Newton (small <span class="arithmatex">\(\lambda\)</span>).</li>
</ul>
<p>Damping improves robustness when the Jacobian is rank-deficient or when the neglected second-order terms are not negligible Gauss–Newton and Levenberg–Marquardt are highly effective when the residuals are nearly linear—common in curve fitting, bundle adjustment, and certain layerwise training procedures in deep learning—yielding fast convergence without the expense of full second derivatives.</p>
<h3 id="quasi-newton-methods">Quasi-Newton methods<a class="headerlink" href="#quasi-newton-methods" title="Permanent link">¶</a></h3>
<p>When computing or storing the Hessian is too expensive, we can build low-rank approximations of <span class="arithmatex">\(\nabla^2 f(x_k)\)</span> or its inverse. These methods use gradient information from previous steps to estimate curvature.</p>
<p>The most famous examples are:</p>
<ul>
<li>BFGS (Broyden–Fletcher–Goldfarb–Shanno)  </li>
<li>DFP (Davidon–Fletcher–Powell)  </li>
<li>L-BFGS (Limited-memory BFGS) — for very large-scale problems.</li>
</ul>
<p>Quasi-Newton methods (BFGS, L-BFGS) build inverse-Hessian approximations from gradient differences, achieving superlinear convergence with low memory. They maintain many of Newton’s fast local convergence properties, but with per-iteration costs similar to first-order methods. For instance, BFGS maintains an approximation <span class="arithmatex">\(B_k \approx \nabla^2 f(x_k)^{-1}\)</span> updated via gradient and step differences:</p>
<div class="arithmatex">\[
B_{k+1} = B_k + \frac{(s_k^\top y_k + y_k^\top B_k y_k)}{(s_k^\top y_k)^2} s_k s_k^\top
- \frac{B_k y_k s_k^\top + s_k y_k^\top B_k}{s_k^\top y_k},
\]</div>
<p>where <span class="arithmatex">\(s_k = x_{k+1} - x_k\)</span> and <span class="arithmatex">\(y_k = \nabla f(x_{k+1}) - \nabla f(x_k)\)</span>.</p>
<p>These methods achieve superlinear convergence in practice, making them popular for large smooth optimization problems.</p>
<p>When to use Newton or quasi-Newton methods:</p>
<ul>
<li>You need high-accuracy solutions.  </li>
<li>The problem is smooth and reasonably well-conditioned.  </li>
<li>The dimension is moderate, or Hessian systems can be solved efficiently (e.g., using sparse linear algebra).  </li>
</ul>
<p>For large, ill-conditioned, or nonsmooth problems, first-order or proximal methods (Chapter 10) are typically more suitable.</p>
<h2 id="constraints-and-nonsmooth-terms-projection-and-proximal-methods">Constraints and nonsmooth terms: projection and proximal methods<a class="headerlink" href="#constraints-and-nonsmooth-terms-projection-and-proximal-methods" title="Permanent link">¶</a></h2>
<p>In practice, most convex objectives are not just “nice smooth <span class="arithmatex">\(f(x)\)</span>”. They often have:</p>
<ul>
<li>constraints <span class="arithmatex">\(x \in \mathcal{X}\)</span>,</li>
<li>nonsmooth regularisers like <span class="arithmatex">\(\|x\|_1\)</span>,</li>
<li>penalties that encode robustness or sparsity (Chapter 6).</li>
</ul>
<p>Two core ideas handle this: projected gradient and proximal gradient.</p>
<h3 id="projected-gradient-descent">Projected gradient descent<a class="headerlink" href="#projected-gradient-descent" title="Permanent link">¶</a></h3>
<p>Setting: Minimise convex, differentiable <span class="arithmatex">\(f(x)\)</span> subject to <span class="arithmatex">\(x \in \mathcal{X}\)</span>, where <span class="arithmatex">\(\mathcal{X}\)</span> is a simple closed convex set (Chapter 4).</p>
<p>Algorithm:</p>
<ol>
<li>Gradient step:
   <script type="math/tex; mode=display">
   y_k = x_k - \alpha \nabla f(x_k).
   </script>
</li>
<li>Projection:
   <script type="math/tex; mode=display">
   x_{k+1}
   =
   \Pi_{\mathcal{X}}(y_k)
   :=
   \arg\min_{x \in \mathcal{X}} \|x - y_k\|_2^2~.
   </script>
</li>
</ol>
<p>Interpretation:</p>
<ul>
<li>You take an unconstrained step downhill,</li>
<li>then you “snap back” to feasibility by Euclidean projection.</li>
</ul>
<p>Examples of <span class="arithmatex">\(\mathcal{X}\)</span> where projection is cheap:</p>
<ul>
<li>A box: <span class="arithmatex">\(l \le x \le u\)</span> (clip each coordinate).</li>
<li>The probability simplex <span class="arithmatex">\(\{x \ge 0, \sum_i x_i = 1\}\)</span> (there are fast projection routines).</li>
<li>An <span class="arithmatex">\(\ell_2\)</span> ball <span class="arithmatex">\(\{x : \|x\|_2 \le R\}\)</span> (scale down if needed).</li>
</ul>
<p>Projected gradient is the constrained version of gradient descent. It maintains feasibility at every iterate.</p>
<h3 id="proximal-gradient-forwardbackward-splitting">Proximal gradient (forward–backward splitting)<a class="headerlink" href="#proximal-gradient-forwardbackward-splitting" title="Permanent link">¶</a></h3>
<p>Setting: Composite convex minimisation
<script type="math/tex; mode=display">
\min_x \; F(x) := f(x) + R(x),
</script>
where:</p>
<ul>
<li><span class="arithmatex">\(f\)</span> is convex, differentiable, with Lipschitz gradient,</li>
<li><span class="arithmatex">\(R\)</span> is convex, possibly nonsmooth.</li>
</ul>
<p>Typical choices of <span class="arithmatex">\(R(x)\)</span>:</p>
<ul>
<li><span class="arithmatex">\(R(x) = \lambda \|x\|_1\)</span> (sparsity),</li>
<li><span class="arithmatex">\(R(x) = \lambda \|x\|_2^2\)</span> (ridge),</li>
<li><span class="arithmatex">\(R(x)\)</span> is the indicator function of a convex set <span class="arithmatex">\(\mathcal{X}\)</span>, i.e. <span class="arithmatex">\(R(x)=0\)</span> if <span class="arithmatex">\(x \in \mathcal{X}\)</span> and <span class="arithmatex">\(+\infty\)</span> otherwise — this encodes a hard constraint.</li>
</ul>
<p>Define the proximal operator of <span class="arithmatex">\(R\)</span>:
<script type="math/tex; mode=display">
\mathrm{prox}_{\alpha R}(y)
=
\arg\min_x
\left(
R(x) + \frac{1}{2\alpha} \|x-y\|_2^2
\right).
</script>
</p>
<p>Proximal gradient method:</p>
<ol>
<li>Gradient step on <span class="arithmatex">\(f\)</span>:
   <script type="math/tex; mode=display">
   y_k = x_k - \alpha \nabla f(x_k).
   </script>
</li>
<li>Proximal step on <span class="arithmatex">\(R\)</span>:
   <script type="math/tex; mode=display">
   x_{k+1} = \mathrm{prox}_{\alpha R}(y_k).
   </script>
</li>
</ol>
<p>This is also called forward–backward splitting: “forward” = gradient step, “backward” = prox step.</p>
<h4 id="interpretation">Interpretation:<a class="headerlink" href="#interpretation" title="Permanent link">¶</a></h4>
<ul>
<li>The prox step “handles” the nonsmooth or constrained part exactly.</li>
<li>For <span class="arithmatex">\(R(x)=\lambda \|x\|_1\)</span>, <span class="arithmatex">\(\mathrm{prox}_{\alpha R}\)</span> is soft-thresholding, which promotes sparsity in <span class="arithmatex">\(x\)</span>.<br>
  This is the heart of <span class="arithmatex">\(\ell_1\)</span>-regularised least-squares (LASSO) and many sparse recovery problems.</li>
<li>For <span class="arithmatex">\(R\)</span> as an indicator of <span class="arithmatex">\(\mathcal{X}\)</span>, <span class="arithmatex">\(\mathrm{prox}_{\alpha R} = \Pi_\mathcal{X}\)</span>, so projected gradient is a special case of proximal gradient.</li>
</ul>
<p>This unifies constraints and regularisation.</p>
<h4 id="when-to-use-proximal-projected-gradient">When to use proximal / projected gradient<a class="headerlink" href="#when-to-use-proximal-projected-gradient" title="Permanent link">¶</a></h4>
<ul>
<li>High-dimensional ML/statistics problems.</li>
<li>Objectives with <span class="arithmatex">\(\ell_1\)</span>, group sparsity, total variation, hinge loss, or indicator constraints.</li>
<li>You can evaluate <span class="arithmatex">\(\nabla f\)</span> and compute <span class="arithmatex">\(\mathrm{prox}_{\alpha R}\)</span> cheaply.</li>
<li>You don’t need absurdly high accuracy, but you do need scalability.</li>
</ul>
<p>This is the standard tool for modern large-scale convex learning problems.</p>
<h2 id="penalties-barriers-and-interior-point-methods">Penalties, barriers, and interior-point methods<a class="headerlink" href="#penalties-barriers-and-interior-point-methods" title="Permanent link">¶</a></h2>
<p>So far we’ve assumed either:</p>
<ul>
<li>simple constraints we can project onto,</li>
<li>or nonsmooth terms we can prox.</li>
</ul>
<p>What if the constraints are general convex inequalities <span class="arithmatex">\(g_i(x)\le0\)</span>: Enter penalty methods, barrier methods, and (ultimately) interior-point methods.</p>
<h3 id="penalty-methods">Penalty methods<a class="headerlink" href="#penalty-methods" title="Permanent link">¶</a></h3>
<p>Turn constrained optimisation into unconstrained optimisation by adding a penalty for violating constraints. Suppose we want
<script type="math/tex; mode=display">
\min_x f(x)
\quad \text{s.t.} \quad g_i(x) \le 0,\ i=1,\dots,m.
</script>
</p>
<p>A penalty method solves instead
<script type="math/tex; mode=display">
\min_x \; f(x) + \rho \sum_{i=1}^m \phi(g_i(x)),
</script>
where:</p>
<ul>
<li><span class="arithmatex">\(\phi(r)\)</span> is <span class="arithmatex">\(0\)</span> when <span class="arithmatex">\(r \le 0\)</span> (feasible),</li>
<li><span class="arithmatex">\(\phi(r)\)</span> grows when <span class="arithmatex">\(r&gt;0\)</span> (infeasible),</li>
<li><span class="arithmatex">\(\rho &gt; 0\)</span> is a penalty weight.</li>
</ul>
<p>As <span class="arithmatex">\(\rho \to \infty\)</span>, infeasible points become extremely expensive, so minimisers approach feasibility.  </p>
<p>This is conceptually simple and is sometimes effective, but:</p>
<ul>
<li>choosing <span class="arithmatex">\(\rho\)</span> is tricky,</li>
<li>very large <span class="arithmatex">\(\rho\)</span> can make the landscape ill-conditioned and hard for gradient/Newton to solve.</li>
</ul>
<h3 id="algorithm-basic-penalty-method-quadratic-or-general-penalization">Algorithm: Basic Penalty Method (Quadratic or General Penalization)<a class="headerlink" href="#algorithm-basic-penalty-method-quadratic-or-general-penalization" title="Permanent link">¶</a></h3>
<p>Goal:  Solve<br>
<script type="math/tex; mode=display">
\min_x f(x) \quad \text{s.t. } g_i(x) \le 0,\; i=1,\dots,m.
</script>
</p>
<p>Penalty formulation:<br>
<script type="math/tex; mode=display">
F_\rho(x) = f(x) + \rho \sum_{i=1}^m \phi(g_i(x)),
</script>
where  </p>
<ul>
<li><span class="arithmatex">\(\phi(r) = 0\)</span> if <span class="arithmatex">\(r \le 0\)</span>,  </li>
<li><span class="arithmatex">\(\phi(r)\)</span> grows when <span class="arithmatex">\(r&gt;0\)</span> (e.g., <span class="arithmatex">\(\phi(r)=\max\{0,r\}^2\)</span>),  </li>
<li><span class="arithmatex">\(\rho &gt; 0\)</span> is the penalty weight.</li>
</ul>
<p>Inputs:  </p>
<ul>
<li>objective <span class="arithmatex">\(f(x)\)</span>  </li>
<li>constraints <span class="arithmatex">\(g_i(x)\)</span>  </li>
<li>penalty function <span class="arithmatex">\(\phi\)</span>  </li>
<li>initial point <span class="arithmatex">\(x_0\)</span>  </li>
<li>initial penalty parameter <span class="arithmatex">\(\rho_0 &gt; 0\)</span>  </li>
<li>penalty update factor <span class="arithmatex">\(\gamma &gt; 1\)</span>  </li>
<li>tolerance <span class="arithmatex">\(\varepsilon\)</span></li>
</ul>
<p>Procedure:</p>
<ol>
<li>Choose <span class="arithmatex">\(x_0\)</span>, <span class="arithmatex">\(\rho_0 &gt; 0\)</span>.  </li>
<li>For <span class="arithmatex">\(k = 0, 1, 2, \dots\)</span>:  <ol>
<li>Solve the penalized subproblem  <span class="arithmatex">\(x_{k+1} = \arg\min_x F_{\rho_k}(x)\)</span> using Newton’s method, gradient descent, quasi-Newton, etc.  </li>
<li>Check feasibility / stopping:  If <span class="arithmatex">\(\max_i g_i(x_{k+1}) \le \varepsilon, \quad   \|x_{k+1} - x_k\| \le \varepsilon\)</span>  stop and return <span class="arithmatex">\(x_{k+1}\)</span>.  </li>
<li>Increase penalty parameter  <span class="arithmatex">\(\rho_{k+1} = \gamma\, \rho_k\)</span>   with typical <span class="arithmatex">\(\gamma \in [5,10]\)</span>.  </li>
</ol>
</li>
<li>End.</li>
</ol>
<h3 id="barrier-methods">Barrier methods<a class="headerlink" href="#barrier-methods" title="Permanent link">¶</a></h3>
<p>Penalty methods penalise violation <em>after</em> you cross the boundary. Barrier methods make it impossible to even touch the boundary. For inequality constraints <span class="arithmatex">\(g_i(x) \le 0\)</span>, define the logarithmic barrier
<script type="math/tex; mode=display">
b(x) = - \sum_{i=1}^m \log(-g_i(x)).
</script>
This is finite only if <span class="arithmatex">\(g_i(x) &lt; 0\)</span> for all <span class="arithmatex">\(i\)</span>, i.e. <span class="arithmatex">\(x\)</span> is strictly feasible. As you approach the boundary <span class="arithmatex">\(g_i(x)=0\)</span>, <span class="arithmatex">\(b(x)\)</span> blows up to <span class="arithmatex">\(+\infty\)</span>.</p>
<p>We then solve, for a sequence of increasing parameters <span class="arithmatex">\(t\)</span>:
<script type="math/tex; mode=display">
\min_x \; F_t(x) := t f(x) + b(x),
</script>
subject to strict feasibility <span class="arithmatex">\(g_i(x)&lt;0\)</span>.</p>
<p>As <span class="arithmatex">\(t \to \infty\)</span>, minimisers of <span class="arithmatex">\(F_t\)</span> approach the true constrained optimum. The path of minimisers <span class="arithmatex">\(x^*(t)\)</span> is called the central path.</p>
<p>Key points:</p>
<ul>
<li><span class="arithmatex">\(F_t\)</span> is smooth on the interior of the feasible region.</li>
<li>We can apply Newton’s method to <span class="arithmatex">\(F_t\)</span>.</li>
<li>Each Newton step solves a linear system involving the Hessian of <span class="arithmatex">\(F_t\)</span>, so the inner loop looks like a damped Newton method.</li>
<li>Increasing <span class="arithmatex">\(t\)</span> tightens the approximation; we “home in” on the boundary of feasibility.</li>
</ul>
<h3 id="algorithm-barrier-method-logarithmic-barrier-interior-approximation">Algorithm: Barrier Method (Logarithmic Barrier / Interior Approximation)<a class="headerlink" href="#algorithm-barrier-method-logarithmic-barrier-interior-approximation" title="Permanent link">¶</a></h3>
<p>Goal: Solve the constrained problem<br>
<script type="math/tex; mode=display">
\min_x f(x) \quad \text{s.t. } g_i(x) \le 0,\; i=1,\dots,m.
</script>
</p>
<p>Logarithmic barrier:<br>
<script type="math/tex; mode=display">
b(x) = -\sum_{i=1}^m \log\!\big(-g_i(x)\big),
</script>
defined only for strictly feasible points <span class="arithmatex">\(g_i(x)&lt;0\)</span>.</p>
<p>Barrier subproblem:<br>
<script type="math/tex; mode=display">
F_t(x) = t\, f(x) + b(x),
</script>
where <span class="arithmatex">\(t&gt;0\)</span> is the barrier parameter.</p>
<p>As <span class="arithmatex">\(t \to \infty\)</span>, minimizers of <span class="arithmatex">\(F_t\)</span> approach the constrained optimum.</p>
<p>Inputs:  </p>
<ul>
<li>objective <span class="arithmatex">\(f(x)\)</span>  </li>
<li>inequality constraints <span class="arithmatex">\(g_i(x)\)</span>  </li>
<li>barrier function <span class="arithmatex">\(b(x)\)</span>  </li>
<li>strictly feasible starting point <span class="arithmatex">\(x_0\)</span> (<span class="arithmatex">\(g_i(x_0) &lt; 0\)</span>)  </li>
<li>initial barrier parameter <span class="arithmatex">\(t_0 &gt; 0\)</span>  </li>
<li>barrier growth factor <span class="arithmatex">\(\mu &gt; 1\)</span> (often <span class="arithmatex">\(\mu = 10\)</span>)  </li>
<li>tolerance <span class="arithmatex">\(\varepsilon\)</span></li>
</ul>
<p>Procedure:</p>
<ol>
<li>Choose strictly feasible <span class="arithmatex">\(x_0\)</span>, and pick <span class="arithmatex">\(t_0 &gt; 0\)</span>.  </li>
<li>For <span class="arithmatex">\(k = 0,1,2,\dots\)</span>:  <ol>
<li>Centering step (inner loop):  Solve the barrier subproblem  <script type="math/tex">
  x_{k+1} = \arg\min_x F_{t_k}(x)
  \quad\text{with} g_i(x)<0. </script>  Typically use Newton’s method (damped) on <span class="arithmatex">\(F_{t_k}\)</span>.  Stop when the Newton decrement satisfies  <span class="arithmatex">\(\lambda(x_{k+1})^2/2 \le \varepsilon\)</span></li>
<li>Optimality / stopping test:    If  <span class="arithmatex">\(\frac{m}{t_k} \le \varepsilon,\)</span>
  then <span class="arithmatex">\(x_{k+1}\)</span> is an <span class="arithmatex">\(\varepsilon\)</span>-approximate solution of the original constrained problem; stop and return <span class="arithmatex">\(x_{k+1}\)</span>.  </li>
<li>Increase barrier parameter:  <span class="arithmatex">\(t_{k+1} = \mu\, t_k,\)</span>   which tightens the approximation and moves closer to the boundary.  </li>
</ol>
</li>
<li>End.</li>
</ol>
<h3 id="interior-point-methods">Interior-point methods<a class="headerlink" href="#interior-point-methods" title="Permanent link">¶</a></h3>
<p>Interior-point methods combine barrier functions with Newton’s method to solve general convex programs:</p>
<ul>
<li>They maintain strict feasibility throughout.</li>
<li>Each iteration solves a Newton system for the barrier-augmented objective.</li>
<li>They naturally generate primal–dual pairs and duality gap estimates.</li>
<li>Under standard assumptions (e.g., Slater’s condition), they converge in a predictable number of iterations.</li>
</ul>
<p>Interior-point methods are the foundation of modern solvers for LP, QP, SOCP, and SDP. They are more expensive per iteration than first-order methods but converge in far fewer steps and achieve high accuracy.</p>
<h3 id="algorithm-primaldual-interior-point-method-for-convex-inequality-constraints">Algorithm: Primal–Dual Interior-Point Method (for convex inequality constraints)<a class="headerlink" href="#algorithm-primaldual-interior-point-method-for-convex-inequality-constraints" title="Permanent link">¶</a></h3>
<p>We consider the problem
<script type="math/tex; mode=display">
\min_x\; f(x) \quad \text{s.t. } g_i(x) \le 0,\; i=1,\dots,m.
</script>
</p>
<p>Introduce Lagrange multipliers <span class="arithmatex">\(\lambda \ge 0\)</span>. The KKT conditions are
<script type="math/tex; mode=display">
\begin{aligned}
\nabla f(x) + \sum_i \lambda_i \nabla g_i(x) &= 0, \\
g_i(x) &\le 0, \\
\lambda_i &\ge 0, \\
\lambda_i\, g_i(x) &= 0.
\end{aligned}
</script>
</p>
<p>Interior-point methods enforce the relaxed condition
<script type="math/tex; mode=display">
\lambda_i\, g_i(x) = -\frac{1}{t},
</script>
which keeps iterates strictly feasible.</p>
<h3 id="inputs">Inputs<a class="headerlink" href="#inputs" title="Permanent link">¶</a></h3>
<ul>
<li>objective <span class="arithmatex">\(f(x)\)</span>  </li>
<li>inequality constraints <span class="arithmatex">\(g_i(x)\)</span>  </li>
<li>initial primal point <span class="arithmatex">\(x_0\)</span> with <span class="arithmatex">\(g_i(x_0)&lt;0\)</span>  </li>
<li>initial dual variable <span class="arithmatex">\(\lambda_0 &gt; 0\)</span>  </li>
<li>initial barrier parameter <span class="arithmatex">\(t_0 &gt; 0\)</span>  </li>
<li>growth factor <span class="arithmatex">\(\mu &gt; 1\)</span>  </li>
<li>tolerance <span class="arithmatex">\(\varepsilon\)</span></li>
</ul>
<h3 id="procedure">Procedure<a class="headerlink" href="#procedure" title="Permanent link">¶</a></h3>
<ol>
<li>
<p>Choose strictly feasible <span class="arithmatex">\(x_0\)</span>, positive <span class="arithmatex">\(\lambda_0\)</span>, and <span class="arithmatex">\(t_0\)</span>.</p>
</li>
<li>
<p>For <span class="arithmatex">\(k = 0,1,2,\dots\)</span>:</p>
<p>(a) Form the perturbed KKT system.  Solve for the Newton direction <span class="arithmatex">\((\Delta x, \Delta \lambda)\)</span>:</p>
<p>
<script type="math/tex; mode=display">
   \begin{bmatrix}
   \nabla^2 f(x) + \sum_i \lambda_i \nabla^2 g_i(x) & \nabla g(x) \\
   \text{diag}(\lambda)\,\nabla g(x)^\top & \text{diag}(g(x))
   \end{bmatrix}
   \begin{bmatrix}
   \Delta x \\
   \Delta \lambda
   \end{bmatrix}
   =
   -
   \begin{bmatrix}
   \nabla f(x) + \sum_i \lambda_i \nabla g_i(x) \\
   \lambda \circ g(x) + \tfrac{1}{t}\mathbf{1}
   \end{bmatrix}.
   </script>
</p>
<p>(b) Line search to keep strict feasibility. Choose the maximum <span class="arithmatex">\(\alpha\in(0,1]\)</span> such that:</p>
<ul>
<li><span class="arithmatex">\(g_i(x + \alpha \Delta x) &lt; 0\)</span>,</li>
<li><span class="arithmatex">\(\lambda + \alpha \Delta \lambda &gt; 0\)</span>.</li>
</ul>
<p>(c) Update: <span class="arithmatex">\(x \leftarrow x + \alpha \Delta x,
   \qquad  \lambda \leftarrow \lambda + \alpha \Delta \lambda.\)</span></p>
<p>(d) Check duality gap: <span class="arithmatex">\(\text{gap} = - g(x)^\top \lambda\)</span> If <span class="arithmatex">\(\text{gap} \le \varepsilon\)</span>, stop.</p>
<p>(e) Increase barrier parameter <span class="arithmatex">\(t \leftarrow \mu t.\)</span></p>
</li>
<li>
<p>Return <span class="arithmatex">\(x\)</span>.</p>
</li>
</ol>
<h2 id="choosing-the-right-method-in-practice">Choosing the right method in practice<a class="headerlink" href="#choosing-the-right-method-in-practice" title="Permanent link">¶</a></h2>
<p>Case A. Smooth, unconstrained, very high dimensional.<br>
Example: logistic regression on millions of samples.<br>
Use: gradient descent or (better) accelerated gradient.<br>
Why: cheap iterations, easy to implement, scales.  </p>
<p>Case B. Smooth, unconstrained, moderate dimensional, need high accuracy.<br>
Example: convex nonlinear fitting with well-behaved Hessian.<br>
Use: Newton or quasi-Newton.<br>
Why: quadratic (or near-quadratic) convergence near optimum.  </p>
<p>Case C. Convex with simple feasible set <span class="arithmatex">\(x \in \mathcal{X}\)</span> (box, ball, simplex).<br>
Use: projected gradient.<br>
Why: projection is easy, maintains feasibility at each step.  </p>
<p>Case D. Composite objective <span class="arithmatex">\(f(x) + R(x)\)</span> where <span class="arithmatex">\(R\)</span> is nonsmooth (e.g. <span class="arithmatex">\(\ell_1\)</span>, indicator of a constraint set).<br>
Use: proximal gradient.<br>
Why: prox handles nonsmooth/constraint part exactly each step.  </p>
<p>Case E. General convex program with inequalities <span class="arithmatex">\(g_i(x)\le 0\)</span>.<br>
Use: interior-point methods.<br>
Why: they solve smooth barrier subproblems via Newton steps and give primal–dual certificates through KKT and duality (Chapters 7–8).  </p>
<h2 id="mental-map">Mental Map<a class="headerlink" href="#mental-map" title="Permanent link">¶</a></h2>
<div class="highlight"><pre><span></span><code>                Algorithms for Convex Optimization
     Turning convex geometry + optimality conditions into solvers
                              │
                              ▼
            Core question: how do we actually solve problems?
   Choose an algorithm class that matches problem structure + scale
                              │
                              ▼
     ┌────────────────────────────────────────────────────────────┐
     │ Problem Classes  →  Method Classes                         │
     │ Smooth unconstrained:        GD, Acceleration, Newton      │
     │ Smooth + simple constraints: Projected gradient            │
     │ Composite (smooth+nonsmooth): Proximal/coordinate/splitting│
     │ General constrained convex:  Interior-point / primal–dual  │
     └────────────────────────────────────────────────────────────┘
                              │
                              ▼
     ┌───────────────────────────────────────────────────────────┐
     │ First-Order Core: Gradient Descent                        │
     │ x_{k+1} = x_k − α_k ∇f(x_k)                               │
     │ Requirements: convex + L-smooth                           │
     │ - Step size from L or line search                         │
     │ - Rate (smooth convex): O(1/k)                            │
     │ Geometry: move opposite supporting hyperplane slope       
     └───────────────────────────────────────────────────────────┘
                              │
                              ▼
     ┌───────────────────────────────────────────────────────────┐
     │ Acceleration (Nesterov / Momentum)                        │
     │ Two sequences: gradient at y_k + extrapolation to y_{k+1} │
     │ - Rate (smooth convex): O(1/k^2)                          │
     │ - Best possible for gradient-only methods                 │
     │ Tradeoff: faster but more sensitive to tuning/noise       │
     └───────────────────────────────────────────────────────────┘
                              │
                              ▼
     ┌──────────────────────────────────────────────────────────────┐
     │ Nonsmooth First-Order: Subgradient Descent                   │
     │ x_{k+1} = x_k − α_k g_k,   g_k ∈ ∂f(x_k)                     │
     │ - Works for convex nonsmooth objectives                      │
     │ - Needs diminishing step sizes                               │
     │ - Worst-case rate: O(1/√k)                                   │
     │ Use when: only subgradients available / simple implementation│
     └──────────────────────────────────────────────────────────────┘
                              │
                              ▼
     ┌───────────────────────────────────────────────────────────┐
     │ Fixing Nonsmoothness: Proximal &amp; Smoothing                │
     │ Prox operator: prox_{αR}(y)=argmin_x R(x)+(1/2α)‖x−y‖²    │
     │ - Handles ℓ₁, indicators, TV, etc.                        │
     │ Smoothing: Huber / softplus / log-sum-exp                 │
     │ - Enables fast smooth methods                             │
     └───────────────────────────────────────────────────────────┘
                              │
                              ▼
     ┌─────────────────────────────────────────────────────────────┐
     │ Steepest Descent = Gradient Descent under a chosen norm     │
     │ Δx_nsd = argmin_{‖v‖=1} ∇f(x)ᵀv                             │
     │ - Dual norm controls gradient magnitude                     │
     │ - ℓ₂ → standard GD                                          │
     │ - Quadratic norm → preconditioned GD / Newton-like          │
     │ - ℓ₁ → coordinate-like steps                                │
     │ Purpose: change geometry to reduce anisotropy / improve rate│
     └─────────────────────────────────────────────────────────────┘
                              │
                              ▼
     ┌─────────────────────────────────────────────────────────────┐
     │ Quadratic Structure: Conjugate Gradient (CG)                │
     │ Solve: ½xᵀAx − bᵀx, A≻0  (equivalently Ax=b)                │
     │ - Builds A-conjugate directions (Hessian-orthogonal)        │
     │ - Uses only matrix–vector products Ap                       │
     │ - Converges in ≤ n steps (exact arithmetic)                 │
     │ - Practical iterations ~ O(√κ) with κ=λ_max/λ_min           │
     │ - Preconditioning is key for speed                          │
     └─────────────────────────────────────────────────────────────┘
                              │
                              ▼
     ┌─────────────────────────────────────────────────────────────┐
     │ Second-Order Methods: Newton &amp; Variants                     │
     │ Newton step:  ∇²f(x_k) d = −∇f(x_k)                         │
     │ - Quadratic local model → fast local convergence            │
     │ - Needs line search / trust region for robustness           │
     │ Gauss–Newton / Levenberg–Marquardt: least-squares structure │
     │ Quasi-Newton (BFGS/L-BFGS): Hessian inverse approximations  │
     │ Use when: moderate dimension or efficient linear solves     │
     └───────────────────────────────────────────────────────────┘
                              │
                              ▼
     ┌──────────────────────────────────────────────────────────────┐
     │ Handling Constraints: Projection &amp; Proximal Splitting        │
     │ Projected GD:  y=x−α∇f(x);  x⁺=Π_X(y)                        │
     │ Proximal gradient: y=x−α∇f(x); x⁺=prox_{αR}(y)               │
     │ Unification: indicator_R(X) ⇒ prox = projection              │
     │ Use when: constraints/regularizers have cheap prox/project   │
     └──────────────────────────────────────────────────────────────┘
                              │
                              ▼
     ┌─────────────────────────────────────────────────────────────┐
     │ General Inequalities: Penalties → Barriers → Interior-Point │
     │ Penalty: f(x)+ρ Σ φ(g_i(x))                                 │
     │ Barrier: tf(x) − Σ log(−g_i(x))  (strict feasibility)       │
     │ Interior-point: Newton steps on (primal–dual) perturbed KKT │
     │ - Few iterations, high accuracy, solver backbone for LP/QP  │
     │ - Uses duality gap certificates                             │
     └─────────────────────────────────────────────────────────────┘
                              │
                              ▼
                 Practical selection (the decision logic)
     ┌─────────────────────────────────────────────────────────────┐
     │ Huge-scale smooth → GD / accelerated / L-BFGS               │
     │ Moderate smooth, high accuracy → Newton / quasi-Newton      │
     │ Simple constraints → projected gradient                     │
     │ Smooth + nonsmooth regularizer → proximal gradient / FISTA  │
     │ General constraints → interior-point / primal–dual          │
     │ Quadratic / SPD linear systems → CG (+ preconditioning)     │
     └─────────────────────────────────────────────────────────────┘
</code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer">
        
          
          <a href="../18b_regularization/" class="md-footer__link md-footer__link--prev" aria-label="Previous: 11. Regularized Approximation – Balancing Fit and Complexity">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                11. Regularized Approximation – Balancing Fit and Complexity
              </div>
            </div>
          </a>
        
        
          
          <a href="../19a_optimization_constraints/" class="md-footer__link md-footer__link--next" aria-label="Next: 13. Optimization Algorithms for Equality-Constrained Problems">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                13. Optimization Algorithms for Equality-Constrained Problems
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      © 2025 Salman Khan — Educational Use Only
    </div>
  
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/SalK91/convex_optimization" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "navigation.indexes", "navigation.path", "navigation.top", "navigation.footer", "toc.follow", "content.code.copy", "content.action.edit", "content.action.view", "search.suggest", "search.highlight"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../../js/print-site.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>