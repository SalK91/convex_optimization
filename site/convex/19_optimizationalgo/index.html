<!DOCTYPE html><html lang="en" class="no-js"><head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Structured lecture notes on optimization, convex analysis, and algorithms.">
      
      
        <meta name="author" content="Salman Khan">
      
      
        <link rel="canonical" href="https://salk91.github.io/convex_optimization/convex/19_optimizationalgo/">
      
      
        <link rel="prev" href="../18b_regularization/">
      
      
        <link rel="next" href="../19a_optimization_constraints/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>12. Algorithms for Convex Optimization - Mathematics for Machine Learning</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.e53b48f4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Merriweather:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&amp;display=fallback">
        <style>:root{--md-text-font:"Merriweather";--md-code-font:"Fira Code"}</style>
      
    
    
      <link rel="stylesheet" href="../../styles/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"><script src="../../assets/javascripts/glightbox.min.js"></script><style id="glightbox-style">
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="cyan">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#chapter-12-algorithms-for-convex-optimization" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Mathematics for Machine Learning" class="md-header__button md-logo" aria-label="Mathematics for Machine Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Mathematics for Machine Learning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              12. Algorithms for Convex Optimization
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="cyan" aria-label="Switch to light mode" type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="cyan" aria-label="Switch to dark mode" type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m3.55 19.09 1.41 1.41 1.8-1.79-1.42-1.42M12 6c-3.31 0-6 2.69-6 6s2.69 6 6 6 6-2.69 6-6c0-3.32-2.69-6-6-6m8 7h3v-2h-3m-2.76 7.71 1.8 1.79 1.41-1.41-1.79-1.8M20.45 5l-1.41-1.4-1.8 1.79 1.42 1.42M13 1h-2v3h2M6.76 5.39 4.96 3.6 3.55 5l1.79 1.81zM1 13h3v-2H1m12 9h-2v3h2"></path></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/SalK91/convex_optimization" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Mathematics for Machine Learning" class="md-nav__button md-logo" aria-label="Mathematics for Machine Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    Mathematics for Machine Learning
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/SalK91/convex_optimization" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Convex Optimization
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Convex Optimization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../11_intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. Introduction and Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../12_vector/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. Linear Algebra Foundations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../13_calculus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. Multivariable Calculus for Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../14_convexsets/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Convex Sets and Geometric Fundamentals
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15_convexfunctions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. Convex Functions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../16_subgradients/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. Nonsmooth Convex Optimization – Subgradients
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../16a_optimality_conditions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. First-Order Optimality Conditions in Convex Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../17_kkt/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8. Optimization Principles – From Gradient Descent to KKT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18_duality/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9. Lagrange Duality Theory
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18a_pareto/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10. Pareto Optimality and Multi-Objective Convex Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18b_regularization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11. Regularized Approximation – Balancing Fit and Complexity
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    12. Algorithms for Convex Optimization
    
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../19a_optimization_constraints/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    13. Optimization Algorithms for Equality-Constrained Problems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../19b_optimization_constraints/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    14. Optimization Algorithms for Inequality-Constrained Problems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../20_advanced/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    15. Advanced Large-Scale and Structured Methods
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../21_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    16. Modelling Patterns and Algorithm Selection in Practice
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../30_canonical_problems/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    17. Canonical Problems in Convex Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3">
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Optimization Beyond Convexity
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Optimization Beyond Convexity
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nonconvex/41_intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nonconvex/42_meta/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. Metaheuristic Optimization Methods
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nonconvex/43_hybrid/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. Hybrid and Modern Optimization Methods
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4">
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Cheat Sheets
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Cheat Sheets
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cheatsheets/20a_cheatsheet/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Optimization Algos - Cheat Sheet
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5">
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Appendices
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Appendices
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../appendices/120_ineqaulities/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Appendix A - Common Inequalities and Identities
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../appendices/130_projections/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Appendix B - Projection and Proximal Operators
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../appendices/140_support/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Appendix C - Support Functions and Dual Geometry (Advanced)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../appendices/160_conjugates/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Appendix D - Convex Conjugates and Fenchel Duality (Advanced)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../appendices/170_probability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Appendix E - Convexity in Probability and Statistics (Advanced)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../appendices/180_subgradient_methods/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Appendix F - Subgradient Method and Variants (Advanced)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../appendices/190_proximal/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Appendix G - Proximal Operators
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../appendices/200_mirror/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Appendix H - Mirror Descent and Bregman Geometry
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../appendices/300_matrixfactorization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Appendix I - Matrix Factorization
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/SalK91/convex_optimization/edit/master/docs/convex/19_optimizationalgo.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/SalK91/convex_optimization/raw/master/docs/convex/19_optimizationalgo.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg>
    </a>
  


<h1 id="chapter-12-algorithms-for-convex-optimization">Chapter 12: Algorithms for Convex Optimization<a class="headerlink" href="#chapter-12-algorithms-for-convex-optimization" title="Permanent link">¶</a></h1>
<p>In Chapters 2–8 we built the mathematics of convex optimization: linear algebra (Chapter 2), gradients and Hessians (Chapter 3), convex sets (Chapter 4), convex functions (Chapter 5), subgradients (Chapter 6), KKT conditions (Chapter 7), and duality (Chapter 8). </p>
<p>Now we answer the practical question:</p>
<p>How do we actually solve convex optimization problems in practice?</p>
<p>This chapter develops the major algorithmic families used to solve convex problems. Our goal is not only to describe each method, but to explain:</p>
<ul>
<li>what class of problem it solves,</li>
<li>what information it needs (gradient, Hessian, projection, etc.),</li>
<li>when you should use it,</li>
<li>how it connects to the modelling choices you make.</li>
</ul>
<h2 id="91-problem-classes-vs-method-classes">9.1 Problem classes vs method classes<a class="headerlink" href="#91-problem-classes-vs-method-classes" title="Permanent link">¶</a></h2>
<p>Before we dive into algorithms, we need a map. Different algorithms are natural for different convex problem structures.</p>
<h3 id="911-smooth-unconstrained-convex-minimisation">9.1.1 Smooth unconstrained convex minimisation<a class="headerlink" href="#911-smooth-unconstrained-convex-minimisation" title="Permanent link">¶</a></h3>
<p>We want
<script type="math/tex; mode=display">
\min_x f(x),
</script>
where <span class="arithmatex">\(f:\mathbb{R}^n \to \mathbb{R}\)</span> is convex and differentiable.</p>
<p>Typical methods:</p>
<ul>
<li>Gradient descent (first-order),</li>
<li>Accelerated gradient,</li>
<li>Newton / quasi-Newton (second-order).</li>
</ul>
<p>Information required:</p>
<ul>
<li><span class="arithmatex">\(\nabla f(x)\)</span>, sometimes <span class="arithmatex">\(\nabla^2 f(x)\)</span>.</li>
</ul>
<h3 id="912-smooth-convex-minimisation-with-simple-constraints">9.1.2 Smooth convex minimisation with simple constraints<a class="headerlink" href="#912-smooth-convex-minimisation-with-simple-constraints" title="Permanent link">¶</a></h3>
<p>We want
<script type="math/tex; mode=display">
\min_x f(x)
\quad \text{s.t.} \quad x \in \mathcal{X},
</script>
where <span class="arithmatex">\(\mathcal{X}\)</span> is a “simple” closed convex set such as a box, a norm ball, or a simplex (Chapter 4).</p>
<h4 id="practical-examples-of-simple-constraints">Practical Examples of Simple Constraints<a class="headerlink" href="#practical-examples-of-simple-constraints" title="Permanent link">¶</a></h4>
<table>
<thead>
<tr>
<th>Constraint Type</th>
<th>Explanation</th>
<th>Example</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>Box</td>
<td>Each variable is bounded independently within lower and upper limits.</td>
<td><span class="arithmatex">\( 0 \le x_i \le 1 \)</span></td>
<td>Parameters are restricted to a fixed range (e.g., pixel intensities, control limits).</td>
</tr>
<tr>
<td>Norm Ball</td>
<td>All feasible points lie within a fixed radius from a center under some norm.</td>
<td><span class="arithmatex">\( \|x - x_0\|_2 \le 1 \)</span></td>
<td>Keeps the solution close to a reference point — controls total magnitude or deviation.</td>
</tr>
<tr>
<td>Simplex</td>
<td>Nonnegative variables that sum to one.</td>
<td><span class="arithmatex">\( x_i \ge 0,\ \sum_i x_i = 1 \)</span></td>
<td>Represents valid probability distributions or normalized weights (e.g., portfolio allocations).</td>
</tr>
</tbody>
</table>
<p>Typical method:</p>
<ul>
<li>Projected gradient descent, which alternates a gradient step and Euclidean projection back to <span class="arithmatex">\(\mathcal{X}\)</span>.</li>
</ul>
<p>Information required:</p>
<ul>
<li><span class="arithmatex">\(\nabla f(x)\)</span>,</li>
<li>the ability to compute <span class="arithmatex">\(\Pi_\mathcal{X}(y) = \arg\min_{x \in \mathcal{X}} \|x-y\|_2^2\)</span> efficiently.</li>
</ul>
<h3 id="913-composite-convex-minimisation-smooth-nonsmooth">9.1.3 Composite convex minimisation (smooth + nonsmooth)<a class="headerlink" href="#913-composite-convex-minimisation-smooth-nonsmooth" title="Permanent link">¶</a></h3>
<p>We want
<script type="math/tex; mode=display">
\min_x \; F(x) := f(x) + R(x),
</script>
where <span class="arithmatex">\(f\)</span> is convex and differentiable with Lipschitz gradient, and <span class="arithmatex">\(R\)</span> is convex but possibly nonsmooth (Chapter 6).<br>
Examples:</p>
<ul>
<li><span class="arithmatex">\(f(x)=\|Ax-b\|_2^2\)</span>, <span class="arithmatex">\(R(x)=\lambda\|x\|_1\)</span> (LASSO),</li>
<li><span class="arithmatex">\(R(x)\)</span> is the indicator of a convex set, enforcing a hard constraint.</li>
</ul>
<p>Typical method:</p>
<ul>
<li>Proximal gradient / forward–backward splitting,</li>
<li>Projected gradient as a special case.</li>
</ul>
<p>Information required:</p>
<ul>
<li><span class="arithmatex">\(\nabla f(x)\)</span>,</li>
<li>the proximal operator of <span class="arithmatex">\(R\)</span>.</li>
</ul>
<h3 id="914-general-convex-programs-with-inequality-constraints">9.1.4 General convex programs with inequality constraints<a class="headerlink" href="#914-general-convex-programs-with-inequality-constraints" title="Permanent link">¶</a></h3>
<p>We want
<script type="math/tex; mode=display">
\begin{array}{ll}
\text{minimise} & f(x) \\
\text{subject to} & g_i(x) \le 0,\quad i=1,\dots,m, \\
& h_j(x) = 0,\quad j=1,\dots,p,
\end{array}
</script>
where <span class="arithmatex">\(f\)</span> and <span class="arithmatex">\(g_i\)</span> are convex, <span class="arithmatex">\(h_j\)</span> are affine.  </p>
<p>Typical method:</p>
<ul>
<li>Interior-point (barrier) methods.</li>
</ul>
<p>Information required:</p>
<ul>
<li>Gradients and Hessians of the barrier-augmented objective,</li>
<li>ability to solve linear systems arising from Newton steps.</li>
</ul>
<h3 id="915-the-moral">9.1.5 The moral<a class="headerlink" href="#915-the-moral" title="Permanent link">¶</a></h3>
<p>There is no single “best” algorithm.<br>
There is a best algorithm for the structure you have.</p>
<ul>
<li>First-order methods scale to huge problems but converge relatively slowly.</li>
<li>Newton and interior-point methods converge extremely fast in iterations but each iteration is more expensive (they solve linear systems involving Hessians).</li>
<li>Proximal methods are designed for nonsmooth regularisers and constraints that appear everywhere in statistics and machine learning.</li>
<li>Interior-point methods are the workhorse for general convex programs (including linear programs, quadratic programs, conic programs) and deliver high-accuracy solutions with strong certificates of optimality </li>
</ul>
<h2 id="92-first-order-methods-gradient-descent">9.2 First-order methods: Gradient descent<a class="headerlink" href="#92-first-order-methods-gradient-descent" title="Permanent link">¶</a></h2>
<h3 id="921-setting">9.2.1 Setting<a class="headerlink" href="#921-setting" title="Permanent link">¶</a></h3>
<p>We solve
<script type="math/tex; mode=display">
\min_x f(x),
</script>
where <span class="arithmatex">\(f\)</span> is convex, differentiable, and (ideally) <span class="arithmatex">\(L\)</span>-smooth: its gradient is Lipschitz with constant <span class="arithmatex">\(L\)</span>, meaning
<script type="math/tex; mode=display">
\|\nabla f(x) - \nabla f(y)\|_2 \le L \|x-y\|_2 \quad \text{for all } x,y.
</script>
Smoothness lets us control step sizes.</p>
<h3 id="922-algorithm">9.2.2 Algorithm<a class="headerlink" href="#922-algorithm" title="Permanent link">¶</a></h3>
<p>Gradient descent iterates
<script type="math/tex; mode=display">
x_{k+1} = x_k - \alpha_k \nabla f(x_k),
</script>
where <span class="arithmatex">\(\alpha_k&gt;0\)</span> is the step size (also called learning rate in machine learning). A common choice is a constant <span class="arithmatex">\(\alpha_k = 1/L\)</span> when <span class="arithmatex">\(L\)</span> is known, or a backtracking line search when it is not.</p>
<blockquote>
<p>Derivation: Around <span class="arithmatex">\(x_t\)</span>, we approximate <span class="arithmatex">\(f\)</span> using its Taylor expansion:</p>
<div class="arithmatex">\[
f(x) \approx f(x_t) + \langle \nabla f(x_t), x - x_t \rangle.
\]</div>
<ul>
<li>We assume <span class="arithmatex">\(f\)</span> behaves approximately like its tangent plane near <span class="arithmatex">\(x_t\)</span>.  </li>
<li>If we were to minimize just this linear model, we would move infinitely far in the direction of steepest descent <span class="arithmatex">\(-\nabla f(x_t)\)</span>, which is not realistic or stable.</li>
</ul>
<p>This motivates adding a locality restriction — we trust the linear approximation near <span class="arithmatex">\(x_t\)</span>, not globally. To prevent taking arbitrarily large steps, we add a quadratic penalty for moving away from <span class="arithmatex">\(x_t\)</span>:</p>
<div class="arithmatex">\[
f(x) \approx f(x_t) + \langle \nabla f(x_t), x - x_t \rangle + \frac{1}{2\eta} \|x - x_t\|^2,
\]</div>
<p>where <span class="arithmatex">\(\eta &gt; 0\)</span> is the learning rate or step size.</p>
<ul>
<li>The linear term pulls <span class="arithmatex">\(x\)</span> in the steepest descent direction.</li>
<li>The quadratic term acts like a trust region, discouraging large deviations from <span class="arithmatex">\(x_t\)</span>.</li>
<li><span class="arithmatex">\(\eta\)</span> trades off aggressive progress vs stability:<ul>
<li>Small <span class="arithmatex">\(\eta\)</span> → cautious updates.</li>
<li>Large <span class="arithmatex">\(\eta\)</span> → bold updates (risk of divergence).</li>
</ul>
</li>
</ul>
<p>We define the next iterate as the minimizer of the surrogate objective:</p>
<div class="arithmatex">\[
x_{t+1} = \arg\min_{x \in \mathcal{X}} \Big[ f(x_t) + \langle \nabla f(x_t), x - x_t \rangle + \frac{1}{2\eta} \|x - x_t\|^2 \Big].
\]</div>
<p>Ignoring the constant term <span class="arithmatex">\(f(x_t)\)</span> and differentiating w.r.t. <span class="arithmatex">\(x\)</span>:</p>
<div class="arithmatex">\[
\nabla f(x_t) + \frac{1}{\eta}(x - x_t) = 0
\]</div>
<p>Solving:</p>
<div class="arithmatex">\[
x_{t+1} = x_t - \eta \nabla f(x_t)
\]</div>
</blockquote>
<h3 id="923-geometric-meaning">9.2.3 Geometric meaning<a class="headerlink" href="#923-geometric-meaning" title="Permanent link">¶</a></h3>
<p>From Chapter 3, the first-order Taylor model is
<script type="math/tex; mode=display">
f(x + d) \approx f(x) + \nabla f(x)^\top d.
</script>
This is minimised (under a step length constraint) by taking <span class="arithmatex">\(d\)</span> in the direction <span class="arithmatex">\(-\nabla f(x)\)</span>. So gradient descent is just “take a cautious step downhill”.</p>
<h3 id="924-convergence">9.2.4 Convergence<a class="headerlink" href="#924-convergence" title="Permanent link">¶</a></h3>
<p>For convex, <span class="arithmatex">\(L\)</span>-smooth <span class="arithmatex">\(f\)</span>, gradient descent with a suitable fixed step size satisfies
<script type="math/tex; mode=display">
f(x_k) - f^\star = O\!\left(\frac{1}{k}\right),
</script>
where <span class="arithmatex">\(f^\star\)</span> is the global minimum. This <span class="arithmatex">\(O(1/k)\)</span> sublinear rate is slow compared to second-order methods, but each step is extremely cheap: you only need <span class="arithmatex">\(\nabla f(x_k)\)</span>.</p>
<h3 id="925-when-to-use-gradient-descent">9.2.5 When to use gradient descent<a class="headerlink" href="#925-when-to-use-gradient-descent" title="Permanent link">¶</a></h3>
<ul>
<li>Problems with millions of variables (large-scale ML).</li>
<li>You can afford many cheap iterations.</li>
<li>You only have access to gradients (or stochastic gradients).</li>
<li>You do not need very high precision.</li>
</ul>
<p>Gradient descent is the baseline first-order method. But we can do better.</p>
<h2 id="93-accelerated-first-order-methods">9.3 Accelerated first-order methods<a class="headerlink" href="#93-accelerated-first-order-methods" title="Permanent link">¶</a></h2>
<p>Plain gradient descent has an <span class="arithmatex">\(O(1/k)\)</span> rate for smooth convex problems. Remarkably, we can do better — and in fact, provably optimal — by adding <em>momentum</em>.</p>
<h3 id="931-nesterov-acceleration">9.3.1 Nesterov acceleration<a class="headerlink" href="#931-nesterov-acceleration" title="Permanent link">¶</a></h3>
<p>Nesterov’s accelerated gradient method modifies the update using a momentum-like extrapolation. One common presentation is:</p>
<ol>
<li>Maintain two sequences <span class="arithmatex">\(x_k\)</span> and <span class="arithmatex">\(y_k\)</span>.</li>
<li>Take a gradient step from <span class="arithmatex">\(y_k\)</span>:
   <script type="math/tex; mode=display">
   x_{k+1} = y_k - \alpha \nabla f(y_k).
   </script>
</li>
<li>Extrapolate:
   <script type="math/tex; mode=display">
   y_{k+1} = x_{k+1} + \beta_k (x_{k+1} - x_k).
   </script>
</li>
</ol>
<p>The extra <span class="arithmatex">\(\beta_k\)</span> term “looks ahead,” helping the method exploit curvature better than plain gradient descent.</p>
<h3 id="932-optimal-first-order-rate">9.3.2 Optimal first-order rate<a class="headerlink" href="#932-optimal-first-order-rate" title="Permanent link">¶</a></h3>
<p>For smooth convex <span class="arithmatex">\(f\)</span>, accelerated gradient achieves
<script type="math/tex; mode=display">
f(x_k) - f^\star = O\!\left(\frac{1}{k^2}\right),
</script>
which is <em>optimal</em> for any algorithm that uses only gradient information and not higher derivatives. In other words, you cannot beat <span class="arithmatex">\(O(1/k^2)\)</span> in the worst case using only first-order oracle calls.</p>
<h3 id="933-when-to-use-acceleration">9.3.3 When to use acceleration<a class="headerlink" href="#933-when-to-use-acceleration" title="Permanent link">¶</a></h3>
<ul>
<li>Same setting as gradient descent (large-scale smooth convex problems),</li>
<li>but you want to converge in fewer iterations.</li>
<li>You can tolerate a little more instability/parameter tuning (acceleration can overshoot if step sizes are not chosen carefully).</li>
</ul>
<p>Acceleration is the default upgrade from vanilla gradient descent in many smooth convex machine learning problems.</p>
<p>The convergence of gradient descent depends strongly on the geometry of the level sets of the objective function. When these level sets are poorly conditioned—that is, highly anisotropic or elongated (not spherical)—the gradient directions tend to oscillate across narrow valleys, leading to zig-zag behavior and slow convergence.</p>
<p>In contrast, when the level sets are well-conditioned (approximately spherical), gradient descent progresses efficiently toward the minimum. Thus, the efficiency of gradient-based methods is governed by how aspherical (anisotropic) the level sets are, which is directly related to the condition number of the Hessian.</p>
<h2 id="94-steepest-descent-method">9.4 Steepest Descent Method<a class="headerlink" href="#94-steepest-descent-method" title="Permanent link">¶</a></h2>
<p>The steepest descent method generalizes gradient descent by depending on the choice of norm used to measure step size or direction. It finds the direction of <em>maximum decrease</em> of the objective function under a unit norm constraint.</p>
<blockquote>
<p>The norm defines the “geometry” of optimization.
Gradient descent is steepest descent under the Euclidean norm.
Changing the norm changes what “steepest” means, and can greatly affect convergence, especially for ill-conditioned or anisotropic problems.</p>
</blockquote>
<p>At a point <span class="arithmatex">\(x\)</span>, and for a chosen norm <span class="arithmatex">\(|\cdot|\)</span>:</p>
<div class="arithmatex">\[
\Delta x_{\text{nsd}} = \arg\min_{|v| = 1} \nabla f(x)^T v
\]</div>
<p>This defines the normalized steepest descent direction — the unit-norm direction that yields the most negative directional derivative (i.e., the steepest local decrease of <span class="arithmatex">\(f\)</span>).</p>
<ul>
<li><span class="arithmatex">\(\Delta x_{\text{nsd}}\)</span>: normalized steepest descent direction</li>
<li><span class="arithmatex">\(\Delta x_{\text{sd}}\)</span>: unnormalized direction (scaled by the gradient norm)</li>
</ul>
<p>For small steps <span class="arithmatex">\(v\)</span>,
<script type="math/tex; mode=display">
f(x + v) \approx f(x) + \nabla f(x)^T v.
</script>
The term <span class="arithmatex">\(\nabla f(x)^T v\)</span> describes how fast <span class="arithmatex">\(f\)</span> increases in direction <span class="arithmatex">\(v\)</span>.
To decrease <span class="arithmatex">\(f\)</span> most rapidly, we pick <span class="arithmatex">\(v\)</span> that minimizes this inner product — subject to <span class="arithmatex">\(|v| = 1\)</span>.</p>
<ul>
<li>The result depends on which norm we use to measure the “size” of <span class="arithmatex">\(v\)</span>.</li>
<li>The corresponding dual norm <span class="arithmatex">\(|\cdot|_*\)</span> determines how we measure the gradient’s magnitude.</li>
</ul>
<p>Thus, the steepest descent direction always aligns with the negative gradient, but it is scaled and shaped according to the geometry induced by the chosen norm.</p>
<h2 id="941-mathematical-properties">9.4.1. Mathematical Properties<a class="headerlink" href="#941-mathematical-properties" title="Permanent link">¶</a></h2>
<h3 id="a-normalized-direction">(a) Normalized direction<a class="headerlink" href="#a-normalized-direction" title="Permanent link">¶</a></h3>
<p>
<script type="math/tex; mode=display">
\Delta x_{\text{nsd}} = \arg\min_{|v|=1} \nabla f(x)^T v
</script>
→ unit vector with the most negative directional derivative.</p>
<h3 id="b-unnormalized-direction">(b) Unnormalized direction<a class="headerlink" href="#b-unnormalized-direction" title="Permanent link">¶</a></h3>
<p>
<script type="math/tex; mode=display">
\Delta x_{\text{sd}} = |\nabla f(x)| , \Delta x*{\text{nsd}}
</script>
This gives the actual direction and magnitude used in updates.</p>
<h3 id="c-key-identity">(c) Key identity<a class="headerlink" href="#c-key-identity" title="Permanent link">¶</a></h3>
<p>
<script type="math/tex; mode=display">
\nabla f(x)^T \Delta x_{\text{sd}} = -|\nabla f(x)|_*^2
</script>
The directional derivative equals the negative squared dual norm of the gradient.</p>
<h3 id="942-the-steepest-descent-method">9.4.2. The Steepest Descent Method<a class="headerlink" href="#942-the-steepest-descent-method" title="Permanent link">¶</a></h3>
<p>The iterative update rule is:
<script type="math/tex; mode=display">
x_{k+1} = x_k + t_k , \Delta x_{\text{sd}},
</script>
where <span class="arithmatex">\(t_k &gt; 0\)</span> is a step size (from line search or a fixed rule).</p>
<ul>
<li>For the Euclidean norm, this reduces to ordinary gradient descent.</li>
<li>For other norms, it adapts the search direction to the geometry of the problem.</li>
</ul>
<p>Convergence: Similar to gradient descent — linear for general convex functions, potentially faster when level sets are well-conditioned.</p>
<h3 id="943-role-of-the-norm-and-its-influence">9.4.3. Role of the Norm and Its Influence<a class="headerlink" href="#943-role-of-the-norm-and-its-influence" title="Permanent link">¶</a></h3>
<p>The choice of norm determines:</p>
<ol>
<li>The shape of the unit ball <span class="arithmatex">\({v : |v| \le 1}\)</span>,</li>
<li>The direction of steepest descent, since the minimization is constrained by that shape,</li>
<li>The dual norm <span class="arithmatex">\(|\nabla f(x)|_*\)</span> that measures the gradient’s size.</li>
</ol>
<p>Different norms yield different “geometries” of descent:</p>
<table>
<thead>
<tr>
<th>Norm</th>
<th>Unit Ball Shape</th>
<th>Dual Norm</th>
<th>Effect on Direction</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="arithmatex">\(\ell_2\)</span></td>
<td>Circle / sphere</td>
<td><span class="arithmatex">\(\ell_2\)</span></td>
<td>Direction is opposite to gradient</td>
</tr>
<tr>
<td><span class="arithmatex">\(\ell_1\)</span></td>
<td>Diamond</td>
<td><span class="arithmatex">\(\ell_\infty\)</span></td>
<td>Moves along coordinate of largest gradient</td>
</tr>
<tr>
<td><span class="arithmatex">\(\ell_\infty\)</span></td>
<td>Square</td>
<td><span class="arithmatex">\(\ell_1\)</span></td>
<td>Moves opposite to sum of all gradient signs</td>
</tr>
<tr>
<td>Quadratic <span class="arithmatex">\((x^T P x)^{1/2}\)</span></td>
<td>Ellipsoid</td>
<td>Weighted <span class="arithmatex">\(\ell_2\)</span></td>
<td>Scales direction by preconditioner <span class="arithmatex">\(P^{-1}\)</span></td>
</tr>
</tbody>
</table>
<p>Thus, the norm defines how “distance” and “steepness” are perceived, shaping how the algorithm moves through the landscape of <span class="arithmatex">\(f(x)\)</span>.</p>
<h3 id="a-euclidean-norm-v_2">(a) Euclidean Norm <span class="arithmatex">\(|v|_2\)</span><a class="headerlink" href="#a-euclidean-norm-v_2" title="Permanent link">¶</a></h3>
<div class="arithmatex">\[
\Delta x_{\text{nsd}} = -\frac{\nabla f(x)}{|\nabla f(x)|*2},
\quad
\Delta x*{\text{sd}} = -\nabla f(x)
\]</div>
<p>This is standard gradient descent.
The direction is exactly opposite the gradient, and steps are isotropic (same scaling in all directions).</p>
<h3 id="b-quadratic-norm-v_p-vt-p-v12-with-p-succ-0">(b) Quadratic Norm <span class="arithmatex">\(|v|_P = (v^T P v)^{1/2}\)</span>, with <span class="arithmatex">\(P \succ 0\)</span><a class="headerlink" href="#b-quadratic-norm-v_p-vt-p-v12-with-p-succ-0" title="Permanent link">¶</a></h3>
<p>Here, <span class="arithmatex">\(P\)</span> defines an ellipsoidal metric.
The dual norm is <span class="arithmatex">\(|y|_* = (y^T P^{-1} y)^{1/2}\)</span>.</p>
<div class="arithmatex">\[
\Delta x_{\text{sd}} = -P^{-1}\nabla f(x)
\]</div>
<p>This corresponds to preconditioned gradient descent, where <span class="arithmatex">\(P\)</span> rescales directions to counter anisotropy in level sets.</p>
<p>Interpretation:</p>
<ul>
<li>If <span class="arithmatex">\(P\)</span> approximates the Hessian, this becomes Newton’s method.</li>
<li>If <span class="arithmatex">\(P\)</span> is diagonal, it acts like an adaptive step size per coordinate.</li>
</ul>
<h3 id="c-ell_1-norm">(c) <span class="arithmatex">\(\ell_1\)</span>-Norm<a class="headerlink" href="#c-ell_1-norm" title="Permanent link">¶</a></h3>
<div class="arithmatex">\[
\Delta x_{\text{nsd}} = -e_i, \quad i = \arg\max_j \left|\frac{\partial f}{\partial x_j}\right|
$$
and
$$
\Delta x_{\text{sd}} = -|\nabla f(x)|_\infty e_i
\]</div>
<p>The step moves along the coordinate with the largest gradient component, resembling a coordinate descent update.</p>
<p>Geometric intuition:
The <span class="arithmatex">\(\ell_1\)</span>-unit ball is a diamond; its corners align with coordinate axes, so the steepest direction is along one axis at a time.</p>
<ul>
<li>In <span class="arithmatex">\(\ell_2\)</span>-norm: the unit ball is a circle → the steepest direction is exactly opposite the gradient.</li>
<li>In <span class="arithmatex">\(\ell_1\)</span>-norm: the unit ball is a diamond → the steepest direction points to a corner (one coordinate).</li>
<li>In quadratic norms: the unit ball is an ellipsoid → the steepest direction follows the metric-adjusted gradient.</li>
</ul>
<p>Hence, the norm defines the geometry of what “steepest” means.</p>
<h2 id="95-newtons-method-and-second-order-methods">9.5 Newton’s method and second-order methods<a class="headerlink" href="#95-newtons-method-and-second-order-methods" title="Permanent link">¶</a></h2>
<p>First-order methods (like gradient descent) only use gradient information. Newton’s method, in contrast, incorporates curvature information from the Hessian to take steps that better adapt to the local geometry of the function. This often leads to much faster convergence near the optimum.</p>
<h3 id="951-local-quadratic-model">9.5.1 Local quadratic model<a class="headerlink" href="#951-local-quadratic-model" title="Permanent link">¶</a></h3>
<p>From Chapter 3, the second-order Taylor approximation of <span class="arithmatex">\(f(x)\)</span> around a point <span class="arithmatex">\(x_k\)</span> is:</p>
<div class="arithmatex">\[
f(x_k + d)
\approx
f(x_k)
+ \nabla f(x_k)^\top d
+ \tfrac{1}{2} d^\top \nabla^2 f(x_k) d.
\]</div>
<p>If we temporarily trust this quadratic model, we can choose <span class="arithmatex">\(d\)</span> to minimize the right-hand side.<br>
Differentiating with respect to <span class="arithmatex">\(d\)</span> and setting to zero gives:</p>
<div class="arithmatex">\[
\nabla^2 f(x_k) \, d_{\text{newton}} = - \nabla f(x_k).
\]</div>
<p>Hence, the Newton step is:</p>
<div class="arithmatex">\[
d_{\text{newton}} = - [\nabla^2 f(x_k)]^{-1} \nabla f(x_k),
\quad
x_{k+1} = x_k + d_{\text{newton}}.
\]</div>
<p>This step points toward the minimizer of the local quadratic model, and near the true minimizer, Newton’s method exhibits quadratic convergence.</p>
<h3 id="952-convergence-behaviour">9.5.2 Convergence behaviour<a class="headerlink" href="#952-convergence-behaviour" title="Permanent link">¶</a></h3>
<ul>
<li>Near the minimiser of a strictly convex, twice-differentiable <span class="arithmatex">\(f\)</span>, Newton’s method converges quadratically: roughly, the number of correct digits doubles every iteration.  </li>
<li>This is dramatically faster than the <span class="arithmatex">\(O(1/k)\)</span> or <span class="arithmatex">\(O(1/k^2)\)</span> rates typical of first-order methods — but only once the iterates enter the basin of attraction.  </li>
<li>Far from the minimiser, Newton’s method can behave erratically or even diverge.<br>
  To stabilise it, we typically pair it with a line search or trust region strategy to control step size.</li>
</ul>
<h3 id="953-implementation">9.5.3 Implementation<a class="headerlink" href="#953-implementation" title="Permanent link">¶</a></h3>
<p>The main computational effort in each iteration lies in evaluating derivatives and solving the Newton system:</p>
<div class="arithmatex">\[
H \, \Delta x = -g,
\]</div>
<p>where</p>
<div class="arithmatex">\[
H = \nabla^2 f(x), \quad g = \nabla f(x).
\]</div>
<h4 id="solving-via-cholesky-factorization">Solving via Cholesky factorization<a class="headerlink" href="#solving-via-cholesky-factorization" title="Permanent link">¶</a></h4>
<p>If <span class="arithmatex">\(H\)</span> is symmetric and positive definite, we can efficiently solve this system using a Cholesky factorization:</p>
<div class="arithmatex">\[
H = L L^{\top},
\]</div>
<p>where <span class="arithmatex">\(L\)</span> is lower triangular.<br>
The Newton step is then:</p>
<div class="arithmatex">\[
\Delta x_{\text{nt}} = -L^{-\top} L^{-1} g.
\]</div>
<p>This involves two triangular solves:</p>
<ol>
<li><span class="arithmatex">\(L y = -g\)</span></li>
<li><span class="arithmatex">\(L^{\top} \Delta x_{\text{nt}} = y\)</span></li>
</ol>
<p>This avoids explicitly computing <span class="arithmatex">\(H^{-1}\)</span> and ensures numerical stability.</p>
<h4 id="newton-decrement">Newton decrement<a class="headerlink" href="#newton-decrement" title="Permanent link">¶</a></h4>
<p>A useful measure of progress is the Newton decrement:</p>
<div class="arithmatex">\[
\lambda(x) = \| L^{-1} g \|_2,
\]</div>
<p>which approximates how far we are from the optimum.<br>
A common stopping criterion is <span class="arithmatex">\(\lambda(x)^2 / 2 &lt; \varepsilon\)</span>.</p>
<h3 id="954-computational-cost">9.5.4 Computational cost<a class="headerlink" href="#954-computational-cost" title="Permanent link">¶</a></h3>
<p>Each Newton step requires solving a linear system involving <span class="arithmatex">\(\nabla^2 f(x_k)\)</span>, which costs about as much as factoring the Hessian (or an approximation).</p>
<ul>
<li>For an unstructured, dense Hessian, Cholesky factorization requires approximately <span class="arithmatex">\((1/3) n^3\)</span> floating-point operations.  </li>
<li>If <span class="arithmatex">\(H\)</span> is sparse, banded, or has special structure, the cost can be much lower.  </li>
<li>Because of this cubic scaling, Newton’s method is most attractive for medium-scale problems where high accuracy is required.</li>
</ul>
<h3 id="955-why-convexity-helps">9.5.5 Why convexity helps<a class="headerlink" href="#955-why-convexity-helps" title="Permanent link">¶</a></h3>
<p>If <span class="arithmatex">\(f\)</span> is convex, then <span class="arithmatex">\(\nabla^2 f(x_k)\)</span> is positive semidefinite (Chapter 5).<br>
This has two important implications:</p>
<ul>
<li>The local quadratic model is bowl-shaped, so the Newton direction points toward a minimiser.  </li>
<li>Regularised Newton steps (e.g. using <span class="arithmatex">\(H + \mu I\)</span> for small <span class="arithmatex">\(\mu &gt; 0\)</span>) are guaranteed to be descent directions and behave predictably.</li>
</ul>
<h3 id="956-quasi-newton-methods">9.5.6 Quasi-Newton methods<a class="headerlink" href="#956-quasi-newton-methods" title="Permanent link">¶</a></h3>
<p>When computing or storing the Hessian is too expensive, we can build low-rank approximations of <span class="arithmatex">\(\nabla^2 f(x_k)\)</span> or its inverse.<br>
These methods use gradient information from previous steps to estimate curvature.</p>
<p>The most famous examples are:</p>
<ul>
<li>BFGS (Broyden–Fletcher–Goldfarb–Shanno)  </li>
<li>DFP (Davidon–Fletcher–Powell)  </li>
<li>L-BFGS (Limited-memory BFGS) — for very large-scale problems.</li>
</ul>
<p>They maintain many of Newton’s fast local convergence properties, but with per-iteration costs similar to first-order methods.</p>
<p>For instance, BFGS maintains an approximation <span class="arithmatex">\(B_k \approx \nabla^2 f(x_k)^{-1}\)</span> updated via gradient and step differences:</p>
<div class="arithmatex">\[
B_{k+1} = B_k + \frac{(s_k^\top y_k + y_k^\top B_k y_k)}{(s_k^\top y_k)^2} s_k s_k^\top
- \frac{B_k y_k s_k^\top + s_k y_k^\top B_k}{s_k^\top y_k},
\]</div>
<p>where <span class="arithmatex">\(s_k = x_{k+1} - x_k\)</span> and <span class="arithmatex">\(y_k = \nabla f(x_{k+1}) - \nabla f(x_k)\)</span>.</p>
<p>These methods achieve superlinear convergence in practice, making them popular for large smooth optimization problems.</p>
<h3 id="957-when-to-use-newton-or-quasi-newton-methods">9.5.7 When to use Newton or quasi-Newton methods<a class="headerlink" href="#957-when-to-use-newton-or-quasi-newton-methods" title="Permanent link">¶</a></h3>
<p>Use Newton or quasi-Newton methods when:</p>
<ul>
<li>You need high-accuracy solutions.  </li>
<li>The problem is smooth and reasonably well-conditioned.  </li>
<li>The dimension is moderate, or Hessian systems can be solved efficiently (e.g., using sparse linear algebra).  </li>
</ul>
<p>For large, ill-conditioned, or nonsmooth problems, first-order or proximal methods (Chapter 10) are typically more suitable.</p>
<h2 id="96-constraints-and-nonsmooth-terms-projection-and-proximal-methods">9.6 Constraints and nonsmooth terms: projection and proximal methods<a class="headerlink" href="#96-constraints-and-nonsmooth-terms-projection-and-proximal-methods" title="Permanent link">¶</a></h2>
<p>In practice, most convex optimization problems are not purely smooth.<br>
They often include:</p>
<ul>
<li>Constraints: <span class="arithmatex">\(x \in \mathcal{X}\)</span>,</li>
<li>Nonsmooth regularisers: such as <span class="arithmatex">\(\|x\|_1\)</span>,</li>
<li>Penalties: promoting robustness or sparsity (see Chapter 6).</li>
</ul>
<p>Two core strategies handle such settings:</p>
<ol>
<li>Projected gradient methods — where we project each iterate back into the feasible set <span class="arithmatex">\(\mathcal{X}\)</span>.  </li>
<li>Proximal gradient methods — which generalize projection to handle nonsmooth but structured terms.</li>
</ol>
<p>These methods extend the ideas of gradient and Newton updates to the broader world of constrained and composite optimization.</p>
<h3 id="952-convergence-behaviour_1">9.5.2 Convergence behaviour<a class="headerlink" href="#952-convergence-behaviour_1" title="Permanent link">¶</a></h3>
<ul>
<li>Near the minimiser of a strictly convex, twice-differentiable <span class="arithmatex">\(f\)</span>, Newton’s method converges quadratically: roughly, the number of correct digits doubles every iteration.</li>
<li>This is dramatically faster than <span class="arithmatex">\(O(1/k)\)</span> or <span class="arithmatex">\(O(1/k^2)\)</span>, but only once you’re in the “basin of attraction.”</li>
<li>Far from the minimiser, Newton can misbehave, so we pair it with a line search or trust region.</li>
</ul>
<h3 id="953-computational-cost">9.5.3 Computational cost<a class="headerlink" href="#953-computational-cost" title="Permanent link">¶</a></h3>
<p>Each Newton step requires solving a linear system involving <span class="arithmatex">\(\nabla^2 f(x_k)\)</span>, which costs about as much as factoring the Hessian (or an approximation). This is expensive in very high dimensions, which is why Newton is most attractive for medium-scale problems where high accuracy matters.</p>
<h3 id="954-why-convexity-helps">9.5.4 Why convexity helps<a class="headerlink" href="#954-why-convexity-helps" title="Permanent link">¶</a></h3>
<p>If <span class="arithmatex">\(f\)</span> is convex, then <span class="arithmatex">\(\nabla^2 f(x_k)\)</span> is positive semidefinite (Chapter 5). This means:</p>
<ul>
<li>The quadratic model is bowl-shaped, so the Newton step makes sense.</li>
<li>Regularised Newton steps (adding a multiple of the identity to the Hessian) behave very predictably.</li>
</ul>
<h3 id="955-quasi-newton">9.5.5 Quasi-Newton<a class="headerlink" href="#955-quasi-newton" title="Permanent link">¶</a></h3>
<p>When Hessians are too expensive, we can build low-rank approximations of <span class="arithmatex">\(\nabla^2 f(x_k)\)</span> or its inverse. Famous examples include BFGS and L-BFGS. These methods keep much of Newton’s fast local convergence but with per-iteration cost closer to first-order methods.</p>
<h3 id="956-when-to-use-newton-quasi-newton">9.5.6 When to use Newton / quasi-Newton<a class="headerlink" href="#956-when-to-use-newton-quasi-newton" title="Permanent link">¶</a></h3>
<ul>
<li>You need high-accuracy solutions.</li>
<li>The problem is smooth and reasonably well-conditioned.</li>
<li>The dimension is moderate, or Hessian systems can be solved efficiently (e.g. via sparse linear algebra).</li>
</ul>
<h2 id="95-constraints-and-nonsmooth-terms-projection-and-proximal-methods">9.5 Constraints and nonsmooth terms: projection and proximal methods<a class="headerlink" href="#95-constraints-and-nonsmooth-terms-projection-and-proximal-methods" title="Permanent link">¶</a></h2>
<p>In practice, most convex objectives are not just “nice smooth <span class="arithmatex">\(f(x)\)</span>”. They often have:</p>
<ul>
<li>constraints <span class="arithmatex">\(x \in \mathcal{X}\)</span>,</li>
<li>nonsmooth regularisers like <span class="arithmatex">\(\|x\|_1\)</span>,</li>
<li>penalties that encode robustness or sparsity (Chapter 6).</li>
</ul>
<p>Two core ideas handle this: projected gradient and proximal gradient.</p>
<h3 id="961-projected-gradient-descent">9.6.1 Projected gradient descent<a class="headerlink" href="#961-projected-gradient-descent" title="Permanent link">¶</a></h3>
<p>Setting:<br>
Minimise convex, differentiable <span class="arithmatex">\(f(x)\)</span> subject to <span class="arithmatex">\(x \in \mathcal{X}\)</span>, where <span class="arithmatex">\(\mathcal{X}\)</span> is a simple closed convex set (Chapter 4).</p>
<p>Algorithm:</p>
<ol>
<li>Gradient step:
   <script type="math/tex; mode=display">
   y_k = x_k - \alpha \nabla f(x_k).
   </script>
</li>
<li>Projection:
   <script type="math/tex; mode=display">
   x_{k+1}
   =
   \Pi_{\mathcal{X}}(y_k)
   :=
   \arg\min_{x \in \mathcal{X}} \|x - y_k\|_2^2~.
   </script>
</li>
</ol>
<p>Interpretation:</p>
<ul>
<li>You take an unconstrained step downhill,</li>
<li>then you “snap back” to feasibility by Euclidean projection.</li>
</ul>
<p>Examples of <span class="arithmatex">\(\mathcal{X}\)</span> where projection is cheap:</p>
<ul>
<li>A box: <span class="arithmatex">\(l \le x \le u\)</span> (clip each coordinate).</li>
<li>The probability simplex <span class="arithmatex">\(\{x \ge 0, \sum_i x_i = 1\}\)</span> (there are fast projection routines).</li>
<li>An <span class="arithmatex">\(\ell_2\)</span> ball <span class="arithmatex">\(\{x : \|x\|_2 \le R\}\)</span> (scale down if needed).</li>
</ul>
<p>Projected gradient is the constrained version of gradient descent. It maintains feasibility at every iterate.</p>
<h3 id="962-proximal-gradient-forwardbackward-splitting">9.6.2 Proximal gradient (forward–backward splitting)<a class="headerlink" href="#962-proximal-gradient-forwardbackward-splitting" title="Permanent link">¶</a></h3>
<p>Setting:<br>
Composite convex minimisation
<script type="math/tex; mode=display">
\min_x \; F(x) := f(x) + R(x),
</script>
where:</p>
<ul>
<li><span class="arithmatex">\(f\)</span> is convex, differentiable, with Lipschitz gradient,</li>
<li><span class="arithmatex">\(R\)</span> is convex, possibly nonsmooth.</li>
</ul>
<p>Typical choices of <span class="arithmatex">\(R(x)\)</span>:</p>
<ul>
<li><span class="arithmatex">\(R(x) = \lambda \|x\|_1\)</span> (sparsity),</li>
<li><span class="arithmatex">\(R(x) = \lambda \|x\|_2^2\)</span> (ridge),</li>
<li><span class="arithmatex">\(R(x)\)</span> is the indicator function of a convex set <span class="arithmatex">\(\mathcal{X}\)</span>, i.e. <span class="arithmatex">\(R(x)=0\)</span> if <span class="arithmatex">\(x \in \mathcal{X}\)</span> and <span class="arithmatex">\(+\infty\)</span> otherwise — this encodes a hard constraint.</li>
</ul>
<p>Define the proximal operator of <span class="arithmatex">\(R\)</span>:
<script type="math/tex; mode=display">
\mathrm{prox}_{\alpha R}(y)
=
\arg\min_x
\left(
R(x) + \frac{1}{2\alpha} \|x-y\|_2^2
\right).
</script>
</p>
<p>Proximal gradient method:</p>
<ol>
<li>Gradient step on <span class="arithmatex">\(f\)</span>:
   <script type="math/tex; mode=display">
   y_k = x_k - \alpha \nabla f(x_k).
   </script>
</li>
<li>Proximal step on <span class="arithmatex">\(R\)</span>:
   <script type="math/tex; mode=display">
   x_{k+1} = \mathrm{prox}_{\alpha R}(y_k).
   </script>
</li>
</ol>
<p>This is also called forward–backward splitting: “forward” = gradient step, “backward” = prox step.</p>
<h4 id="interpretation">Interpretation:<a class="headerlink" href="#interpretation" title="Permanent link">¶</a></h4>
<ul>
<li>The prox step “handles” the nonsmooth or constrained part exactly.</li>
<li>For <span class="arithmatex">\(R(x)=\lambda \|x\|_1\)</span>, <span class="arithmatex">\(\mathrm{prox}_{\alpha R}\)</span> is soft-thresholding, which promotes sparsity in <span class="arithmatex">\(x\)</span>.<br>
  This is the heart of <span class="arithmatex">\(\ell_1\)</span>-regularised least-squares (LASSO) and many sparse recovery problems.</li>
<li>For <span class="arithmatex">\(R\)</span> as an indicator of <span class="arithmatex">\(\mathcal{X}\)</span>, <span class="arithmatex">\(\mathrm{prox}_{\alpha R} = \Pi_\mathcal{X}\)</span>, so projected gradient is a special case of proximal gradient.</li>
</ul>
<p>This unifies constraints and regularisation.</p>
<h4 id="when-to-use-proximal-projected-gradient">When to use proximal / projected gradient<a class="headerlink" href="#when-to-use-proximal-projected-gradient" title="Permanent link">¶</a></h4>
<ul>
<li>High-dimensional ML/statistics problems.</li>
<li>Objectives with <span class="arithmatex">\(\ell_1\)</span>, group sparsity, total variation, hinge loss, or indicator constraints.</li>
<li>You can evaluate <span class="arithmatex">\(\nabla f\)</span> and compute <span class="arithmatex">\(\mathrm{prox}_{\alpha R}\)</span> cheaply.</li>
<li>You don’t need absurdly high accuracy, but you do need scalability.</li>
</ul>
<p>This is the standard tool for modern large-scale convex learning problems.</p>
<h2 id="97-penalties-barriers-and-interior-point-methods">9.7 Penalties, barriers, and interior-point methods<a class="headerlink" href="#97-penalties-barriers-and-interior-point-methods" title="Permanent link">¶</a></h2>
<p>So far we’ve assumed either:</p>
<ul>
<li>simple constraints we can project onto,</li>
<li>or nonsmooth terms we can prox.</li>
</ul>
<p>What if the constraints are general convex inequalities <span class="arithmatex">\(g_i(x)\le0\)</span>?<br>
Enter penalty methods, barrier methods, and (ultimately) interior-point methods.</p>
<h3 id="971-penalty-methods">9.7.1 Penalty methods<a class="headerlink" href="#971-penalty-methods" title="Permanent link">¶</a></h3>
<p>Turn constrained optimisation into unconstrained optimisation by adding a penalty for violating constraints.</p>
<p>Suppose we want
<script type="math/tex; mode=display">
\min_x f(x)
\quad \text{s.t.} \quad g_i(x) \le 0,\ i=1,\dots,m.
</script>
</p>
<p>A penalty method solves instead
<script type="math/tex; mode=display">
\min_x \; f(x) + \rho \sum_{i=1}^m \phi(g_i(x)),
</script>
where:</p>
<ul>
<li><span class="arithmatex">\(\phi(r)\)</span> is <span class="arithmatex">\(0\)</span> when <span class="arithmatex">\(r \le 0\)</span> (feasible),</li>
<li><span class="arithmatex">\(\phi(r)\)</span> grows when <span class="arithmatex">\(r&gt;0\)</span> (infeasible),</li>
<li><span class="arithmatex">\(\rho &gt; 0\)</span> is a penalty weight.</li>
</ul>
<p>As <span class="arithmatex">\(\rho \to \infty\)</span>, infeasible points become extremely expensive, so minimisers approach feasibility.  </p>
<p>This is conceptually simple and is sometimes effective, but:</p>
<ul>
<li>choosing <span class="arithmatex">\(\rho\)</span> is tricky,</li>
<li>very large <span class="arithmatex">\(\rho\)</span> can make the landscape ill-conditioned and hard for gradient/Newton to solve.</li>
</ul>
<p>Penalty methods are closely linked to robust formulations and Huber-like losses: you replace a hard requirement by a soft cost. This is exactly what you do in robust regression and in <span class="arithmatex">\(\epsilon\)</span>-insensitive / Huber losses (see Section 9.7).</p>
<h3 id="972-barrier-methods">9.7.2 Barrier methods<a class="headerlink" href="#972-barrier-methods" title="Permanent link">¶</a></h3>
<p>Penalty methods penalise violation <em>after</em> you cross the boundary. Barrier methods make it impossible to even touch the boundary.</p>
<p>For inequality constraints <span class="arithmatex">\(g_i(x) \le 0\)</span>, define the logarithmic barrier
<script type="math/tex; mode=display">
b(x) = - \sum_{i=1}^m \log(-g_i(x)).
</script>
This is finite only if <span class="arithmatex">\(g_i(x) &lt; 0\)</span> for all <span class="arithmatex">\(i\)</span>, i.e. <span class="arithmatex">\(x\)</span> is strictly feasible. As you approach the boundary <span class="arithmatex">\(g_i(x)=0\)</span>, <span class="arithmatex">\(b(x)\)</span> blows up to <span class="arithmatex">\(+\infty\)</span>.</p>
<p>We then solve, for a sequence of increasing parameters <span class="arithmatex">\(t\)</span>:
<script type="math/tex; mode=display">
\min_x \; F_t(x) := t f(x) + b(x),
</script>
subject to strict feasibility <span class="arithmatex">\(g_i(x)&lt;0\)</span>.</p>
<p>As <span class="arithmatex">\(t \to \infty\)</span>, minimisers of <span class="arithmatex">\(F_t\)</span> approach the true constrained optimum. The path of minimisers <span class="arithmatex">\(x^*(t)\)</span> is called the central path.</p>
<p>Key points:</p>
<ul>
<li><span class="arithmatex">\(F_t\)</span> is smooth on the interior of the feasible region.</li>
<li>We can apply Newton’s method to <span class="arithmatex">\(F_t\)</span>.</li>
<li>Each Newton step solves a linear system involving the Hessian of <span class="arithmatex">\(F_t\)</span>, so the inner loop looks like a damped Newton method.</li>
<li>Increasing <span class="arithmatex">\(t\)</span> tightens the approximation; we “home in” on the boundary of feasibility.</li>
</ul>
<p>This is the core idea of interior-point methods.</p>
<h3 id="973-interior-point-methods-in-practice">9.7.3 Interior-point methods in practice<a class="headerlink" href="#973-interior-point-methods-in-practice" title="Permanent link">¶</a></h3>
<p>Interior-point methods:</p>
<ul>
<li>Are globally convergent for convex problems under mild assumptions (Slater’s condition; see Chapter 8).</li>
<li>Solve a series of smooth, strictly feasible subproblems.</li>
<li>Use Newton-like steps to update primal (and, implicitly, dual) variables.</li>
<li>Produce both primal and dual iterates — so they naturally produce a duality gap, which certifies how close you are to optimality (Chapter 8).</li>
</ul>
<p>Interior-point methods are the engine behind modern general-purpose convex solvers for:</p>
<ul>
<li>linear programs (LP),</li>
<li>quadratic programs (QP),</li>
<li>second-order cone programs (SOCP),</li>
<li>semidefinite programs (SDP).</li>
</ul>
<p>They give high-accuracy answers and KKT-based optimality certificates. They are more expensive per iteration than gradient methods, but need far fewer iterations, and they handle fully general convex constraints.</p>
<p>Summary: Penalty vs Barrier vs Interior-Point</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Feasibility During Iteration</th>
<th>Mechanism</th>
<th>Typical Behavior</th>
</tr>
</thead>
<tbody>
<tr>
<td>Penalty</td>
<td>May violate constraints</td>
<td>Adds large penalty outside feasible region</td>
<td>Easy to implement but can be ill-conditioned</td>
</tr>
<tr>
<td>Barrier</td>
<td>Stays strictly feasible</td>
<td>Adds infinite cost near constraint boundary</td>
<td>Smooth approximation to constrained problem</td>
</tr>
<tr>
<td>Interior-Point</td>
<td>Always feasible (uses barrier)</td>
<td>Solves a sequence of barrier problems with increasing precision</td>
<td>Follows central path to true optimum</td>
</tr>
</tbody>
</table>
<h2 id="98-choosing-the-right-method-in-practice">9.8 Choosing the right method in practice<a class="headerlink" href="#98-choosing-the-right-method-in-practice" title="Permanent link">¶</a></h2>
<p>Let’s summarise the chapter in the form of a decision guide.</p>
<p>Case A. Smooth, unconstrained, very high dimensional.<br>
Example: logistic regression on millions of samples.<br>
Use: gradient descent or (better) accelerated gradient.<br>
Why: cheap iterations, easy to implement, scales.  </p>
<p>Case B. Smooth, unconstrained, moderate dimensional, need high accuracy.<br>
Example: convex nonlinear fitting with well-behaved Hessian.<br>
Use: Newton or quasi-Newton.<br>
Why: quadratic (or near-quadratic) convergence near optimum.  </p>
<p>Case C. Convex with simple feasible set <span class="arithmatex">\(x \in \mathcal{X}\)</span> (box, ball, simplex).<br>
Use: projected gradient.<br>
Why: projection is easy, maintains feasibility at each step.  </p>
<p>Case D. Composite objective <span class="arithmatex">\(f(x) + R(x)\)</span> where <span class="arithmatex">\(R\)</span> is nonsmooth (e.g. <span class="arithmatex">\(\ell_1\)</span>, indicator of a constraint set).<br>
Use: proximal gradient.<br>
Why: prox handles nonsmooth/constraint part exactly each step.  </p>
<p>Case E. General convex program with inequalities <span class="arithmatex">\(g_i(x)\le 0\)</span>.<br>
Use: interior-point methods.<br>
Why: they solve smooth barrier subproblems via Newton steps and give primal–dual certificates through KKT and duality (Chapters 7–8).  </p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      © 2025 Salman Khan — Educational Use Only
    </div>
  
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/SalK91/convex_optimization" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.top", "toc.integrate", "content.code.copy", "content.code.annotate", "content.action.edit", "content.action.view", "content.tabs.link", "search.suggest", "search.highlight"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>