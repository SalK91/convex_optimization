<!DOCTYPE html><html lang="en" class="no-js"><head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Structured lecture notes on optimization, convex analysis, and algorithms.">
      
      
        <meta name="author" content="Salman Khan">
      
      
        <link rel="canonical" href="https://salk91.github.io/convex_optimization/2_0_identifyconvex/">
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>2 0 identifyconvex - Mathematics for Machine Learning</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.e53b48f4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Merriweather:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&amp;display=fallback">
        <style>:root{--md-text-font:"Merriweather";--md-code-font:"Fira Code"}</style>
      
    
    
      <link rel="stylesheet" href="../styles/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  <link href="../assets/stylesheets/glightbox.min.css" rel="stylesheet"><script src="../assets/javascripts/glightbox.min.js"></script><style id="glightbox-style">
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Mathematics for Machine Learning" class="md-header__button md-logo" aria-label="Mathematics for Machine Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Mathematics for Machine Learning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              2 0 identifyconvex
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="indigo" aria-label="Switch to light mode" type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="indigo" aria-label="Switch to dark mode" type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m3.55 19.09 1.41 1.41 1.8-1.79-1.42-1.42M12 6c-3.31 0-6 2.69-6 6s2.69 6 6 6 6-2.69 6-6c0-3.32-2.69-6-6-6m8 7h3v-2h-3m-2.76 7.71 1.8 1.79 1.41-1.41-1.79-1.8M20.45 5l-1.41-1.4-1.8 1.79 1.42 1.42M13 1h-2v3h2M6.76 5.39 4.96 3.6 3.55 5l1.79 1.81zM1 13h3v-2H1m12 9h-2v3h2"></path></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/SalK91/convex_optimization" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Mathematics for Machine Learning" class="md-nav__button md-logo" aria-label="Mathematics for Machine Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    Mathematics for Machine Learning
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/SalK91/convex_optimization" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1">
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Convex Optimization:
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Convex Optimization:
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_0_intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. Introduction and Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_1_vector/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. Linear Algebra Foundations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_7_calculus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. Multivariable Calculus for Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_8_convexsets/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Convex Sets and Geometric Fundamentals
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_9_convexfunctions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. Convex Functions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_7a_subgradients/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. Nonsmooth Convex Optimization – Subgradients
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_12_kkt/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. Optimization Principles – From Gradient Descent to KKT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_13_duality/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8. Lagrange Duality Theory
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3_0_optimizationalgo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9. Algorithms for Convex Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3_7_advanced/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10. Advanced Large-Scale and Structured Methods
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3_8_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11. Modelling Patterns and Algorithm Selection in Practice
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_10_ineqaulities/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Appendix A - Common Inequalities and Identities
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_11_support/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Appendix B - Support Functions and Dual Geometry (Advanced)
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/SalK91/convex_optimization/edit/master/docs/2_0_identifyconvex.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/SalK91/convex_optimization/raw/master/docs/2_0_identifyconvex.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg>
    </a>
  


  <h1>2 0 identifyconvex</h1>

<p>Convex optimization problems form the backbone of modern optimization theory due to their well-behaved geometry and tractable properties. By definition, an optimization problem is convex if (a) its objective function is convex and (b) its feasible set is convex. In practical terms, this means any weighted average (or convex combination) of two feasible points remains feasible (a hallmark of convex sets – see Section A, Chapter 4: Affine and Convex Geometry). These conditions are crucial because they guarantee that every local optimum is a global optimum. In other words, you never get trapped in a "bad" local minimum when the problem is convex. This global optimality property makes convex problems far easier to solve reliably than general nonlinear problems.</p>
<p><strong>Convex Optimization Problem – Formal Definition:</strong> A standard form optimization problem is convex if it can be written as: minimize <span class="arithmatex">\(f_0(x)\)</span> subject to <span class="arithmatex">\(f_i(x) \le 0\)</span> (for <span class="arithmatex">\(i=1,\dots,m\)</span>) and <span class="arithmatex">\(h_j(x) = 0\)</span> (for <span class="arithmatex">\(j=1,\dots,p\)</span>), where <span class="arithmatex">\(f_0\)</span> is a convex function, each inequality constraint function <span class="arithmatex">\(f_i\)</span> is convex, and each equality constraint <span class="arithmatex">\(h_j(x)\)</span> is an affine function (linear function plus a constant). Equivalently, it is the problem of minimizing a convex function over a convex set. The feasible region in a convex problem is the intersection of a convex domain and constraint sets, which is itself convex.</p>
<p>Convexity of the objective and constraints can be tested using both geometric intuition and analytic tools. In this section, we'll walk through how to verify the convexity of an optimization problem step by step. We start by checking the objective function (is it convex?), then each constraint (does it define a convex region?), and finally we outline a checklist and even a simple flowchart of questions to systematically determine convexity. We will also highlight common patterns that break convexity (so you can spot non-convex structures easily), and work through several intuitive examples (like least squares, LASSO, and a quadratic program) to solidify the concepts. Throughout, we'll lean on geometric language (think of “bowl-shaped” functions and “flat” constraints) and simple derivations rather than heavy proofs – our goal is building understanding and intuition for graduate students and ML practitioners.</p>
<h3 id="convexity-of-the-objective-function">Convexity of the Objective Function<a class="headerlink" href="#convexity-of-the-objective-function" title="Permanent link">¶</a></h3>
<p>The objective function <span class="arithmatex">\(f_0(x)\)</span> is the function we seek to minimize (we'll assume a minimization problem for concreteness; a maximization of a concave function is equivalent since maximizing a concave <span class="arithmatex">\(g\)</span> is same as minimizing <span class="arithmatex">\(f_0(x) = -g(x)\)</span>, which is convex
en.wikipedia.org
). To check if <span class="arithmatex">\(f_0(x)\)</span> is convex, we have several tools at our disposal, ranging from visual (geometric) tests to analytical conditions:</p>
<ul>
<li>
<p><strong>Geometric Definition (Epigraph Test):</strong> Recall that a function <span class="arithmatex">\(f:\mathbb{R}^n\to\mathbb{R}\)</span> is convex if and only if its epigraph – the set <span class="arithmatex">\(\mathrm{epi}(f) = {(x,t): f(x) \le t}\)</span> – is a convex set. Geometrically, this means that if you take any two points on the graph of <span class="arithmatex">\(f\)</span>, the line segment (or “chord”) connecting them lies above the graph everywhere between those points. Algebraically, for any two points <span class="arithmatex">\(x,y\)</span> in the domain and any <span class="arithmatex">\(\theta\in[0,1]\)</span>, a convex <span class="arithmatex">\(f\)</span> satisfies the inequality: 
    <script type="math/tex; mode=display">
    f(\theta x + (1 - \theta) y)
    \le
    \theta f(x) + (1 - \theta) f(y)
    </script>
</p>
<p>This is the precise definition of convexity (see Section A, Chapter 4). In contrast, a non-convex function will "curve up and down" – its graph might dip below some chord (a familiar example is <span class="arithmatex">\(\sin x\)</span>, which is neither convex nor concave over its full domain).</p>
</li>
<li>
<p><strong>First-Order Test (Tangent Underestimation):</strong> If <span class="arithmatex">\(f(x)\)</span> is differentiable, a very useful characterization of convexity is that its tangent plane at any point lies below the graph of <span class="arithmatex">\(f\)</span> everywhere. Formally, <span class="arithmatex">\(f\)</span> is convex if and only if for all points <span class="arithmatex">\(x,y\)</span> in its domain,
    <script type="math/tex; mode=display">
    f(y) \ge f(x) + \nabla f(x)^\top (y - x)
    </script>
    This inequality says that the first-order Taylor approximation of <span class="arithmatex">\(f\)</span> at <span class="arithmatex">\(x\)</span> underestimates the function at any other point <span class="arithmatex">\(y\)</span> (no tangent ever goes above the curve). This is intuitive: a convex function has no “hidden dips” below its tangents. In geometric terms, you can stand anywhere on the surface and the local linear approximation forms a supporting plane underneath the surface. If <span class="arithmatex">\(f\)</span> is not differentiable, we can use the more general notion of a subgradient <span class="arithmatex">\(g \in \partial f(x)\)</span>. A vector <span class="arithmatex">\(g\)</span> is a subgradient of <span class="arithmatex">\(f\)</span> at <span class="arithmatex">\(x\)</span> if <span class="arithmatex">\(f(y) \ge f(x) + g^T (y - x)\)</span> for all <span class="arithmatex">\(y\)</span>. For convex functions, at least one subgradient exists at every point (even at a kink), and the inequality still holds. For example, the absolute value function <span class="arithmatex">\(f(x)=|x|\)</span> is convex but not differentiable at 0; its subgradients at 0 are any <span class="arithmatex">\(g\in[-1,1]\)</span>, which gives an entire family of supporting lines <span class="arithmatex">\(f(y) \ge |0| + g,(y-0)\)</span> hovering below the <span class="arithmatex">\(|x|\)</span> V-shape.</p>
</li>
<li>
<p><strong>Second-Order Test (Hessian Criterion):</strong> If <span class="arithmatex">\(f(x)\)</span> is twice differentiable, convexity can be checked via the Hessian matrix (the matrix of second partial derivatives). The Hessian <span class="arithmatex">\(\nabla^2 f(x)\)</span> must be positive semidefinite (PSD) at every point <span class="arithmatex">\(x\)</span> in the domain for <span class="arithmatex">\(f\)</span> to be convex. In <span class="arithmatex">\(\mathbb{R}\)</span> (one dimension), this reduces to the simple condition <span class="arithmatex">\(f''(x) \ge 0\)</span> for all <span class="arithmatex">\(x\)</span>. In higher dimensions, positive semidefiniteness means <span class="arithmatex">\(z^T (\nabla^2 f(x)),z \ge 0\)</span> for all vectors <span class="arithmatex">\(z\)</span> (intuitively, <span class="arithmatex">\(f\)</span> curves "upward" in every direction). This second-order test is often the most straightforward for smooth functions: for instance, if <span class="arithmatex">\(f(x) = \tfrac{1}{2}x^T Q x + c^T x\)</span> is a quadratic function, then <span class="arithmatex">\(\nabla^2 f(x) = Q\)</span>, so <span class="arithmatex">\(f\)</span> is convex exactly when <span class="arithmatex">\(Q \succeq 0\)</span> (PSD matrix). As a quick example, <span class="arithmatex">\(f(x)=x^2\)</span> has <span class="arithmatex">\(f''(x)=2&gt;0\)</span> so it's convex (a bowl shape), whereas <span class="arithmatex">\(f(x)=\cos x\)</span> has <span class="arithmatex">\(f''(x)=-\cos x\)</span> which is negative around <span class="arithmatex">\(x=0\)</span>, revealing its non-convex curvature.</p>
</li>
<li>
<p><strong>Recognizing Known Convex Functions (By Type):</strong> Over time, you will build a library of common convex functions and patterns. Many functions are known to be convex by their form. For example: any linear or affine function (<span class="arithmatex">\(f(x)=a^T x + b\)</span>) is convex (and concave) because it just produces a flat plane. Quadratic functions <span class="arithmatex">\(f(x)=x^T Q x + c^T x + d\)</span> are convex if <span class="arithmatex">\(Q\)</span> is PSD, as noted. Norms like <span class="arithmatex">\(||x||_2\)</span> or <span class="arithmatex">\(||x||1\)</span> are convex (the <span class="arithmatex">\(L_1\)</span> norm is essentially a sum of absolute values, forming a pointed "diamond" cone). Exponential functions <span class="arithmatex">\(e^{ax}\)</span> are convex for any real <span class="arithmatex">\(a\)</span>. Even-powered monomials <span class="arithmatex">\(x^{2}, x^4, x^6,\dots\)</span> are convex on <span class="arithmatex">\(\mathbb{R}\)</span>. More generally, <span class="arithmatex">\(x^p\)</span> is convex on <span class="arithmatex">\(\mathbb{R}{++}\)</span> (positive reals) for <span class="arithmatex">\(p\ge 1\)</span> or <span class="arithmatex">\(p\le 0\)</span>. Negative entropy <span class="arithmatex">\(x\log x\)</span> is convex on <span class="arithmatex">\(x&gt;0\)</span>. The log-sum-exp function (important in machine learning) <span class="arithmatex">\(f(x)=\log(e^{x_1}+\cdots+e^{x_n})\)</span> is convex. Even the maximum of a set of convex functions is convex (e.g. <span class="arithmatex">\(f(x)=\max{f_1(x),\dots,f_k(x)}\)</span> is convex) because its epigraph is the intersection of halfspaces from each <span class="arithmatex">\(f_i\)</span>. If your objective <span class="arithmatex">\(f_0(x)\)</span> can be expressed as a sum of convex functions, a maximum of convex functions, or an affine transformation of a convex function, then <span class="arithmatex">\(f_0\)</span> is convex. (Convexity is closed under these operations: e.g. nonnegative weighted sums of convex functions remain convex, and composing a convex function with an affine mapping keeps it convex.)</p>
</li>
</ul>
<p>In practice, a good strategy is to decompose the objective into known building blocks. If each piece is convex and they are combined by operations that preserve convexity, then the whole objective is convex. For example, if <span class="arithmatex">\(f_0(x) = g(h(x))\)</span> and you know <span class="arithmatex">\(g\)</span> is convex non-decreasing and <span class="arithmatex">\(h(x)\)</span> is convex, then <span class="arithmatex">\(f_0\)</span> is convex (one common case: <span class="arithmatex">\(g(t)=\log t\)</span> which is increasing concave, so <span class="arithmatex">\(-g(t)=-\log t\)</span> is convex non-decreasing; thus <span class="arithmatex">\(- \log(h(x))\)</span> is convex if <span class="arithmatex">\(h(x)\)</span> is convex and positive). On the other hand, if you detect any component that is non-convex (say a term like <span class="arithmatex">\(\sin x\)</span> or <span class="arithmatex">\(x^T Q x\)</span> with an indefinite <span class="arithmatex">\(Q\)</span>, or a product of variables like <span class="arithmatex">\(x_i x_j\)</span>), that is a red flag – the objective might be non-convex unless that term can be transformed or bounded within a convex structure.</p>
<h3 id="convexity-of-the-constraints-feasible-set">Convexity of the Constraints (Feasible Set)<a class="headerlink" href="#convexity-of-the-constraints-feasible-set" title="Permanent link">¶</a></h3>
<p>The second part of the convexity check is to examine the constraints, which determine the feasible set. Even if the objective is convex, a non-convex feasible region will make the overall problem non-convex (since you're effectively minimizing a convex function over a non-convex set, which can introduce local minima). To ensure the feasible set is convex, each constraint must individually define a convex set, and all constraints together (their intersection) must therefore also yield a convex set.</p>
<p>Here are the typical types of constraints and how to check their convexity:</p>
<ul>
<li>
<p><strong>Convex Inequality Constraints:</strong> These are of the form
    <script type="math/tex; mode=display">
    f_i(x) \le 0
    </script>
</p>
<p>where <span class="arithmatex">\(f_i(x)\)</span> is a convex function. Such a constraint means we are taking a sublevel set of a convex function, <span class="arithmatex">\({x \mid f_i(x) \le 0}\)</span>. By definition, any sublevel set of a convex function is a convex set. Intuitively, if <span class="arithmatex">\(f_i\)</span> is convex, the region where <span class="arithmatex">\(f_i(x)\)</span> is below some threshold looks like a "bowl" or a filled-in convex region. For example, <span class="arithmatex">\(f_i(x) = ||x||_2 - 1 \le 0\)</span> describes the set <span class="arithmatex">\({x: ||x||_2 \le 1}\)</span>, which is a solid Euclidean ball – a convex set. Likewise, linear inequalities like <span class="arithmatex">\(a^T x \le b\)</span> are convex constraints (they define half-spaces). Rule of thumb: If each <span class="arithmatex">\(f_i(x)\le 0\)</span> is convex in <span class="arithmatex">\(x\)</span>, then the feasible set defined by all such inequalities is convex (since it's an intersection of convex sets).</p>
<blockquote>
<p>note: Sometimes constraints are given in an equivalent form like <span class="arithmatex">\(g(x)\ge 0\)</span>. You can always rewrite <span class="arithmatex">\(g(x)\ge 0\)</span> as <span class="arithmatex">\(-g(x) \le 0\)</span>. So if you encounter <span class="arithmatex">\(g(x)\ge 0\)</span>, check if <span class="arithmatex">\(g(x)\)</span> is concave (since <span class="arithmatex">\(-g\)</span> would then be convex). For instance, <span class="arithmatex">\(g(x) = \text{log}(x)\)</span> is concave on <span class="arithmatex">\(x&gt;0\)</span>, so the constraint <span class="arithmatex">\(\log(x) \ge 3\)</span> is equivalent to <span class="arithmatex">\(-,\log(x) \le -3\)</span>, and <span class="arithmatex">\(-,\log(x)\)</span> is convex; hence this constraint defines a convex feasible set (here <span class="arithmatex">\(x \ge e^3\)</span>).</p>
</blockquote>
</li>
<li>
<p><strong>Affine Equality Constraints:</strong> These are constraints of the form
    <script type="math/tex; mode=display">
    h_j(x) = 0
    </script>
</p>
<p>where <span class="arithmatex">\(h_j(x)\)</span> is an affine function, meaning <span class="arithmatex">\(h_j(x) = a_j^T x + b_j\)</span> for some constant vector <span class="arithmatex">\(a_j\)</span> and scalar <span class="arithmatex">\(b_j\)</span>. Affine equalities are convex constraints because an affine set <span class="arithmatex">\({x \mid a^T x + b = 0}\)</span> is actually a flat hyperplane (or a translate of a subspace), which is a convex set (recall: any line or plane is convex since the line segment between any two points on a line/plane stays on that line/plane; see Section A, Chapter 4). For example, <span class="arithmatex">\(x_1 + 2x_2 = 5\)</span> defines a line in <span class="arithmatex">\(\mathbb{R}^2\)</span>, which is convex. Important: If an equality constraint is non-affine (e.g. <span class="arithmatex">\(x_1 x_2 = 10\)</span> or <span class="arithmatex">\(x_1^2 + x_2^2 = 1\)</span>), the feasible set will typically be non-convex. For instance, <span class="arithmatex">\(x_1 x_2 = 10\)</span> is a hyperbola – a curved set that is not convex; <span class="arithmatex">\(x_1^2 + x_2^2 = 1\)</span> is the unit circle (just the boundary of a ball), which is not a convex set by itself (any line between two points on the circle goes through the inside which is not included in the feasible set). Thus, any nonlinear equality generally signals non-convexity (except in trivial cases like something that reduces to an affine constraint on a higher-dimensional space).</p>
</li>
<li>
<p><strong>Convex Set Membership Constraints:</strong> Sometimes constraints are given in the form “<span class="arithmatex">\(x\)</span> belongs to a set <span class="arithmatex">\(C\)</span>”, denoted <span class="arithmatex">\(x \in C\)</span>. In order for the problem to remain convex, the set <span class="arithmatex">\(C\)</span> must be convex. Many common constraint sets in optimization are indeed convex: for example, polyhedra defined by linear inequalities (<span class="arithmatex">\(\{\, x \mid A x \le b \,\}\)</span>) are convex; norm balls like <span class="arithmatex">\(\{\, x \mid \|x\|_p \le \alpha \,\}\)</span> are convex sets (for any <span class="arithmatex">\(p \ge 1\)</span>); the set of probability distributions <span class="arithmatex">\(\{\, x \mid x_i \ge 0, \ \sum_i x_i = 1 \,\}\)</span> is convex; the set of positive semidefinite matrices (in semidefinite programming) is convex. However, if <span class="arithmatex">\(C\)</span> is something like a finite set or has a discrete structure (e.g. "<span class="arithmatex">\(x_i \in \{0,1\}\)</span> for some component"), then <span class="arithmatex">\(C\)</span> is non-convex. Discrete constraints (integer or binary decisions) break convexity because the feasible region becomes a set of isolated points or separate chunks, not a single nicely connected region. As another example, the set <span class="arithmatex">\(C = \{\, x : 1 \le \|x\|_2 \le 2 \,\}\)</span> – an annulus (ring) between two circles – is not convex because it excludes the interior donut hole (a line between a point on the inner circle and a point on the outer circle would pass through the hole which is infeasible).</p>
</li>
</ul>
<p>In summary, to have a convex feasible set, every constraint should individually carve out a convex region. All inequality constraints should be convex functions (producing convex sublevel sets), all equalities should be affine (flat), and any set-membership conditions should refer to convex sets. Since the intersection of any collection of convex sets is convex, these conditions ensure the overall feasible set is convex. If any one constraint is non-convex, the feasible region (being an intersection including a non-convex piece) will be non-convex – and hence the whole problem is not convex.</p>
<h3 id="common-non-convex-structures-to-watch-for">Common Non-Convex Structures to Watch For<a class="headerlink" href="#common-non-convex-structures-to-watch-for" title="Permanent link">¶</a></h3>
<p>Having a mental checklist of "usual suspects" that break convexity is extremely useful. Often, by scanning the form of the objective and constraints, you can spot patterns that are inherently non-convex. Here are some common non-convex structures:</p>
<ul>
<li>
<p><strong>Bilinear or Multilinear Terms:</strong> If the objective or a constraint involves a product of decision variables (e.g. a term like <span class="arithmatex">\(x_i \cdot y_j\)</span> or <span class="arithmatex">\(x_1 x_2\)</span>), this is generally non-convex. For example, the function <span class="arithmatex">\(f(x_1,x_2) = x_1 x_2\)</span> is not convex on <span class="arithmatex">\(\mathbb{R}^2\)</span> (its Hessian is indefinite), and the constraint <span class="arithmatex">\(x_1 x_2 \le c\)</span> typically yields a hyperbolic region which is not convex. Bilinear terms often arise in problems like optimal power flow, portfolio optimization with products, or geometry problems – and they usually indicate the problem is hard (non-convex) unless you can reformulate them in convex form (sometimes via change of variables or relaxations).</p>
</li>
<li>
<p><strong>Indefinite Quadratics:</strong> A quadratic function <span class="arithmatex">\(x^T Q x + c^T x\)</span> is convex only if <span class="arithmatex">\(Q\)</span> is PSD. If <span class="arithmatex">\(Q\)</span> has even one negative eigenvalue (making it indefinite or negative definite), the function is not convex – it “curves downward” in at least one direction. For instance, <span class="arithmatex">\(f(x_1,x_2) = x_1^2 - x_2^2\)</span> (here <span class="arithmatex">\(Q=\mathrm{diag}(1,-1)\)</span>) is a saddle-shaped function, not convex. So if you see a quadratic objective or constraint, check the matrix: a negative sign on a squared term or a “difference of squares” usually signals non-convexity (unless you can somehow constrain that term’s effect away).</p>
</li>
<li>
<p><strong>Nonlinear Equality Constraints:</strong> As mentioned, anything like <span class="arithmatex">\(h(x)=0\)</span> where <span class="arithmatex">\(h\)</span> is nonlinear (especially products, trigonometric equations, polynomial equations beyond first degree) is likely non-convex. A classic example is a fixed product or fixed norm constraint: <span class="arithmatex">\(x_1 x_2 = 1\)</span> or <span class="arithmatex">\(||x||_2 = 1\)</span>. These carve out a curved manifold (a hyperbola or a sphere surface) without thickness – not convex. When you have such constraints, the feasible region often ends up disconnected or curved in a way that violates convexity. (One exception: something like <span class="arithmatex">\(x^2+y^2=0\)</span> is convex, but only because it implies <span class="arithmatex">\(x=0,y=0\)</span> – a trivial single-point set, which is convex. In general, non-affine equalities that allow multiple points are trouble.)</p>
</li>
<li>
<p><strong>Ratios and Fractional Forms:</strong> Objective terms like <span class="arithmatex">\(\frac{p(x)}{q(x)}\)</span> (where <span class="arithmatex">\(p\)</span> and <span class="arithmatex">\(q\)</span> are functions of <span class="arithmatex">\(x\)</span>) or constraints like <span class="arithmatex">\(\frac{f(x)}{g(x)} \le c\)</span> are typically non-convex (these are quotient or fractional programs). A simple example: <span class="arithmatex">\(f(x)=\frac{1}{x}\)</span> on <span class="arithmatex">\(x&gt;0\)</span> is convex, but if you have something like <span class="arithmatex">\(\frac{x_1}{x_2}\)</span> it’s neither convex nor concave on a broad domain. Many ratio problems can sometimes be convexified by clever transformations (e.g. transforming variables if <span class="arithmatex">\(x_2\)</span> is positive), but at face value, be cautious with fractional terms.</p>
</li>
<li>
<p><strong>Discrete Variables or Logic:</strong> If your problem involves integer variables (e.g. <span class="arithmatex">\(x_i \in {0,1}\)</span> or <span class="arithmatex">\(x_i\)</span> must be an integer) or logical constraints (if-then conditions, either-or constraints), then the feasible set is not convex. For example, requiring <span class="arithmatex">\(x\)</span> to be 0 or 1 means the feasible set is just two points, which is not convex (no line segment between 0 and 1 stays in the set except at the endpoints). These kinds of problems fall into combinatorial optimization or mixed-integer programming, which are generally NP-hard. They are solved with very different techniques (branch-and-bound, etc.) compared to convex optimization. There are ways to relax some discrete problems into convex ones (for example, dropping the integrality to allow continuous variables between 0 and 1, or using convex hulls), but the original discrete problem is non-convex.</p>
</li>
<li>
<p><strong>“U-Shaped then Inverted U” Functions:</strong> Any single-variable function that isn’t convex over its whole domain often shows a change in curvature. For example, <span class="arithmatex">\(\sin x\)</span> alternates between convex and concave regions; a function like <span class="arithmatex">\(f(x) = x^3\)</span> has <span class="arithmatex">\(f''(x) = 6x\)</span>, which is negative for <span class="arithmatex">\(x&lt;0\)</span> and positive for <span class="arithmatex">\(x&gt;0\)</span>, so <span class="arithmatex">\(f(x)\)</span> is not convex on the entire real line (it fails the Hessian test globally). If the objective function or a constraint function “bends” upward in some places and downward in others, it’s not globally convex. Recognizing these shapes (e.g. an objective with multiple local minima valleys separated by hills) is key — convex functions have a single valley (global bowl shape), whereas non-convex ones can have multiple valleys and peaks.</p>
</li>
</ul>
<p>In summary, when scanning a problem, look out for these red flags. Spotting a single non-convex structure is enough to conclude the problem (as stated) is non-convex. Sometimes, such problems can be transformed or approximated by convex problems (this is a big area of research), but that’s beyond our current scope. Here, our goal is identification: know it when you see it.</p>
<h3 id="examples-convex-or-not">Examples: Convex or Not?<a class="headerlink" href="#examples-convex-or-not" title="Permanent link">¶</a></h3>
<p>Let's solidify these concepts with a few intuitive examples. We will examine some optimization problems and apply the convexity checks. This will illustrate both positive examples (problems that are convex and why) and a negative example (a non-convex problem and how to tell).</p>
<ol>
<li>
<p><strong>Unconstrained Least Squares (Convex):</strong> </p>
<p>Problem: <span class="arithmatex">\(\min_x f(x)\)</span> where <span class="arithmatex">\(f(x) = |Ax - b|_2^2 = (Ax - b)^T(Ax - b)\)</span>. This is the classic least squares problem. </p>
<p>Objective: <span class="arithmatex">\(f(x)\)</span> is a quadratic function. We can expand <span class="arithmatex">\(f(x) = x^T (A^T A) x - 2b^T A x + |b|_2^2\)</span>. Here the Hessian is <span class="arithmatex">\(Q = 2A^T A\)</span>. The matrix <span class="arithmatex">\(A^T A\)</span> is symmetric positive semidefinite (in fact positive definite if <span class="arithmatex">\(A\)</span> has full column rank). Thus <span class="arithmatex">\(Q \succeq 0\)</span>, so <span class="arithmatex">\(f(x)\)</span> is convex. There are no constraints (the domain is all <span class="arithmatex">\(x\)</span>, which is a convex set <span class="arithmatex">\(\mathbb{R}^n\)</span>), so the feasible set is convex. By our criteria, this optimization problem is convex. Indeed, least squares has a unique global minimum given by the normal equations. If we plot <span class="arithmatex">\(f(x)\)</span> as a function (for example, if <span class="arithmatex">\(x\)</span> is one-dimensional, <span class="arithmatex">\(f(x)\)</span> is a simple parabola), it's clearly bowl-shaped and has no secondary minima. This matches our formal check: quadratic with PSD curvature → convex objective.</p>
</li>
<li>
<p><strong>LASSO Regression (Convex):</strong></p>
<p>Problem: <span class="arithmatex">\(\min_{x\in\mathbb{R}^n} ; \frac{1}{2}|Ax - b|_2^2 + \lambda |x|_1\)</span>, for some <span class="arithmatex">\(\lambda &gt; 0\)</span>. This is the LASSO optimization used in machine learning for sparse linear models. </p>
<p>Objective: It is a sum of two terms: <span class="arithmatex">\(g(x) = \frac{1}{2}|Ax - b|_2^2\)</span> (a convex quadratic, as just discussed) and <span class="arithmatex">\(h(x) = \lambda |x|_1\)</span> (the <span class="arithmatex">\(L_1\)</span> norm times a positive scalar, which is convex). The sum of convex functions is convex, so <span class="arithmatex">\(f(x) = g(x)+h(x)\)</span> is convex. There are no explicit constraints (again <span class="arithmatex">\(x\in\mathbb{R}^n\)</span>), so the feasible set is all of <span class="arithmatex">\(\mathbb{R}^n\)</span> (convex). Thus, the LASSO problem is convex. Geometrically, the first term <span class="arithmatex">\(|Ax-b|_2^2\)</span> defines ellipsoidal level sets (nice and smooth), and the second term <span class="arithmatex">\(|x|_1\)</span> has level sets that are diamonds (corners along axes). The combination yields a convex “bowl with a corner-like shape around the bottom,” but crucially no local minima besides the global one. Many algorithms exploit this convexity (LASSO can be solved efficiently by coordinate descent or proximal gradient methods, leveraging the convex subgradient of <span class="arithmatex">\(|x|_1\)</span>).</p>
</li>
<li>
<p><strong>Quadratic Program with Constraints (Convex)</strong>:</p>
<p>Problem: <span class="arithmatex">\(\displaystyle \min_{x} ;\frac{1}{2} x^T Q x + c^T x \quad \text{s.t.}; A x \le d; Bx = e.\)</span> This is a quadratic program (QP) with linear constraints. </p>
<p>To check convexity: The objective is convex if <span class="arithmatex">\(Q \succeq 0\)</span> (positive semidefinite). All terms are quadratic/linear which are easy to verify. Constraints: <span class="arithmatex">\(A x \le d\)</span> are linear inequality constraints – each of the form <span class="arithmatex">\(a_i^T x \le d_i\)</span> – which are convex (halfspaces). <span class="arithmatex">\(B x = e\)</span> are affine equalities – also convex (subspace translated by <span class="arithmatex">\(e\)</span>). So if <span class="arithmatex">\(Q\)</span> is PSD, everything in this problem is convex: convex objective, convex feasible region. This becomes a convex optimization problem, often called a convex QP. For example, consider a specific QP:</p>
<div class="arithmatex">\[
\begin{aligned}
\min_{x_1,\, x_2} \quad &amp; 2x_1^2 + x_2^2 + 3x_1 + 4x_2 \\
\text{s.t.} \quad &amp; x_1 + x_2 = 1, \\
&amp; x_1 \ge 0, \\
&amp; x_2 \ge 0.
\end{aligned}
\]</div>
<p>Here </p>
<div class="arithmatex">\[
Q = \begin{pmatrix}
4 &amp; 0 \\
0 &amp; 2
\end{pmatrix}
\]</div>
<p>(since objective <span class="arithmatex">\(= 2x_1^2 + x_2^2 + \dots\)</span>), which is PSD. The equality <span class="arithmatex">\(x_1+x_2=1\)</span> is affine (a line), and <span class="arithmatex">\(x_1 \ge 0, x_2 \ge 0\)</span> are halfspaces (actually together <span class="arithmatex">\(x_1,x_2\ge0\)</span> define the first quadrant, which is convex). So all conditions check out – it's convex. We know from theory and experience that convex QPs can be solved efficiently to global optimality (there are Interior-Point solvers, etc.). Had <span class="arithmatex">\(Q\)</span> been non-PSD, the objective would be indefinite and the problem not convex – in that case, even though the constraints are still linear, the objective's shape would cause multiple local minima or unbounded directions.</p>
</li>
<li>
<p><strong>Non-Convex Optimization Example (Bilinear Constraint)</strong>: </p>
<p>Problem: <span class="arithmatex">\(\displaystyle \min_{x_1,x_2} ; x_1^2 + x_2^2 \quad \text{s.t.}; x_1 x_2 \ge 1.\)</span> This is a made-up example to demonstrate a non-convex feasible region. </p>
<p>Objective: <span class="arithmatex">\(f(x_1,x_2) = x_1^2 + x_2^2\)</span> is convex (it's a bowl shaped paraboloid). Constraint: <span class="arithmatex">\(x_1 x_2 \ge 1\)</span> is not a convex constraint. The feasible set <span class="arithmatex">\({(x_1,x_2): x_1 x_2 \ge 1}\)</span> consists of two disjoint regions: one where both <span class="arithmatex">\(x_1\)</span> and <span class="arithmatex">\(x_2\)</span> are positive (and their product exceeds 1), and one where both are negative (since a negative times a negative is positive, exceeding 1). The feasible region looks like two opposite quadrants cut away from the origin. This set is non-convex (you can take a point from the positive quadrant and one from the negative quadrant, and the line segment between them will cross through the region near the origin where <span class="arithmatex">\(x_1 x_2 &lt; 1\)</span>, which is infeasible). Thus, even though the objective is convex, the non-convex constraint breaks the problem's convexity. In fact, this problem has two separate “valleys” to minimize in (one in the <span class="arithmatex">\(x_1,x_2 &gt; 0\)</span> region and one in the <span class="arithmatex">\(x_1,x_2 &lt; 0\)</span> region). Each region has a local minimum (roughly when <span class="arithmatex">\(x_1 x_2 = 1\)</span> and the mass is evenly distributed, e.g. <span class="arithmatex">\(x_1=x_2=1\)</span> or <span class="arithmatex">\(x_1=x_2=-1\)</span>), but there is no single global bowl – we have two distinct basins. A solver that doesn’t account for non-convexity might get stuck in one of them. This illustrates why breaking convexity is dangerous: local optimality need not imply global optimality. Indeed, <span class="arithmatex">\(x_1=x_2=1\)</span> gives <span class="arithmatex">\(f=2\)</span> and <span class="arithmatex">\(x_1=x_2=-1\)</span> gives <span class="arithmatex">\(f=2\)</span>, and those are the best feasible points; but if you started at <span class="arithmatex">\((10, 0.1)\)</span> which satisfies <span class="arithmatex">\(10 \cdot 0.1 = 1\)</span>, any local descent would stay in the positive quadrant basin.</p>
</li>
</ol>
<h3 id="checklist-for-verifying-convexity">Checklist for Verifying Convexity<a class="headerlink" href="#checklist-for-verifying-convexity" title="Permanent link">¶</a></h3>
<p>To wrap up, here is a handy checklist you can use as a step-by-step guide when faced with a new optimization problem. This is essentially a flowchart in words for convexity verification:</p>
<ol>
<li>
<p><strong>Problem Form:</strong> Convert the problem to a clear standard form. Are you minimizing an objective? (If it’s a maximization, consider the equivalent minimization of the negative objective.) Make sure all constraints are written as either “<span class="arithmatex">\(\le\)</span>” inequalities, “<span class="arithmatex">\(=\)</span>” equalities, or set memberships.</p>
</li>
<li>
<p><strong>Objective Function Convexity:</strong> Is the objective <span class="arithmatex">\(f_0(x)\)</span> convex? Check using the tools:</p>
</li>
<li>
<p>Does <span class="arithmatex">\(f_0(x)\)</span> match a known convex function type or a sum/composition of convex functions?</p>
</li>
<li>If it's smooth, is the Hessian <span class="arithmatex">\(\nabla^2 f_0(x) \succeq 0\)</span> for all <span class="arithmatex">\(x\)</span>?</li>
<li>If non-smooth, can you reason via subgradients or epigraph definition that it’s convex?</li>
<li>
<p>Any suspect terms (e.g. products, non-convex patterns) in the objective? If no issues and all tests indicate convex, proceed. If not convex, you have a non-convex problem (stop here, unless you plan to reformulate it).</p>
</li>
<li>
<p><strong>Inequality Constraints:</strong> For each constraint of the form <span class="arithmatex">\(f_i(x) \le 0\)</span>, check <span class="arithmatex">\(f_i(x)\)</span>:</p>
</li>
<li>Is <span class="arithmatex">\(f_i\)</span> convex? If yes, this constraint defines a convex region (the sublevel set). If any <span class="arithmatex">\(f_i\)</span> is non-convex (e.g. concave or neither), that constraint is non-convex – the feasible set will not be convex. (Remember you can rewrite <span class="arithmatex">\(g(x)\ge 0\)</span> as <span class="arithmatex">\(-g(x)\le 0\)</span> and check <span class="arithmatex">\(-g\)</span> for convexity.)</li>
<li>
<p>Also ensure the inequality is properly directed: a convex function should be <span class="arithmatex">\(\le 0\)</span>, a concave function should be <span class="arithmatex">\(\ge 0\)</span> to be convex (since <span class="arithmatex">\(g(x)\ge 0\)</span> with <span class="arithmatex">\(g\)</span> concave is the same as <span class="arithmatex">\(-g(x)\le 0\)</span> with <span class="arithmatex">\(-g\)</span> convex).</p>
</li>
<li>
<p><strong>Equality Constraints:</strong> For each <span class="arithmatex">\(h_j(x) = 0\)</span>, determine if <span class="arithmatex">\(h_j\)</span> is affine. If yes, it’s fine (convex constraint). If not (e.g. quadratic or anything nonlinear), the problem is not convex (unless perhaps that equality can be eliminated or transformed in a special way). Non-affine equalities are a deal-breaker for convexity in almost all cases.</p>
</li>
<li>
<p><strong>Domain Constraints:</strong> If the problem statement includes <span class="arithmatex">\(x \in C\)</span> for some set <span class="arithmatex">\(C\)</span>, or implicit domain restrictions (like <span class="arithmatex">\(x_i\)</span> must be integer, or <span class="arithmatex">\(x &gt; 0\)</span>), verify those sets are convex. <span class="arithmatex">\(x_i \ge 0\)</span> (the nonnegative orthant) is convex. Norm balls, simplices, linear subspaces – all convex. But if <span class="arithmatex">\(C\)</span> is, say, <span class="arithmatex">\({0,1}^n\)</span> (binary vectors), or a finite set of points, or defined by a weird non-convex condition, then the problem is not convex. Ensure there is no hidden discreteness.</p>
</li>
<li>
<p><strong>Intersections:</strong> After checking all individual constraints, consider the intersection of all feasible conditions. If each constraint is convex, their intersection is convex. Double-check there isn’t an implicit “either-or” structure (which would actually be a union of sets, not an intersection). If it’s a straightforward intersection of convex sets, you’re good.</p>
</li>
<li>
<p><strong>Conclusion:</strong> If all the above checks pass – objective is convex, all inequalities convex, all equalities affine, domain convex – then congratulations, the problem is convex! You can now be confident that any local optimum you find is globally optimal, and you can leverage the rich theory and algorithms of convex optimization. If any check fails, the problem is not convex. In that case, you might need to try reformulating the problem (sometimes through clever algebra or change of variables) or resort to global optimization techniques if you must solve it as is.</p>
</li>
<li>
<p><strong>(Optional Advanced Check:)</strong> If you’re still in doubt, one advanced technique is to consider the Lagrange dual of the problem (see later chapters) – convex problems have a well-behaved duality theory. Another is to examine the Fenchel conjugate of the objective: for a convex function, the conjugate is well-defined and useful. These are beyond the scope of this checklist, but they can sometimes provide confirmation. Generally, though, the steps above are sufficient in practice.
in any optimization endeavor</p>
</li>
</ol>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      © 2025 Salman Khan — Educational Use Only
    </div>
  
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/SalK91/convex_optimization" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.top", "navigation.expand", "header.autohide", "search.suggest", "search.highlight", "content.code.copy", "content.action.edit", "content.action.view"], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>