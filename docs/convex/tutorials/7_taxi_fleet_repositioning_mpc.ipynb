{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2dee698",
   "metadata": {},
   "source": [
    "# Taxi / Ride-Hailing Fleet Repositioning with Rolling-Horizon Convex Optimization (MPC)\n",
    "Taxi/Ride-hailing systems must continuously decide where to position idle vehicles so that future trip requests can be served with low waiting times. When vehicles move without a passenger—often called deadheading (or empty miles) they incur operational cost without generating revenue, so good policies must balance service quality against empty repositioning cost.\n",
    "\n",
    "In this notebook, we study dynamic fleet rebalancing using public trip records from the NYC Taxi & Limousine Commission (TLC). The TLC yellow-taxi data contains pickup/dropoff timestamps and pickup/dropoff zone identifiers, enabling us to aggregate origin–destination demand over time and space.\n",
    "\n",
    "We formulate this rebalancing as a convex, multi-period flow optimization solved in a receding-horizon (Model Predictive Control, MPC) loop: at each time step we \n",
    "\n",
    "1. State: idle vehicles per zone at the current time.\n",
    "2. Forecast: expected demand for the next few hours (simple time-of-week averages from training data).\n",
    "3. Optimize (convex): solve a multi-period, time-expanded flow model that decides:\n",
    "   - how many trips to serve in each zone pair, and\n",
    "   - how many vehicles to move empty between zones (reposition / deadhead flows),\n",
    "   trading off customer service vs. deadheading cost.\n",
    "4. Apply only the first step of the plan.\n",
    "5. Simulate reality: reveal the actual demand from held-out TLC data, update vehicle locations with travel-time lags, and repeat.\n",
    "\n",
    "---\n",
    "\n",
    "Data:\n",
    "- NYC TLC Trip Record Data (monthly Parquet download links)\n",
    "- Taxi zone lookup table (`LocationID → Borough/Zone/Service zone`)\n",
    "- Yellow taxi data dictionary for column meanings\n",
    "\n",
    "\n",
    "## Problem at a glance\n",
    "\n",
    "- City is partitioned into zones $i \\in \\{1,\\dots,K\\}$.\n",
    "- Time is discretized into steps $t = 0,1,\\dots$ (e.g., 15 minutes).\n",
    "- State $s_{i,t}$: idle vehicles in zone $i$ at step $t$.\n",
    "- Demand $d_{ij,t}$: ride requests from zone $i$ to $j$ at step $t$.\n",
    "- Decisions:\n",
    "  - $x_{ij,t}$: rides served from $i \\to j$ (bounded by demand)\n",
    "  - $r_{ij,t}$: empty reposition moves from $i \\to j$\n",
    "\n",
    "We solve a multi-period, time-expanded network-flow problem and run it in a rolling horizon loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86643ccc",
   "metadata": {},
   "source": [
    "## Mathematical formulation\n",
    "\n",
    "Let $H$ be the planning horizon (number of future time steps optimized each time).\n",
    "\n",
    "Decision variables (continuous):\n",
    "- $x_{ij,t} \\ge 0$ served demand (rides) for $t=0,\\dots,H-1$\n",
    "- $r_{ij,t} \\ge 0$ reposition (deadhead) flows\n",
    "- $u_{ij,t} \\ge 0$ unmet demand slack\n",
    "- $s_{i,t} \\ge 0$ idle vehicles for $t=0,\\dots,H$\n",
    "\n",
    "Constraints\n",
    "1. Demand bounds $0 \\le x_{ij,t} \\le \\hat d_{ij,t}$\n",
    "and we set $u_{ij,t} = \\hat d_{ij,t} - x_{ij,t}$.\n",
    "\n",
    "2. Idle vehicle availability\n",
    "$$\n",
    "\\sum_j x_{ij,t} + \\sum_j r_{ij,t} \\le s_{i,t}\n",
    "$$\n",
    "\n",
    "3. Fleet dynamics with travel-time lags\n",
    "\n",
    "We estimate an integer travel-time lag $\\tau_{ij}\\in\\{1,\\dots,\\tau_{\\max}\\}$ (in steps) from data.\n",
    "\n",
    "Vehicles that depart at time $t$ from $i\\to j$ arrive at $j$ at time $t+\\tau_{ij}$. Therefore, for each zone $i$ and time $t$:\n",
    "\n",
    "$$\n",
    "s_{i,t+1} = s_{i,t}\n",
    "- \\sum_j (x_{ij,t} + r_{ij,t})\n",
    "+ \\sum_k \\Big( x_{k i, t-\\tau_{ki}+1} + r_{k i, t-\\tau_{ki}+1} \\Big)\n",
    "$$\n",
    "where terms with negative indices are treated as 0.\n",
    "\n",
    "Objective (LP)\n",
    "$$\n",
    "\\min \\sum_{t,i,j} c^{repo}_{ij}\\, r_{ij,t} \\;+\\; \\lambda \\sum_{t,i,j} u_{ij,t}\n",
    "$$\n",
    "\n",
    "- $c^{repo}_{ij}$: deadhead cost (we use median travel time from data as a proxy)\n",
    "- $\\lambda$: penalty for unmet demand (service-level priority)\n",
    "\n",
    "Optional convex smoothing (QP):\n",
    "Add $\\eta \\sum_t \\|s_{\\cdot,t+1}-s_{\\cdot,t}\\|_2^2$ to reduce oscillatory repositioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0668f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3e0b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\salmank\\anaconda3\\envs\\pymc_env_5\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvxpy installed solvers: ['CLARABEL', 'CVXOPT', 'ECOS', 'ECOS_BB', 'GLOP', 'GLPK', 'GLPK_MI', 'OSQP', 'PDLP', 'SCIPY', 'SCS']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import pyarrow \n",
    "import cvxpy as cp\n",
    "\n",
    "SEED = 7\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "print(\"cvxpy installed solvers:\", cp.installed_solvers())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27daa155",
   "metadata": {},
   "source": [
    "#### Download NYC TLC data (Parquet) + zone lookup (CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a52a2763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Exists: data_tlc\\taxi_zone_lookup.csv\n",
      "✅ Exists: data_tlc\\yellow_tripdata_2024-01.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import urllib.request\n",
    "\n",
    "DATA_DIR = \"data_tlc\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Choose a month. You can change this to any month available on the TLC page.\n",
    "MONTH = \"2024-01\"\n",
    "\n",
    "YELLOW_URL = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{MONTH}.parquet\"\n",
    "ZONE_URL   = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\"\n",
    "\n",
    "YELLOW_PATH = os.path.join(DATA_DIR, f\"yellow_tripdata_{MONTH}.parquet\")\n",
    "ZONE_PATH   = os.path.join(DATA_DIR, \"taxi_zone_lookup.csv\")\n",
    "\n",
    "DOWNLOAD = True\n",
    "\n",
    "def download(url: str, path: str):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"✅ Exists: {path}\")\n",
    "        return\n",
    "    print(f\"⬇️ Downloading: {url}\")\n",
    "    urllib.request.urlretrieve(url, path)\n",
    "    print(f\"✅ Saved to: {path}\")\n",
    "\n",
    "if DOWNLOAD:\n",
    "    download(ZONE_URL, ZONE_PATH)\n",
    "    download(YELLOW_URL, YELLOW_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8093fef5",
   "metadata": {},
   "source": [
    "#### Load and clean the data\n",
    "\n",
    "We only need:\n",
    "- pickup datetime (`tpep_pickup_datetime`)\n",
    "- dropoff datetime (`tpep_dropoff_datetime`)\n",
    "- pickup zone ID (`PULocationID`)\n",
    "- dropoff zone ID (`DOLocationID`)\n",
    "\n",
    "We filter to a manageable time window and optionally sample rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "579ce2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>pickup_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:57:55</td>\n",
       "      <td>2024-01-01 01:17:43</td>\n",
       "      <td>186</td>\n",
       "      <td>79</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>2024-01-01 00:57:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 00:03:00</td>\n",
       "      <td>2024-01-01 00:09:36</td>\n",
       "      <td>140</td>\n",
       "      <td>236</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>2024-01-01 00:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 00:17:06</td>\n",
       "      <td>2024-01-01 00:35:01</td>\n",
       "      <td>236</td>\n",
       "      <td>79</td>\n",
       "      <td>17.916667</td>\n",
       "      <td>2024-01-01 00:17:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 00:36:38</td>\n",
       "      <td>2024-01-01 00:44:56</td>\n",
       "      <td>79</td>\n",
       "      <td>211</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>2024-01-01 00:36:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 00:46:51</td>\n",
       "      <td>2024-01-01 00:52:57</td>\n",
       "      <td>211</td>\n",
       "      <td>148</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>2024-01-01 00:46:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tpep_pickup_datetime tpep_dropoff_datetime  PULocationID  DOLocationID  \\\n",
       "0  2024-01-01 00:57:55   2024-01-01 01:17:43           186            79   \n",
       "1  2024-01-01 00:03:00   2024-01-01 00:09:36           140           236   \n",
       "2  2024-01-01 00:17:06   2024-01-01 00:35:01           236            79   \n",
       "3  2024-01-01 00:36:38   2024-01-01 00:44:56            79           211   \n",
       "4  2024-01-01 00:46:51   2024-01-01 00:52:57           211           148   \n",
       "\n",
       "   duration_min           pickup_dt  \n",
       "0     19.800000 2024-01-01 00:57:55  \n",
       "1      6.600000 2024-01-01 00:03:00  \n",
       "2     17.916667 2024-01-01 00:17:06  \n",
       "3      8.300000 2024-01-01 00:36:38  \n",
       "4      6.100000 2024-01-01 00:46:51  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column subset (keeps memory reasonable)\n",
    "COLS = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"PULocationID\", \"DOLocationID\"]\n",
    "\n",
    "# Optional row sampling after load (set to None for full month)\n",
    "N_SAMPLE = 3_000_000  # adjust based on your machine\n",
    "\n",
    "df = pd.read_parquet(YELLOW_PATH, columns=COLS,  engine=\"pyarrow\")\n",
    "\n",
    "# Basic cleaning\n",
    "df = df.dropna(subset=[\"PULocationID\", \"DOLocationID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"]).copy()\n",
    "\n",
    "\n",
    "# Ensure integer zone IDs\n",
    "df[\"PULocationID\"] = df[\"PULocationID\"].astype(int)\n",
    "df[\"DOLocationID\"] = df[\"DOLocationID\"].astype(int)\n",
    "\n",
    "pickup  = pd.to_datetime(df[\"tpep_pickup_datetime\"])\n",
    "dropoff = pd.to_datetime(df[\"tpep_dropoff_datetime\"])\n",
    "df[\"duration_min\"] = (dropoff - pickup).dt.total_seconds() / 60.0\n",
    "df['pickup_dt'] = pickup\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d155db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>264</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Outside of NYC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LocationID        Borough                     Zone service_zone\n",
       "0             1            EWR           Newark Airport          EWR\n",
       "1             2         Queens              Jamaica Bay    Boro Zone\n",
       "2             3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3             4      Manhattan            Alphabet City  Yellow Zone\n",
       "4             5  Staten Island            Arden Heights    Boro Zone\n",
       "..          ...            ...                      ...          ...\n",
       "260         261      Manhattan       World Trade Center  Yellow Zone\n",
       "261         262      Manhattan           Yorkville East  Yellow Zone\n",
       "262         263      Manhattan           Yorkville West  Yellow Zone\n",
       "263         264        Unknown                      NaN          NaN\n",
       "264         265            NaN           Outside of NYC          NaN\n",
       "\n",
       "[265 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zones = pd.read_csv(ZONE_PATH)\n",
    "zones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d08e7",
   "metadata": {},
   "source": [
    "#### Build demand tensors and travel-time estimates\n",
    "\n",
    "We choose:\n",
    "- time step length `DT_MIN` (e.g., 15 minutes)\n",
    "- a subset of zones (`K_ZONES`) to keep optimization fast\n",
    "- a train/test split within the month:\n",
    "  - train: compute demand profiles and travel-time medians\n",
    "  - test: backtest the MPC policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e698387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train window: 2002-12-31 00:00:00 to 2003-01-21 00:00:00 rows: 2\n",
      "Test  window: 2003-01-21 00:00:00 to 2003-01-28 00:00:00 rows: 0\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "month_start = df[\"pickup_dt\"].min().normalize()\n",
    "train_start = month_start\n",
    "train_end   = train_start + pd.Timedelta(days=21)\n",
    "test_start  = train_end\n",
    "test_end    = test_start + pd.Timedelta(days=7)\n",
    "\n",
    "df_train = df[(df[\"pickup_dt\"] >= train_start) & (df[\"pickup_dt\"] < train_end)].copy()\n",
    "df_test  = df[(df[\"pickup_dt\"] >= test_start)  & (df[\"pickup_dt\"] < test_end)].copy()\n",
    "\n",
    "print(\"Train window:\", train_start, \"to\", train_end, \"rows:\", len(df_train))\n",
    "print(\"Test  window:\", test_start,  \"to\", test_end,  \"rows:\", len(df_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "511126d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example zones: [170]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DT_MIN = 15\n",
    "K_ZONES = 100              # keep moderate; increase if you want\n",
    "H = 12                    # horizon length in steps (12*15min = 3 hours)\n",
    "TAU_MAX = 8               # max travel-time lag in steps (8*15min = 2 hours)\n",
    "\n",
    "top_zones = df_train[\"PULocationID\"].value_counts().head(K_ZONES).index.to_numpy()\n",
    "zone_to_idx = {z:i for i,z in enumerate(top_zones)}\n",
    "idx_to_zone = {i:z for z,i in zone_to_idx.items()}\n",
    "\n",
    "print(\"Example zones:\", top_zones[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e55e0b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>pickup_dt</th>\n",
       "      <th>tbin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53119</th>\n",
       "      <td>2002-12-31 22:59:39</td>\n",
       "      <td>2002-12-31 23:05:41</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>6.033333</td>\n",
       "      <td>2002-12-31 22:59:39</td>\n",
       "      <td>2002-12-31 22:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53120</th>\n",
       "      <td>2002-12-31 22:59:39</td>\n",
       "      <td>2002-12-31 23:05:41</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>6.033333</td>\n",
       "      <td>2002-12-31 22:59:39</td>\n",
       "      <td>2002-12-31 22:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tpep_pickup_datetime tpep_dropoff_datetime  PULocationID  DOLocationID  \\\n",
       "53119  2002-12-31 22:59:39   2002-12-31 23:05:41           170           170   \n",
       "53120  2002-12-31 22:59:39   2002-12-31 23:05:41           170           170   \n",
       "\n",
       "       duration_min           pickup_dt                tbin  \n",
       "53119      6.033333 2002-12-31 22:59:39 2002-12-31 22:45:00  \n",
       "53120      6.033333 2002-12-31 22:59:39 2002-12-31 22:45:00  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discretize_time(ts: pd.Series, dt_min: int) -> pd.Series:\n",
    "    return ts.dt.floor(f\"{dt_min}min\")\n",
    "\n",
    "df_train_k = df_train[df_train[\"PULocationID\"].isin(top_zones) & df_train[\"DOLocationID\"].isin(top_zones)].copy()\n",
    "df_test_k  = df_test[df_test[\"PULocationID\"].isin(top_zones) & df_test[\"DOLocationID\"].isin(top_zones)].copy()\n",
    "\n",
    "df_train_k[\"tbin\"] = discretize_time(df_train_k[\"pickup_dt\"], DT_MIN)\n",
    "df_test_k[\"tbin\"]  = discretize_time(df_test_k[\"pickup_dt\"], DT_MIN)\n",
    "\n",
    "df_train_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b74f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t_index = pd.date_range(df_test_k[\"tbin\"].min(), df_test_k[\"tbin\"].max(), freq=f\"{DT_MIN}min\")\n",
    "t_to_idx = {t:i for i,t in enumerate(t_index)}\n",
    "\n",
    "T_test = len(t_index)\n",
    "K = len(top_zones)\n",
    "\n",
    "d_real = np.zeros((T_test, K, K), dtype=np.float32)\n",
    "\n",
    "for row in df_test_k.itertuples(index=False):\n",
    "    t = row.tbin\n",
    "    if t not in t_to_idx:\n",
    "        continue\n",
    "    ti = t_to_idx[t]\n",
    "    i = zone_to_idx[row.PULocationID]\n",
    "    j = zone_to_idx[row.DOLocationID]\n",
    "    d_real[ti, i, j] += 1.0\n",
    "\n",
    "print(\"Test tensor shape:\", d_real.shape, \"nonzeros:\", np.count_nonzero(d_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1213debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "od_med = (df_train_k\n",
    "          .groupby([\"PULocationID\", \"DOLocationID\"])[\"duration_min\"]\n",
    "          .median()\n",
    "          .reset_index())\n",
    "\n",
    "global_med = float(df_train_k[\"duration_min\"].median())\n",
    "tt_min = np.full((K, K), global_med, dtype=np.float32)\n",
    "\n",
    "for row in od_med.itertuples(index=False):\n",
    "    i = zone_to_idx[row.PULocationID]\n",
    "    j = zone_to_idx[row.DOLocationID]\n",
    "    tt_min[i, j] = float(row.duration_min)\n",
    "\n",
    "tau = np.clip(np.ceil(tt_min / DT_MIN).astype(int), 1, TAU_MAX)\n",
    "c_repo = tt_min.copy()\n",
    "\n",
    "print(\"Median duration (min) global:\", global_med)\n",
    "print(\"tau stats (steps): min\", tau.min(), \"max\", tau.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59ac38d",
   "metadata": {},
   "source": [
    "## 4) Demand forecasting baseline (time-of-week average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d375093",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "steps_per_day = int(24*60/DT_MIN)\n",
    "\n",
    "df_train_k[\"weekday\"] = df_train_k[\"tbin\"].dt.weekday\n",
    "df_train_k[\"step_of_day\"] = (df_train_k[\"tbin\"].dt.hour * 60 + df_train_k[\"tbin\"].dt.minute) // DT_MIN\n",
    "df_train_k[\"date\"] = df_train_k[\"tbin\"].dt.date\n",
    "\n",
    "weekday_days = df_train_k.groupby(\"weekday\")[\"date\"].nunique().to_dict()\n",
    "\n",
    "grp = (df_train_k\n",
    "       .groupby([\"weekday\",\"step_of_day\",\"PULocationID\",\"DOLocationID\"])\n",
    "       .size()\n",
    "       .reset_index(name=\"cnt\"))\n",
    "\n",
    "avg = np.zeros((7, steps_per_day, K, K), dtype=np.float32)\n",
    "\n",
    "for row in grp.itertuples(index=False):\n",
    "    w, s = int(row.weekday), int(row.step_of_day)\n",
    "    i = zone_to_idx[row.PULocationID]\n",
    "    j = zone_to_idx[row.DOLocationID]\n",
    "    denom = max(1, weekday_days.get(w, 1))\n",
    "    avg[w, s, i, j] = float(row.cnt) / denom\n",
    "\n",
    "def forecast_demand(t0: pd.Timestamp, H: int) -> np.ndarray:\n",
    "    out = np.zeros((H, K, K), dtype=np.float32)\n",
    "    for h in range(H):\n",
    "        th = t0 + pd.Timedelta(minutes=DT_MIN*h)\n",
    "        w = th.weekday()\n",
    "        s = (th.hour*60 + th.minute)//DT_MIN\n",
    "        out[h] = avg[w, s]\n",
    "    return out\n",
    "\n",
    "print(\"avg tensor shape:\", avg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b77c99",
   "metadata": {},
   "source": [
    "## 5) Convex MPC optimizer (CVXPY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b549fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def solve_mpc_lp(\n",
    "    s0: np.ndarray,\n",
    "    d_hat: np.ndarray,     # (H,K,K)\n",
    "    c_repo: np.ndarray,    # (K,K)\n",
    "    tau: np.ndarray,       # (K,K) integer steps\n",
    "    lambda_unmet: float = 5.0,\n",
    "    eta_smooth: float = 0.0,\n",
    "    solver: str | None = None,\n",
    "):\n",
    "    H, K, _ = d_hat.shape\n",
    "    s0 = s0.astype(float)\n",
    "\n",
    "    x = cp.Variable((H, K, K), nonneg=True)\n",
    "    r = cp.Variable((H, K, K), nonneg=True)\n",
    "    s = cp.Variable((H+1, K), nonneg=True)\n",
    "    u = cp.Variable((H, K, K), nonneg=True)\n",
    "\n",
    "    cons = [s[0, :] == s0, x <= d_hat, u == d_hat - x]\n",
    "\n",
    "    for t in range(H):\n",
    "        cons += [cp.sum(x[t, :, :], axis=1) + cp.sum(r[t, :, :], axis=1) <= s[t, :]]\n",
    "\n",
    "    for t in range(H):\n",
    "        departures = cp.sum(x[t, :, :], axis=1) + cp.sum(r[t, :, :], axis=1)\n",
    "\n",
    "        arrivals_expr = []\n",
    "        for i in range(K):\n",
    "            incoming_terms = []\n",
    "            for k in range(K):\n",
    "                lag = int(tau[k, i])\n",
    "                dep_t = t - lag + 1\n",
    "                if 0 <= dep_t < H:\n",
    "                    incoming_terms.append(x[dep_t, k, i] + r[dep_t, k, i])\n",
    "            arrivals_expr.append(cp.sum(cp.hstack(incoming_terms)) if incoming_terms else 0.0)\n",
    "\n",
    "        arrivals = cp.hstack(arrivals_expr)\n",
    "        cons += [s[t+1, :] == s[t, :] - departures + arrivals]\n",
    "\n",
    "    obj = cp.sum(cp.multiply(c_repo[None, :, :], r)) + lambda_unmet * cp.sum(u)\n",
    "    if eta_smooth > 0:\n",
    "        obj += eta_smooth * cp.sum_squares(s[1:, :] - s[:-1, :])\n",
    "\n",
    "    prob = cp.Problem(cp.Minimize(obj), cons)\n",
    "\n",
    "    if solver is None:\n",
    "        for cand in [\"ECOS\", \"OSQP\", \"CLARABEL\", \"SCS\"]:\n",
    "            if cand in cp.installed_solvers():\n",
    "                solver = cand\n",
    "                break\n",
    "\n",
    "    prob.solve(solver=solver, verbose=False)\n",
    "    if prob.status not in (\"optimal\", \"optimal_inaccurate\"):\n",
    "        raise RuntimeError(f\"MPC solve failed: status={prob.status}\")\n",
    "\n",
    "    x0 = np.maximum(x.value[0], 0)\n",
    "    r0 = np.maximum(r.value[0], 0)\n",
    "    return x0, r0, float(prob.value), prob.status, solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b509ac",
   "metadata": {},
   "source": [
    "## 6) Simulator + backtesting loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7609a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class SimResult:\n",
    "    service_rate: np.ndarray\n",
    "    unmet: np.ndarray\n",
    "    deadhead_cost: np.ndarray\n",
    "    idle_total: np.ndarray\n",
    "    solver_time: np.ndarray\n",
    "    x_served_total: float\n",
    "    demand_total: float\n",
    "    deadhead_total: float\n",
    "\n",
    "def run_backtest(policy: str, H_policy: int, lambda_unmet=5.0, eta_smooth=0.0, fleet_size=4000):\n",
    "    pickup_counts = df_train_k[\"PULocationID\"].value_counts().reindex(top_zones).fillna(0).to_numpy(dtype=float)\n",
    "    p = pickup_counts / max(1.0, pickup_counts.sum())\n",
    "    s_idle = np.round(fleet_size * p).astype(float)\n",
    "\n",
    "    transit = [np.zeros(K, dtype=float) for _ in range(TAU_MAX)]\n",
    "\n",
    "    service_rate = np.zeros(T_test, dtype=float)\n",
    "    unmet = np.zeros(T_test, dtype=float)\n",
    "    deadhead_cost = np.zeros(T_test, dtype=float)\n",
    "    idle_total = np.zeros(T_test, dtype=float)\n",
    "    solver_time = np.zeros(T_test, dtype=float)\n",
    "\n",
    "    x_served_total = 0.0\n",
    "    demand_total = float(d_real.sum())\n",
    "    deadhead_total = 0.0\n",
    "\n",
    "    for t in tqdm(range(T_test), desc=f\"Backtest: {policy}\"):\n",
    "        arrivals_now = transit.pop(0)\n",
    "        transit.append(np.zeros(K, dtype=float))\n",
    "        s_idle += arrivals_now\n",
    "\n",
    "        idle_total[t] = s_idle.sum()\n",
    "        d_t = d_real[t].astype(float)\n",
    "\n",
    "        if policy == \"none\":\n",
    "            x_plan = d_t.copy()\n",
    "            r_plan = np.zeros((K, K), dtype=float)\n",
    "        else:\n",
    "            t0 = t_index[t]\n",
    "            d_hat = forecast_demand(t0, H_policy)\n",
    "\n",
    "            import time\n",
    "            t_start = time.time()\n",
    "            x0, r0, _, _, _ = solve_mpc_lp(\n",
    "                s0=s_idle,\n",
    "                d_hat=d_hat,\n",
    "                c_repo=c_repo,\n",
    "                tau=tau,\n",
    "                lambda_unmet=lambda_unmet,\n",
    "                eta_smooth=eta_smooth,\n",
    "            )\n",
    "            solver_time[t] = time.time() - t_start\n",
    "            x_plan, r_plan = x0, r0\n",
    "\n",
    "        x_serv = np.minimum(x_plan, d_t)\n",
    "\n",
    "        for i in range(K):\n",
    "            avail = s_idle[i]\n",
    "            serve_out = x_serv[i, :].sum()\n",
    "            if serve_out > avail + 1e-9:\n",
    "                x_serv[i, :] *= (avail / serve_out)\n",
    "                serve_out = avail\n",
    "\n",
    "            avail_left = avail - serve_out\n",
    "            repo_out = r_plan[i, :].sum()\n",
    "            if repo_out > avail_left + 1e-9 and repo_out > 0:\n",
    "                r_plan[i, :] *= (avail_left / repo_out)\n",
    "\n",
    "        dep = x_serv.sum(axis=1) + r_plan.sum(axis=1)\n",
    "        s_idle -= dep\n",
    "        s_idle = np.maximum(s_idle, 0.0)\n",
    "\n",
    "        for i in range(K):\n",
    "            for j in range(K):\n",
    "                flow = x_serv[i, j] + r_plan[i, j]\n",
    "                if flow <= 0:\n",
    "                    continue\n",
    "                lag = int(tau[i, j])\n",
    "                lag = max(1, min(TAU_MAX, lag))\n",
    "                transit[lag-1][j] += flow\n",
    "\n",
    "        served = float(x_serv.sum())\n",
    "        unmet_t = float(d_t.sum() - served)\n",
    "        cost_t = float((c_repo * r_plan).sum())\n",
    "\n",
    "        x_served_total += served\n",
    "        deadhead_total += cost_t\n",
    "\n",
    "        service_rate[t] = served / (float(d_t.sum()) + 1e-9)\n",
    "        unmet[t] = unmet_t\n",
    "        deadhead_cost[t] = cost_t\n",
    "\n",
    "    return SimResult(\n",
    "        service_rate=service_rate,\n",
    "        unmet=unmet,\n",
    "        deadhead_cost=deadhead_cost,\n",
    "        idle_total=idle_total,\n",
    "        solver_time=solver_time,\n",
    "        x_served_total=x_served_total,\n",
    "        demand_total=demand_total,\n",
    "        deadhead_total=deadhead_total,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a58b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run policies\n",
    "res_none = run_backtest(\"none\",   H_policy=1,  fleet_size=4000)\n",
    "res_myo  = run_backtest(\"myopic\", H_policy=1,  fleet_size=4000, lambda_unmet=8.0)\n",
    "res_mpc  = run_backtest(\"mpc\",    H_policy=H,  fleet_size=4000, lambda_unmet=8.0, eta_smooth=1e-3)\n",
    "\n",
    "def summarize(name, res: SimResult):\n",
    "    return {\n",
    "        \"Policy\": name,\n",
    "        \"Total demand\": res.demand_total,\n",
    "        \"Total served\": res.x_served_total,\n",
    "        \"Service rate\": res.x_served_total / max(1e-9, res.demand_total),\n",
    "        \"Total deadhead cost\": res.deadhead_total,\n",
    "        \"Avg solver time (s)\": float(np.mean(res.solver_time[res.solver_time>0])) if np.any(res.solver_time>0) else 0.0,\n",
    "    }\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    summarize(\"No reposition\", res_none),\n",
    "    summarize(\"Myopic H=1\",    res_myo),\n",
    "    summarize(f\"MPC H={H}\",    res_mpc),\n",
    "])\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0c832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(res_none.service_rate, label=\"No reposition\")\n",
    "plt.plot(res_myo.service_rate,  label=\"Myopic H=1\")\n",
    "plt.plot(res_mpc.service_rate,  label=f\"MPC H={H}\")\n",
    "plt.xlabel(\"Time step (15-min)\")\n",
    "plt.ylabel(\"Service rate (served / demand)\")\n",
    "plt.title(\"Service rate over time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(np.cumsum(res_none.deadhead_cost), label=\"No reposition\")\n",
    "plt.plot(np.cumsum(res_myo.deadhead_cost),  label=\"Myopic H=1\")\n",
    "plt.plot(np.cumsum(res_mpc.deadhead_cost),  label=f\"MPC H={H}\")\n",
    "plt.xlabel(\"Time step (15-min)\")\n",
    "plt.ylabel(\"Cumulative deadhead cost (minutes)\")\n",
    "plt.title(\"Cumulative deadhead cost over time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6101b98",
   "metadata": {},
   "source": [
    "## 7) Stress testing scenarios\n",
    "\n",
    "Because we have a simulator, you can create \"what-if\" scenarios without changing the optimizer:\n",
    "- Demand shock: multiply demand in a set of zones for a period (event letting out).\n",
    "- Congestion shock: increase travel times $tt_{ij}$ (and thus $\\tau_{ij}$, $c^{repo}_{ij}$) for certain OD pairs.\n",
    "- Fleet shortage: reduce `fleet_size`.\n",
    "\n",
    "Below is a simple demand shock example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d02655",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_demand_shock(d_real_base: np.ndarray, zone_subset_idx, t_start, t_end, factor=1.5):\n",
    "    d = d_real_base.copy()\n",
    "    d[t_start:t_end, zone_subset_idx, :] *= factor\n",
    "    return d\n",
    "\n",
    "shock_zones = list(range(min(5, K)))\n",
    "t_start_shock, t_end_shock = 24, 36  # adjust based on your test start time\n",
    "\n",
    "d_backup = d_real.copy()\n",
    "d_real = apply_demand_shock(d_real, shock_zones, t_start_shock, t_end_shock, factor=1.8)\n",
    "\n",
    "res_mpc_shock = run_backtest(\"mpc\", H_policy=H, fleet_size=4000, lambda_unmet=8.0, eta_smooth=1e-3)\n",
    "\n",
    "d_real = d_backup\n",
    "\n",
    "print(\"Base MPC service rate:\", res_mpc.x_served_total / res_mpc.demand_total)\n",
    "print(\"Shock MPC service rate:\", res_mpc_shock.x_served_total / res_mpc_shock.demand_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bac558",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(res_mpc.service_rate, label=\"MPC (base)\")\n",
    "plt.plot(res_mpc_shock.service_rate, label=\"MPC (demand shock)\")\n",
    "plt.axvspan(t_start_shock, t_end_shock, alpha=0.2, label=\"Shock window\")\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Service rate\")\n",
    "plt.title(\"MPC robustness under a demand shock\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0563ca65",
   "metadata": {},
   "source": [
    "## Next upgrades (optional)\n",
    "\n",
    "- Add fairness constraints (minimum service per borough / zone group)\n",
    "- Use HVFHV trip records for a closer ride-hailing proxy (also on the TLC page)\n",
    "- Use the taxi zone shapefile to plot maps (geopandas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
