<!DOCTYPE html><html lang="en" class="no-js"><head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Structured lecture notes on optimization, convex analysis, and algorithms.">
      
      
        <meta name="author" content="Salman Khan">
      
      
        <link rel="canonical" href="https://salk91.github.io/convex_optimization/1_1_vector/">
      
      
        <link rel="prev" href="../1_0_intro/">
      
      
        <link rel="next" href="../1_7_calculus/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>2. Linear Algebra Foundations - Mathematics for Machine Learning</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.e53b48f4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Merriweather:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&amp;display=fallback">
        <style>:root{--md-text-font:"Merriweather";--md-code-font:"Fira Code"}</style>
      
    
    
      <link rel="stylesheet" href="../styles/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  <link href="../assets/stylesheets/glightbox.min.css" rel="stylesheet"><script src="../assets/javascripts/glightbox.min.js"></script><style id="glightbox-style">
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#chapter-2-linear-algebra-foundations" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Mathematics for Machine Learning" class="md-header__button md-logo" aria-label="Mathematics for Machine Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Mathematics for Machine Learning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              2. Linear Algebra Foundations
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="indigo" aria-label="Switch to light mode" type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="indigo" aria-label="Switch to dark mode" type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m3.55 19.09 1.41 1.41 1.8-1.79-1.42-1.42M12 6c-3.31 0-6 2.69-6 6s2.69 6 6 6 6-2.69 6-6c0-3.32-2.69-6-6-6m8 7h3v-2h-3m-2.76 7.71 1.8 1.79 1.41-1.41-1.79-1.8M20.45 5l-1.41-1.4-1.8 1.79 1.42 1.42M13 1h-2v3h2M6.76 5.39 4.96 3.6 3.55 5l1.79 1.81zM1 13h3v-2H1m12 9h-2v3h2"></path></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/SalK91/convex_optimization" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Mathematics for Machine Learning" class="md-nav__button md-logo" aria-label="Mathematics for Machine Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg>

    </a>
    Mathematics for Machine Learning
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/SalK91/convex_optimization" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"></path></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" checked>
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Convex Optimization:
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Convex Optimization:
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_0_intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. Introduction and Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    2. Linear Algebra Foundations
    
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_7_calculus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. Multivariable Calculus for Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_8_convexsets/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Convex Sets and Geometric Fundamentals
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_9_convexfunctions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. Convex Functions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_7a_subgradients/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. Nonsmooth Convex Optimization – Subgradients
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_12_kkt/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. Optimization Principles – From Gradient Descent to KKT
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_13_duality/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8. Lagrange Duality Theory
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3_0_optimizationalgo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9. Algorithms for Convex Optimization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3_7_advanced/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10. Advanced Large-Scale and Structured Methods
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3_8_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11. Modelling Patterns and Algorithm Selection in Practice
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_10_ineqaulities/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Appendix A - Common Inequalities and Identities
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_11_support/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Appendix B - Support Functions and Dual Geometry (Advanced)
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/SalK91/convex_optimization/edit/master/docs/1_1_vector.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/SalK91/convex_optimization/raw/master/docs/1_1_vector.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg>
    </a>
  


<h1 id="chapter-2-linear-algebra-foundations">Chapter 2: Linear Algebra Foundations<a class="headerlink" href="#chapter-2-linear-algebra-foundations" title="Permanent link">¶</a></h1>
<p>Convex optimisation is geometric. To talk about convex sets, supporting hyperplanes, projections, and quadratic forms, we need linear algebra. This chapter reviews the specific linear algebra tools we will use throughout: vector spaces, inner products, norms, projections, eigenvalues, and positive semidefinite matrices (Strang, 2016; Boyd and Vandenberghe, 2004).</p>
<hr>
<h2 id="21-vector-spaces-subspaces-and-affine-sets">2.1 Vector spaces, subspaces, and affine sets<a class="headerlink" href="#21-vector-spaces-subspaces-and-affine-sets" title="Permanent link">¶</a></h2>
<p>A <strong>vector space</strong> over <span class="arithmatex">\(\mathbb{R}\)</span> is a set <span class="arithmatex">\(V\)</span> equipped with addition and scalar multiplication satisfying the usual axioms: closure, associativity, distributivity, etc. In this book we mostly work with <span class="arithmatex">\(V = \mathbb{R}^n\)</span>.</p>
<p>A <strong>subspace</strong> <span class="arithmatex">\(S \subseteq \mathbb{R}^n\)</span> is a subset that:</p>
<ol>
<li>contains <span class="arithmatex">\(0\)</span>,</li>
<li>is closed under addition,</li>
<li>is closed under scalar multiplication.</li>
</ol>
<p>For example, the set of all solutions to <span class="arithmatex">\(Ax = 0\)</span> is a subspace, called the <strong>nullspace</strong> or <strong>kernel</strong> of <span class="arithmatex">\(A\)</span>.</p>
<p>An <strong>affine set</strong> is a translated subspace. A set <span class="arithmatex">\(A\)</span> is affine if for any <span class="arithmatex">\(x,y \in A\)</span> and any <span class="arithmatex">\(\theta \in \mathbb{R}\)</span>,<br>
<script type="math/tex; mode=display">
\theta x + (1-\theta) y \in A~.
</script>
Every affine set can be written as
<script type="math/tex; mode=display">
x_0 + S = \{ x_0 + s : s \in S \},
</script>
where <span class="arithmatex">\(S\)</span> is a subspace. Affine sets appear as the solution sets to linear equality constraints <span class="arithmatex">\(Ax = b\)</span>.</p>
<p>Affine sets are important in optimisation because:
- Feasible sets defined by equality constraints are affine.
- Affine functions preserve convexity.</p>
<hr>
<h2 id="22-linear-combinations-span-basis-dimension">2.2 Linear combinations, span, basis, dimension<a class="headerlink" href="#22-linear-combinations-span-basis-dimension" title="Permanent link">¶</a></h2>
<p>Given vectors <span class="arithmatex">\(v_1,\dots,v_k\)</span>, any vector of the form
<script type="math/tex; mode=display">
\alpha_1 v_1 + \cdots + \alpha_k v_k
</script>
is a <strong>linear combination</strong>. The set of all linear combinations is called the <strong>span</strong>:
<script type="math/tex; mode=display">
\mathrm{span}\{v_1,\dots,v_k\} = \left\{ \sum_{i=1}^k \alpha_i v_i : \alpha_i \in \mathbb{R} \right\}.
</script>
</p>
<p>A list of vectors is <strong>linearly independent</strong> if no nontrivial linear combination gives <span class="arithmatex">\(0\)</span>. A <strong>basis</strong> of a subspace <span class="arithmatex">\(S\)</span> is a set of linearly independent vectors whose span is <span class="arithmatex">\(S\)</span>. The number of vectors in a basis is the <strong>dimension</strong> of <span class="arithmatex">\(S\)</span>.</p>
<p>Rank and nullity facts:
- The <strong>column space</strong> of <span class="arithmatex">\(A\)</span> is the span of its columns. Its dimension is <span class="arithmatex">\(\mathrm{rank}(A)\)</span>.
- The <strong>nullspace</strong> of <span class="arithmatex">\(A\)</span> is <span class="arithmatex">\(\{ x : Ax = 0 \}\)</span>.
- The <strong>rank-nullity theorem</strong> states:
<script type="math/tex; mode=display">
\mathrm{rank}(A) + \mathrm{nullity}(A) = n,
</script>
where <span class="arithmatex">\(n\)</span> is the number of columns of <span class="arithmatex">\(A\)</span>.</p>
<p>In constrained optimisation, <span class="arithmatex">\(\mathrm{rank}(A)\)</span> encodes the “number of independent constraints”, and the nullspace encodes feasible directions that do not violate certain constraints (Boyd and Vandenberghe, 2004).</p>
<hr>
<h2 id="23-inner-products-and-orthogonality">2.3 Inner products and orthogonality<a class="headerlink" href="#23-inner-products-and-orthogonality" title="Permanent link">¶</a></h2>
<p>An <strong>inner product</strong> on <span class="arithmatex">\(\mathbb{R}^n\)</span> is a map <span class="arithmatex">\(\langle \cdot,\cdot\rangle : \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}\)</span> such that for all <span class="arithmatex">\(x,y,z\)</span> and all scalars <span class="arithmatex">\(\alpha\)</span>:</p>
<ol>
<li><span class="arithmatex">\(\langle x,y \rangle = \langle y,x\rangle\)</span> (symmetry),</li>
<li><span class="arithmatex">\(\langle x+y,z \rangle = \langle x,z \rangle + \langle y,z\rangle\)</span> (linearity in first argument),</li>
<li><span class="arithmatex">\(\langle \alpha x, y\rangle = \alpha \langle x, y\rangle\)</span>,</li>
<li><span class="arithmatex">\(\langle x, x\rangle \ge 0\)</span> with equality iff <span class="arithmatex">\(x=0\)</span> (positive definiteness).</li>
</ol>
<p>In <span class="arithmatex">\(\mathbb{R}^n\)</span>, the standard inner product is the dot product:
<script type="math/tex; mode=display">
\langle x,y \rangle = x^\top y = \sum_{i=1}^n x_i y_i~.
</script>
</p>
<p>The inner product induces:
- <strong>length (norm)</strong>: <span class="arithmatex">\(\|x\|_2 = \sqrt{\langle x,x\rangle}\)</span>,
- <strong>angle</strong>: 
<script type="math/tex; mode=display">
\cos \theta = \frac{\langle x,y\rangle}{\|x\|\|y\|}~.
</script>
</p>
<p>Two vectors are <strong>orthogonal</strong> if <span class="arithmatex">\(\langle x,y\rangle = 0\)</span>. A set of vectors <span class="arithmatex">\(\{v_i\}\)</span> is <strong>orthonormal</strong> if each <span class="arithmatex">\(\|v_i\| = 1\)</span> and <span class="arithmatex">\(\langle v_i, v_j\rangle = 0\)</span> for <span class="arithmatex">\(i\ne j\)</span>.</p>
<blockquote>
<p>Orthogonality is the language of optimality. Gradients are orthogonal to level sets; Lagrange multipliers encode orthogonality between objective gradient and constraint normals (Boyd and Vandenberghe, 2004).</p>
</blockquote>
<h3 id="the-cauchyschwarz-inequality">The Cauchy–Schwarz inequality<a class="headerlink" href="#the-cauchyschwarz-inequality" title="Permanent link">¶</a></h3>
<p>For any <span class="arithmatex">\(x,y \in \mathbb{R}^n\)</span>:
<script type="math/tex; mode=display">
|\langle x,y\rangle| \le \|x\|\|y\|~,
</script>
with equality iff <span class="arithmatex">\(x\)</span> and <span class="arithmatex">\(y\)</span> are linearly dependent. This is fundamental in analysis and optimisation; it underlies Hölder’s inequality, dual norms, and more.</p>
<hr>
<h2 id="24-norms-and-distances">2.4 Norms and distances<a class="headerlink" href="#24-norms-and-distances" title="Permanent link">¶</a></h2>
<p>A function <span class="arithmatex">\(\|\cdot\|: \mathbb{R}^n \to \mathbb{R}\)</span> is a <strong>norm</strong> if for all <span class="arithmatex">\(x,y\)</span> and scalar <span class="arithmatex">\(\alpha\)</span>:</p>
<ol>
<li><span class="arithmatex">\(\|x\| \ge 0\)</span> and <span class="arithmatex">\(\|x\| = 0 \iff x=0\)</span>,</li>
<li><span class="arithmatex">\(\|\alpha x\| = |\alpha|\|x\|\)</span> (absolute homogeneity),</li>
<li><span class="arithmatex">\(\|x+y\| \le \|x\| + \|y\|\)</span> (triangle inequality).</li>
</ol>
<p>Important norms:</p>
<ul>
<li>Euclidean norm: <span class="arithmatex">\(\|x\|_2 = \sqrt{x^\top x}\)</span>,</li>
<li><span class="arithmatex">\(\ell_1\)</span> norm: <span class="arithmatex">\(\|x\|_1 = \sum_i |x_i|\)</span>,</li>
<li><span class="arithmatex">\(\ell_\infty\)</span> norm: <span class="arithmatex">\(\|x\|_\infty = \max_i |x_i|\)</span>.</li>
</ul>
<p>Norms induce distances: <span class="arithmatex">\(d(x,y) = \|x-y\|\)</span>. The geometry of a norm ball
<script type="math/tex; mode=display">
\{ x : \|x\| \le 1 \}
</script>
matters in optimisation: it describes regularisation constraints (e.g. <span class="arithmatex">\(\ell_1\)</span> promotes sparsity; <span class="arithmatex">\(\ell_2\)</span> promotes smoothness).</p>
<p>Each norm <span class="arithmatex">\(\|\cdot\|\)</span> has a <strong>dual norm</strong> <span class="arithmatex">\(\|\cdot\|_*\)</span> defined by
<script type="math/tex; mode=display">
\|y\|_* = \sup_{\|x\|\le 1} x^\top y~.
</script>
For example, the dual of <span class="arithmatex">\(\ell_1\)</span> is <span class="arithmatex">\(\ell_\infty\)</span>, and the dual of <span class="arithmatex">\(\ell_2\)</span> is itself.</p>
<p>Dual norms reappear in duality theory and in support functions (Hiriart-Urruty and Lemaréchal, 2001).</p>
<hr>
<h2 id="25-linear-maps-matrices-rank">2.5 Linear maps, matrices, rank<a class="headerlink" href="#25-linear-maps-matrices-rank" title="Permanent link">¶</a></h2>
<p>A matrix <span class="arithmatex">\(A \in \mathbb{R}^{m\times n}\)</span> represents a linear map <span class="arithmatex">\(x \mapsto Ax\)</span>. We care especially about:</p>
<ul>
<li>rank<span class="arithmatex">\((A)\)</span>,</li>
<li>null<span class="arithmatex">\((A)\)</span>,</li>
<li>whether <span class="arithmatex">\(A\)</span> is symmetric (<span class="arithmatex">\(A = A^\top\)</span>),</li>
<li>whether <span class="arithmatex">\(A\)</span> is positive semidefinite.</li>
</ul>
<p>A linear constraint <span class="arithmatex">\(Ax = b\)</span> defines an affine set. Inequalities <span class="arithmatex">\(Cx \le d\)</span> define an intersection of halfspaces, hence a convex polyhedron. Both appear as feasible sets in convex optimisation (Boyd and Vandenberghe, 2004).</p>
<hr>
<h2 id="26-eigenvalues-eigenvectors-and-positive-semidefinite-matrices">2.6 Eigenvalues, eigenvectors, and positive semidefinite matrices<a class="headerlink" href="#26-eigenvalues-eigenvectors-and-positive-semidefinite-matrices" title="Permanent link">¶</a></h2>
<p>If <span class="arithmatex">\(A \in \mathbb{R}^{n\times n}\)</span> is linear, a nonzero <span class="arithmatex">\(v\)</span> is an <strong>eigenvector</strong> with <strong>eigenvalue</strong> <span class="arithmatex">\(\lambda\)</span> if
<script type="math/tex; mode=display">
Av = \lambda v~.
</script>
</p>
<p>When <span class="arithmatex">\(A\)</span> is <strong>symmetric</strong> (<span class="arithmatex">\(A = A^\top\)</span>), it has:
- real eigenvalues,
- an orthonormal eigenbasis,
- a spectral decomposition
<script type="math/tex; mode=display">
A = Q \Lambda Q^\top,
</script>
where <span class="arithmatex">\(Q\)</span> is orthonormal and <span class="arithmatex">\(\Lambda\)</span> is diagonal.</p>
<p>A symmetric matrix <span class="arithmatex">\(Q\)</span> is <strong>positive semidefinite (PSD)</strong> if
<script type="math/tex; mode=display">
x^\top Q x \ge 0 \quad \text{for all } x~.
</script>
If <span class="arithmatex">\(x^\top Q x &gt; 0\)</span> for all <span class="arithmatex">\(x\ne 0\)</span>, then <span class="arithmatex">\(Q\)</span> is <strong>positive definite (PD)</strong>.</p>
<p>Why this matters: if <span class="arithmatex">\(f(x) = \tfrac{1}{2} x^\top Q x + c^\top x + d\)</span>, then
<script type="math/tex; mode=display">
\nabla^2 f(x) = Q~.
</script>
So <span class="arithmatex">\(f\)</span> is convex iff <span class="arithmatex">\(Q\)</span> is PSD. Quadratic objectives with PSD Hessians are convex; with indefinite Hessians, they are not (Boyd and Vandenberghe, 2004). This is the algebraic test for convexity of quadratic forms.</p>
<hr>
<h2 id="27-orthogonal-projections-and-least-squares">2.7 Orthogonal projections and least squares<a class="headerlink" href="#27-orthogonal-projections-and-least-squares" title="Permanent link">¶</a></h2>
<p>Let <span class="arithmatex">\(S\)</span> be a subspace of <span class="arithmatex">\(\mathbb{R}^n\)</span>. The <strong>orthogonal projection</strong> of a vector <span class="arithmatex">\(b\)</span> onto <span class="arithmatex">\(S\)</span> is the unique vector <span class="arithmatex">\(p \in S\)</span> minimising <span class="arithmatex">\(\|b - p\|_2\)</span>. Geometrically, <span class="arithmatex">\(p\)</span> is the closest point in <span class="arithmatex">\(S\)</span> to <span class="arithmatex">\(b\)</span>.</p>
<p>If <span class="arithmatex">\(S = \mathrm{span}\{a_1,\dots,a_k\}\)</span> and <span class="arithmatex">\(A = [a_1~\cdots~a_k]\)</span>, then projecting <span class="arithmatex">\(b\)</span> onto <span class="arithmatex">\(S\)</span> is equivalent to solving the least-squares problem
<script type="math/tex; mode=display">
\min_x \|Ax - b\|_2^2~.
</script>
The solution <span class="arithmatex">\(x^*\)</span> satisfies the <strong>normal equations</strong>
<script type="math/tex; mode=display">
A^\top A x^* = A^\top b~.
</script>
</p>
<p>This is our first real convex optimisation problem:</p>
<ul>
<li>the objective <span class="arithmatex">\(\|Ax-b\|_2^2\)</span> is convex,</li>
<li>there are no constraints,</li>
<li>we can solve it in closed form.</li>
</ul>
<p>Least squares is not just linear algebra. It is convex optimisation in disguise.</p>
<p>--</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      © 2025 Salman Khan — Educational Use Only
    </div>
  
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/SalK91/convex_optimization" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.top", "navigation.expand", "header.autohide", "search.suggest", "search.highlight", "content.code.copy", "content.action.edit", "content.action.view"], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>